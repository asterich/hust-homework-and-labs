# 模型量化综述

## 摘要

随着深度学习模型在各种任务中取得突破性进展，其对计算资源的需求也急剧增加。尤其是在资源受限的设备上部署这些模型时，如何在保持模型性能的同时减少计算负担成为了一个紧迫的问题。模型量化，作为解决此问题的有效策略之一，通过减少模型中权重和激活值的位宽来减小模型大小和加速训练/推理过程。本文从训练后量化（Post-Training Quantization, PTQ）和量化感知训练（Quantization-Aware Training, QAT）两类量化方法入手，综述了最近几年的模型量化研究进展，探讨了量化方法的分类、原理以及实施策略。通过对比不同量化方法的优势与劣势，本文旨在为研究人员和实践者提供一个较为清晰的量化模型发展蓝图，同时对未来的研究方向提出展望。

## 引言

在深度学习领域，尤其是在资源受限的环境中部署模型时，模型量化作为一种提高效率的技术手段受到了广泛关注。量化技术通过减少表示模型参数和激活值所需的位数，旨在实现模型大小的减小、计算速度的提升以及能耗的降低。通常，模型量化分为两大类：训练后量化（Post-Training Quantization, PTQ）和量化感知训练（Quantization-Aware Training, QAT）。本文将以这两种主要的量化方法为框架，对当前的模型量化技术进行分类和讨论。

本文将首先介绍模型量化的基础理论，包括量化的数学定义、不同量化策略的类型及其优劣。接着，我们详细探讨后训练量化的不同技术和方法，以及它们在实际应用中的表现和局限性。随后，我们分析量化感知训练的原理、实现技巧以及它如何提高量化后模型的准确性。最后，我们将对比这两种量化方法，并讨论它们在不同应用场景下的适用性，以及它们如何相互补充，共同推动模型量化技术的发展。通过综合当前的研究成果和实践经验，本文旨在为研究人员和开发者提供一个关于模型量化的全面视角，并对未来可能的研究方向和挑战提出见解。

## 基础理论

一个通用的量化公式如下所示：
$$
\mathbf{X}_q=f\left(s \times g\left(\mathbf{X}_r\right)+z\right)
$$
其中 $\mathbf{X}_r$ 是待量化的标量，$\mathbf{X}_q$ 是量化后的标量；$g( \cdot ), s, z$ 分别代表截断函数、缩放程度和零点偏移，它们的计算如下：
$$
\begin{aligned}
& g(x)=\operatorname{clamp}(x, m, M) \\
& \text{where} \operatorname{clamp}(\chi, \alpha, \beta) = max(min(\chi, \beta), \alpha) \\
& s=\frac{n-1}{M-m}, \quad z=\frac{m \times(1-n)}{M-m} \\
& \text { where } m=\min \left\{\mathbf{X}_i\right\}, M=\max \left\{\mathbf{X}_i\right\}
\end{aligned}
$$


max-abs 方法（如下）使用一个对称的边界，这时零点 $z$ 是0，不用计算，这方面的开销会减小。但是这样会使动态范围缩小，因为数据的有效范围本来就是更窄的。这一点在经 ReLU 激活后的数据上尤为明显，因为 ReLU 把负值抹平为0了。
$$
\begin{aligned}
& g(x)=\operatorname{clamp}(x,-M, M) \\
& s=\frac{n-1}{R}, z=0 \\
& \text { where } R=\max \left\{a b s\left\{\mathbf{X}_i\right\}\right\}
\end{aligned}
$$
量化可以用在特征 $\mathbf{F}$ 、权重 $\mathbf{W}$ 和偏置 $\mathbf{b}$ 上。下标 $r$ 和 $q$ 分别表示真值和量化值，$\text{max}$ 下标来自上文中 $R$ ，而 $s_f=(n-1) / F_{\max }, s_w=(n-1) / W_{\max }$。 
$$
\mathbf{F}_q=\frac{n-1}{F_{\max }} \times \mathbf{F}_r, \quad \mathbf{W}_q=\frac{n-1}{W_{\max }} \times \mathbf{W}_r
$$
整数量化后的卷积公式如下所示：
$$
\mathbf{O}_q=\mathbf{F}_q * \mathbf{W}_q \quad \text { s.t. } \mathbf{F}, \mathbf{W} \in \mathbb{Z}
$$
实际上跟浮点卷积是一样的。

去量化使用 $s_f, s_w$ 将 $\mathbf{O}_q$ 转换回浮点形式 $\mathbf{O}_r$。这对使用浮点进行运算的层非常有用。
$$
\mathbf{O}_r=\frac{\mathbf{O}_q}{s_f \times s_w}=\mathbf{O}_q \times \frac{F_{\max }}{(n-1)} \times \frac{W_{\max }}{(n-1)}
$$
在大多数情况下，相继的层间可以用量化后参数进行计算。这让去量化能够被合并消掉。我们使用下面的公式，其中 $\mathbf{F}_q^{l+1}$ 是输入到下一层的量化后特征， $s_f^{l+1}$ 是下一层的量化缩放程度。
$$
\mathbf{F}_q^{l+1}=\frac{\mathbf{0}_q \times s_f^{l+1}}{s_f \times s_w}
$$


## 量化方法

量化领域的研究大致可分为以下两类：训练后量化（Post-Training Quantization, PTQ）和量化感知训练（Quantization-aware Training, QAT）。这两者的区别在于量化时是否将训练过程考虑在内。

### Post-training Quantization

一般而言，PTQ 先取得训练好的模型，然后量化其权重。它是一种直观的量化方法，在模型训练完成后进行，不需要对模型重新训练。PTQ 的主要优势在于其简单方便，使得已经训练好的模型可以快速部署到各种硬件平台上。然而，这种方法也面临着如何在不显著降低模型性能的前提下选择最佳量化方案的挑战。

当前对 CNN 模型 PTQ 量化的研究主要集中在以下几个方面：

- **混合精度量化**：研究如何在不同层应用不同的量化精度，以最小化整体模型的精度损失。例如，"ZeroQ: A Novel Zero Shot Quantization Framework" 提出了一种基于帕累托边界的混合精度量化方法。
- **低比特宽度量化**：如 "Post training 4-bit quantization of convolutional networks for rapid-deployment" 提出了一种实用的4位后训练量化方法，该方法不涉及量化模型的训练（微调），也不需要完整数据集。
- **变换域量化**：针对特定类型的卷积模型（如视觉变换器）的量化，研究如何在变换域中应用量化以提高性能。
- **综合性能研究**：对不同的后训练量化方法进行综合性能研究，以确定在特定任务（如分类和对象检测）中哪些方法最有效。

以下是一些近几年的工作：

##### Post-training 4-bit quantization of convolution networks for rapid-deployment (NeurIPS 2019)

这篇论文提出了首个实用的 4 位 PTQ 方法，不涉及量化模型的训练（微调），也不需要完整数据集。在各常见卷积模型上，该方法的准确率仅比最先进的 baseline 低几个百分点。

具体而言，这项工作为整数量化提出了一种分析的剪切方法（即 ACIQ），并应用在按通道的位分配和量化后的偏差修正中。论文作者经过数学推导，发现在待量化的标量存在 $\text{Laplace}(0, b)$ 的拉普拉斯分布时，剪切最大值 $\alpha$ 取 $b$ 和一个由量化位数决定的常量相乘（例如，4-bit时是5.03, 2-bit时是2.83），效果是最好的。参数 $b$ 可由 $b=\mathbb{E}(|X-\mathbb{E}(X)|)$ 计算得到。

##### ZeroQ: A Novel Zero Shot Quantization Framework (CVPR 2020)

以往的大多数量化方法需要原始数据，这在涉及敏感、专有数据的场景中并不现实。ZeroQ 的主要贡献有两个：

- 通过优化一个与网络不同层次的 batchnorm 统计数据相匹配的“蒸馏数据集”，实现了在没有原始数据的情况下进行有效的量化。
- 支持统一精度和混合精度量化。对于混合精度量化，它引入了一种基于帕累托边界（Pareto frontier）的新方法，自动确定所有层的精度设置，无需暴力搜索。

对于蒸馏数据集，论文作者通过求解以下最优化问题来解决：
$$
\min _{x^r} \sum_{i=0}^L\left\|\tilde{\mu}_i^r-\mu_i\right\|_2^2+\left\|\tilde{\sigma}_i^r-\sigma_i\right\|_2^2
$$
式中 $x^r$ 是蒸馏后的输入数据，$\mu_i/\sigma_i$ 是蒸馏数据集在第 i 层的均值/标准差分布。由此，他们得出以下蒸馏算法：

![image-20231221004341493](C:\Users\asterich\AppData\Roaming\Typora\typora-user-images\image-20231221004341493.png)

对于混合精度量化，论文作者使用 KL散度来确定模型第 $i$ 层对量化的敏感度$\Omega_i\left(k_i\right)$，而后求解以下优化问题：
$$
\min _{\left\{k_i\right\}_{i=1}^L} \Omega_{\text {sum }}=\sum_{i=1}^L \Omega_i\left(k_i\right) \text { s.t. } \sum_{i=1}^L P_i * k_i \leq S_{\text {target }}
$$
其中 $S_{target}$ 是模型量化的目标大小， $k_i$ 是对应的精度设置。这一优化问题可以用一个动态规划的方法求解，而后绘出帕累托边界，并在边界上选取最适合的点。

这篇工作的缺陷在于，在混合精度部分，帕累托边界并无法在理论上保证取得最优解；论文对模型各层敏感度的独立性也做了假设，认为各层表现是相互独立的。

##### Improving Neural Network Quantization without Retraining using Outlier Channel Splitting (ICML 2019)

神经网络的权重和激活在训练后通常遵循钟形分布，而实际硬件使用线性量化网格。这导致量化过程在处理分布中的异常值时面临挑战。这项工作利用异常通道分割（Outlier Channel Splitting, OCS），通过复制包含异常值的通道并将通道值减半，减小异常值对模型量化的影响。这样做的结果是网络在功能上保持不变，但受影响的异常值被移向分布的中心，其效果如下图：

![image-20231221012024661](C:\Users\asterich\AppData\Roaming\Typora\typora-user-images\image-20231221012024661.png)

具体而言，它对异常值神经元做如下变换：
$$
\begin{aligned}
  & y_ {j}  =  \sum _ {i=1}^ {m}  \mathbf x_ {i}  *  \mathbf W_ {ij} \\
  \Rightarrow & {{y_j=\sum_{i=1}^{m-1}{\mathbf x}_{i}*{\mathbf W}_{i j}+({\mathbf x}_{m}*\frac{\mathbf W_{m j}}{2})+({\mathbf x}_{m}*\frac{\mathbf W_{m j}}{2})}} \\ 
  \text{or}  & {{y_{j}=\sum_{i=1}^{m-1}{\mathbf x}_{i}*\mathbf W_{i j}}+(\frac{{\mathbf x}_{m}}{2}*\mathbf W_{m j}}) + (\frac{{\mathbf x}_{m}}{2}*\mathbf W_{m j})
  \end{aligned}
$$
处理后的网络在功能上等价于之前的网络，但是异常值减半。

OCS 方法最初被应用于 Net2Net ，但是这项工作进一步修改 OCS，使得它能够适应量化方法。具体而言，它将原先的量化方法：
$$
\mathrm{{OCS}}_{\mathrm{naive}}(w)={\binom{w/2}{w/2}}
$$


修改成：
$$
\mathrm{{OCS}}_{\mathrm{QA}}(w)={\binom{(w-0.5)/2}{(w+0.5)/2}}
$$


对于被分割神经元的选取，它采用一种较为简单的方法，即每次都选取最大的权重；对某个具有通道数 $C$ 的层，切分成 $\operatorname{ceil}(r \times C)$ 个通道，其中 $r$ 是一个人为设定的比率。作者尝试过比较智能的方法，但是效果并不比简单方法好。

这项工作在保持模型精度的同时，减小了量化对模型的影响；同时，这项工作相较于Value-aware Quantization for Training and Inference of Neural Networks这篇论文，并不需要特殊的硬件，尽管通道数增加确实引入了额外开销，但是这对于量化来说是可接受的。

### Quantization-aware Training

QAT 大致分两类：在量化意识下微调一个满精度的模型和从头以量化参数训练出模型。无论如何，它将量化过程考虑进来，并试图与模型训练的各阶段进行融合。

相对于PTQ，QAT在模型训练过程中考虑了量化的影响。QAT通过在训练中模拟量化的效果，能够生成对量化操作更为健壮的模型，通常能够获得比PTQ更好的性能，特别是在使用低精度量化时。然而，QAT的挑战在于需要重新微调/训练一个模型，并不像PTA方法那样易用；另外，它通常也需要访问训练数据，这在训练数据较为敏感时并不适用。

目前QAT的研究主要集中在以下几个方面：

- **改进训练策略：** 研究者们正在努力改进QAT的训练策略，以提高量化后模型的准确性。这包括设计更有效的量化方法、优化训练算法，以及结合其他技术（如知识蒸馏）来提升性能。

- **自适应量化：** 自适应量化是一个热门的研究方向，旨在使量化过程更加智能和自适应。这涉及到根据数据分布或网络层的特性动态调整量化参数，以最大程度地保持模型性能。

- **低比特宽度：** 随着对边缘设备和移动端的需求增加，研究者们关注如何在更低的比特宽度下进行训练，以减小模型的存储需求和计算开销。

- **模型结构设计：** 一些研究聚焦于通过改进神经网络的结构来增强其对量化的鲁棒性。这可能包括设计新的网络结构或调整现有结构，使其更适应低比特宽度的训练。

- **跨模态量化：** 随着多模态深度学习应用的增多，研究者们开始关注如何在跨模态场景下进行有效的量化，确保在不同数据类型（图像、文本、语音等）上都能取得好的性能。

以下是几篇比较典型的工作：

##### BinaryConnect: Training Deep Neural Networks with binary weights during propagations (NeurIPS 2015)

这篇论文是模型量化领域早期工作之一，是一篇关于在神经网络训练中使用二值权重的论文。它提出通过在前向和反向传播过程中使用二值权重（+1或-1）来减少神经网络的计算和存储开销，从而在硬件资源有限的情况下实现高效的模型部署。

这篇论文的贡献如下：

- 模型在测试集上的精度（二值weight）大大降低，但是训练效果并不比全精度网络差。论文提出这是因为二值化一定程度上给神经网络带来了噪音，反而能起到正则化的作用，减小过拟合。
- 二值化网络可以把单精度乘法变成位操作，大大减少训练过程的计算量；模型大小也能减小32倍，有利于运行在算力受限的设备上。

这篇论文首先提出两种二值化方法：决定的和随机的。决定的二值化方法就是符号函数，而随机的二值化方法以一定概率产生值：

![image-20231224220859851](C:\Users\asterich\AppData\Roaming\Typora\typora-user-images\image-20231224220859851.png)

而后，论文提出一个采用SGD优化器的训练算法：

![image-20231224215219604](C:\Users\asterich\AppData\Roaming\Typora\typora-user-images\image-20231224215219604.png)

算法的关键在于只对前向/反向传播中的权值进行二值化，而在参数更新时仍然采用浮点型的权值，这是因为符号函数会让梯度消失。

##### Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference (CVPR 2018)

这篇论文也是量化领域的一篇经典论文。它提出了一种有效的量化方法，使得推断过程只使用整数运算，大大提升了在CPU上的推理速度；另外，它提出了一个与量化推理框架协同设计的量化训练框架，旨在最大程度减小真实模型因量化带来的精度损失。这篇论文在MobileNet等小网络上进行了测试，显示这一量化框架让小模型在常见硬件上在保持准确度的同时延迟大大降低。

对于量化的数学模型，这篇论文摒弃了当时较为流行的查表法，而是提出了一个实数与整数间的仿射映射：
$$
r = S(q - Z)
$$
其中 $r$ 指待量化的 float32，$q$ 指量化后的整数， $S$ 代表缩放系数，$Z$ 代表零点。可以看到这个映射跟“基础理论”一节提出的模式很相近。由此可以推出反量化公式：
$$
q=r o u n d(Z+\frac{r}{S})
$$
论文进一步提出纯整数运算的矩阵乘法。矩阵乘法的一般形式如下：
$$
r_{3}^{i,k}=\sum_{j=1}^{N}r_{1}^{i,j}r_{2}^{j,k}
$$
代入量化的仿射映射，得到：
$$
S_{3}(q_{3}^{i,k}-Z_{3})=\sum_{j=1}^{N}S_{1}(q_{1}^{i,j}-Z_{1})S_{2}(q_{2}^{j,k}-Z_{2})
$$
化简后得：
$$
q_{3}^{i,k}=\frac{S_{1}S_{2}}{S_{3}}\sum_{j=1}^{N}(q_{1}^{i,j}-Z_{1})(q_{2}^{j,k}-Z_{2})+Z_{3}
$$
这里，只有系数 $M:=\frac{S_{1}S_{2}}{S_{3}}$  不是整数。经验发现 $M$ 的值总是在 $(0, 1)$ 中，因此将 $M$ 做如下表示：
$$
M=2^{-n}M_0
$$
其中 $M_0$ 是一个整数，这个操作相当于将一个整数位移 $n$ 次得到原来的浮点数 $M$ 。至此，所有运算都能用整数运算来完成。

这篇论文还特别提到了对零点的处理可能导致下溢，并对此进行了特殊的处理，这里不细讲。另外，这篇论文认为偏置bias的作用相当重要，而它们在整个网络中占比不大，因此论文仍然采取int32的存储方法。

对于常见的PTQ方法，这篇论文认为它们存在两个问题：

- 各个通道的权重范围相差很大，这使得范围较小的权重准确度降低；
- 异常值让量化后的模型更不准确。

大模型的抗干扰能力比较强，而小模型受这些问题影响较大，表现会大大降低。因此，这篇论文提出了一种在前向传播阶段模拟量化的方法，旨在减小这些问题的影响。具体而言，它在训练后模型的节点之间插入对称量化节点，这种节点先将输入从浮点量化成整数再转换回去，模拟了量化过程的精度损失。而后，对该模型进行微调。如下图：

![image-20231225010615827](C:\Users\asterich\AppData\Roaming\Typora\typora-user-images\image-20231225010615827.png)

这种方法实际上为QAT建立了一个新范式。

##### Mixed Precision Training (ICLR 2018)

这篇论文提出了一种训练方法，在压缩参数浮点精度的同时保持了模型准确性。很多混合精度训练的方案都基于这篇论文的工作进行。这篇论文与前人方案的不同主要在于：

- 所有前馈、后馈的张量和运算都缩减成半精度；
- 不需要改变超参数；
- 模型量化后的结果相比于float32的baseline没有性能损失。

每一层的训练过程如下图所示：

![image-20231224234520521](C:\Users\asterich\AppData\Roaming\Typora\typora-user-images\image-20231224234520521.png)

这篇论文为了在半精度训练时保持模型精度不损失，使用了以下方法：

- 保留一份float32的权重主备份。这么做的原因是学习率乘梯度的值可能非常小，超过了半精度的最小范围，实验显示，有5%的梯度会如此下溢。如果直接对半精度模型如此更新，就会使模型精度有所损失；更新一份单精度权重能够规避这种问题。

- 损失缩放。我们观察下图：

  ![image-20231224234918069](C:\Users\asterich\AppData\Roaming\Typora\typora-user-images\image-20231224234918069.png)

  可以发现有很大一部分值在半精度下会被裁剪成0。为了解决这个问题，我们可以将这个图的峰向右平移，也就是扩大原半精度数值。

- float16累加的时候按float32累加，存储时再转换回float16。

##### Learning to Quantize Deep Networks by Optimizing Quantization Intervals with Task Loss (CVPR 2019)

这篇论文提出了一个可训练的量化器，该量化器具有参数化的量化区间，可以一同进行剪枝和裁剪操作；它还将这个量化器应用于神经网络的权重和激活，并在端到端场景下与目标模型的权重一同优化。这个量化器在极低位宽下实现了ImageNet上的SOTA，并且在使用异构数据集训练、应用于预训练后的网络时仍然有很好的性能。

这篇论文的量化器分为两部分：转换器（transformer）和离散器（discretizer）。转换器将权重和激活归一化（例如$(0, 1)$或$(-1, 1)$），而离散器将归一化的值变为离散值。常见的转换器是使用tanh或者clip函数，但是本文并未采用这种途径，而是将转换器参数化，使其可以与模型一同训练。这种方法相对于PTQ途径，能够取得更好的量化后模型精度。

可训练量化器的思想在LSQ、PACT方法中也有体现。不同的是，它们所量化的参数不同，LSQ方法将量化缩放程度 $s$ 参数化，而PACT将激活函数ReLU6的阈值参数化。