{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验三：基于卷积神经网络的两位数字比较\n",
    "\n",
    "### 准备工作\n",
    "\n",
    "我们使用Pytorch框架，导入所需要的包，并读入数据。然后，我们从原始数据中取10%，生成本次任务的正例和反例。生成过程具体如下：\n",
    "\n",
    "对于提取出来的数据，先按标签进行分组，然后遍历每个数据，对该数据从标签组中随机生成一对正例和三对反例。代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x7fd838b51bd0>\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x7fd76b240c50>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def create_pairs(data, labels):\n",
    "    digit_indices = [np.where(labels == i)[0] for i in range(10)]\n",
    "    # print(digit_indices)\n",
    "    pairs = []\n",
    "    pair_labels = []\n",
    "\n",
    "    for idx in range(len(data)):\n",
    "        x1 = data[idx]\n",
    "        label1 = labels[idx]\n",
    "        for _ in range(4):\n",
    "            x2 = data[np.random.choice(digit_indices[label1])]\n",
    "            pairs.append([x1, x2])\n",
    "            pair_labels.append(1)\n",
    "\n",
    "        generator = np.random.Generator(np.random.PCG64())\n",
    "        for _ in range(4):\n",
    "            label2 = generator.choice(10)\n",
    "            while label2 == label1:\n",
    "                label2 = generator.choice(10)\n",
    "            x2 = data[generator.choice(digit_indices[label2])]\n",
    "            pairs.append([x1, x2])\n",
    "            pair_labels.append(0)\n",
    "\n",
    "    return np.array(pairs), np.array(pair_labels)\n",
    "\n",
    "\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "subset_indices_train = np.random.choice(len(train_data), len(train_data) // 10, replace=False)\n",
    "subset_indices_test = np.random.choice(len(test_data), len(test_data) // 10, replace=False)\n",
    "\n",
    "train_data = torch.utils.data.Subset(train_data, subset_indices_train)\n",
    "test_data = torch.utils.data.Subset(test_data, subset_indices_test)\n",
    "\n",
    "def extract_data_and_labels(dataset):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for image, label in dataset:\n",
    "        data.append(image.numpy()) \n",
    "        labels.append(label)  \n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "\n",
    "train_data_np, train_labels_np = extract_data_and_labels(train_data)\n",
    "test_data_np, test_labels_np = extract_data_and_labels(test_data)\n",
    "\n",
    "train_pairs, train_labels = create_pairs(train_data_np, train_labels_np)\n",
    "test_pairs, test_labels = create_pairs(test_data_np, test_labels_np)\n",
    "\n",
    "train_pairs = torch.from_numpy(train_pairs).float()\n",
    "train_labels = torch.from_numpy(train_labels).float()\n",
    "test_pairs = torch.from_numpy(test_pairs).float()\n",
    "test_labels = torch.from_numpy(test_labels).float()\n",
    "\n",
    "train_pairs = TensorDataset(train_pairs, train_labels)\n",
    "test_pairs = TensorDataset(test_pairs, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_pairs, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_pairs, batch_size=128, shuffle=False)\n",
    "print(train_loader.dataset)\n",
    "print(test_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义网络模型\n",
    "\n",
    "双塔模型（Siamese Network）是一种深度神经网络结构，用于解决对比度学习和相似度度量问题。\n",
    "\n",
    "双塔模型之所以被称为\"双塔\"，是因为它包含两个相同的神经网络结构，这两个网络被称为\"塔\"，并且共享相同的权重。它非常适合此次的图片对比任务，因此本次实验采用双塔模型，由一个 ResNet18 作为基础模型，并在最后将双塔的输出连接起来，输入一个全连接层中，由全连接层最后判等。最后一步的好处是不用编写一个复杂的 ContrastiveLoss 损失函数。\n",
    "\n",
    "需要注意的是，原来的 ResNet18 需要经过修改，将第一层卷积层改为单通道，并去掉最后一层全连接层。\n",
    "\n",
    "模型具体的定义如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        self.resnet = torchvision.models.resnet18(weights=None)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.fc_in_features = self.resnet.fc.in_features\n",
    "        self.resnet = nn.Sequential(*(list(self.resnet.children())[:-1]))\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(128 * 2, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(self.fc_in_features * 2, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "            \n",
    "\n",
    "    def forward_one(self, x : torch.Tensor):\n",
    "        x = self.resnet(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.forward_one(x1)\n",
    "        out2 = self.forward_one(x2)\n",
    "\n",
    "        output = torch.cat((out1, out2), dim=1)\n",
    "        output = self.fc2(output)\n",
    "        output = torch.sigmoid(output)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "\n",
    "model = SiameseNetwork().cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义训练和评估函数\n",
    "\n",
    "训练和评估函数会在某个模型训练的每一轮 epoch 时一并进行评估，并记录该轮次的训练损失、测试损失和测试准确率。\n",
    "\n",
    "这里采用交叉熵损失函数和 Adam 优化器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "        # print(batch_idx, images.shape, targets.shape)\n",
    "        images_1 = images[:, 0, :, :].cuda()\n",
    "        images_2 = images[:, 1, :, :].cuda()\n",
    "        targets = targets.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        # print(images_1.shape, images_2.shape)\n",
    "        outputs = model(images_1, images_2).squeeze()\n",
    "        loss = criterion(outputs, targets)\n",
    "        train_loss += loss\n",
    "        loss.backward()\n",
    "        pred = torch.round(outputs)\n",
    "        correct += pred.eq(targets.view_as(pred)).sum().item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(images_1), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_losses.append(train_loss.item())\n",
    "    train_acc.append(100. * correct / len(train_loader.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, targets) in enumerate(test_loader):\n",
    "            images_1 = images[:, 0, :, :].cuda()\n",
    "            images_2 = images[:, 1, :, :].cuda()\n",
    "            targets = targets.cuda()\n",
    "            outputs = model(images_1, images_2).squeeze()\n",
    "            loss = criterion(outputs, targets).item()\n",
    "            test_loss += loss\n",
    "            pred = torch.round(outputs)\n",
    "            correct += pred.eq(targets.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    test_acc.append(100. * correct / len(test_loader.dataset))\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/48000 (0%)]\tLoss: 0.693608\n",
      "Train Epoch: 0 [1280/48000 (3%)]\tLoss: 0.690857\n",
      "Train Epoch: 0 [2560/48000 (5%)]\tLoss: 0.691190\n",
      "Train Epoch: 0 [3840/48000 (8%)]\tLoss: 0.671510\n",
      "Train Epoch: 0 [5120/48000 (11%)]\tLoss: 0.688707\n",
      "Train Epoch: 0 [6400/48000 (13%)]\tLoss: 0.663547\n",
      "Train Epoch: 0 [7680/48000 (16%)]\tLoss: 0.651743\n",
      "Train Epoch: 0 [8960/48000 (19%)]\tLoss: 0.598765\n",
      "Train Epoch: 0 [10240/48000 (21%)]\tLoss: 0.591077\n",
      "Train Epoch: 0 [11520/48000 (24%)]\tLoss: 0.514157\n",
      "Train Epoch: 0 [12800/48000 (27%)]\tLoss: 0.512945\n",
      "Train Epoch: 0 [14080/48000 (29%)]\tLoss: 0.413235\n",
      "Train Epoch: 0 [15360/48000 (32%)]\tLoss: 0.347866\n",
      "Train Epoch: 0 [16640/48000 (35%)]\tLoss: 0.429629\n",
      "Train Epoch: 0 [17920/48000 (37%)]\tLoss: 0.294561\n",
      "Train Epoch: 0 [19200/48000 (40%)]\tLoss: 0.433141\n",
      "Train Epoch: 0 [20480/48000 (43%)]\tLoss: 0.288964\n",
      "Train Epoch: 0 [21760/48000 (45%)]\tLoss: 0.294095\n",
      "Train Epoch: 0 [23040/48000 (48%)]\tLoss: 0.306177\n",
      "Train Epoch: 0 [24320/48000 (51%)]\tLoss: 0.310019\n",
      "Train Epoch: 0 [25600/48000 (53%)]\tLoss: 0.252143\n",
      "Train Epoch: 0 [26880/48000 (56%)]\tLoss: 0.191547\n",
      "Train Epoch: 0 [28160/48000 (59%)]\tLoss: 0.253695\n",
      "Train Epoch: 0 [29440/48000 (61%)]\tLoss: 0.158728\n",
      "Train Epoch: 0 [30720/48000 (64%)]\tLoss: 0.253030\n",
      "Train Epoch: 0 [32000/48000 (67%)]\tLoss: 0.199176\n",
      "Train Epoch: 0 [33280/48000 (69%)]\tLoss: 0.172032\n",
      "Train Epoch: 0 [34560/48000 (72%)]\tLoss: 0.156366\n",
      "Train Epoch: 0 [35840/48000 (75%)]\tLoss: 0.165349\n",
      "Train Epoch: 0 [37120/48000 (77%)]\tLoss: 0.226765\n",
      "Train Epoch: 0 [38400/48000 (80%)]\tLoss: 0.163390\n",
      "Train Epoch: 0 [39680/48000 (83%)]\tLoss: 0.218265\n",
      "Train Epoch: 0 [40960/48000 (85%)]\tLoss: 0.169781\n",
      "Train Epoch: 0 [42240/48000 (88%)]\tLoss: 0.132593\n",
      "Train Epoch: 0 [43520/48000 (91%)]\tLoss: 0.089599\n",
      "Train Epoch: 0 [44800/48000 (93%)]\tLoss: 0.095779\n",
      "Train Epoch: 0 [46080/48000 (96%)]\tLoss: 0.114375\n",
      "Train Epoch: 0 [47360/48000 (99%)]\tLoss: 0.067560\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 7553/8000 (94%)\n",
      "Train Epoch: 1 [0/48000 (0%)]\tLoss: 0.070889\n",
      "Train Epoch: 1 [1280/48000 (3%)]\tLoss: 0.075453\n",
      "Train Epoch: 1 [2560/48000 (5%)]\tLoss: 0.080032\n",
      "Train Epoch: 1 [3840/48000 (8%)]\tLoss: 0.077221\n",
      "Train Epoch: 1 [5120/48000 (11%)]\tLoss: 0.058659\n",
      "Train Epoch: 1 [6400/48000 (13%)]\tLoss: 0.051734\n",
      "Train Epoch: 1 [7680/48000 (16%)]\tLoss: 0.058827\n",
      "Train Epoch: 1 [8960/48000 (19%)]\tLoss: 0.028270\n",
      "Train Epoch: 1 [10240/48000 (21%)]\tLoss: 0.017812\n",
      "Train Epoch: 1 [11520/48000 (24%)]\tLoss: 0.039853\n",
      "Train Epoch: 1 [12800/48000 (27%)]\tLoss: 0.024170\n",
      "Train Epoch: 1 [14080/48000 (29%)]\tLoss: 0.082020\n",
      "Train Epoch: 1 [15360/48000 (32%)]\tLoss: 0.050414\n",
      "Train Epoch: 1 [16640/48000 (35%)]\tLoss: 0.128002\n",
      "Train Epoch: 1 [17920/48000 (37%)]\tLoss: 0.042381\n",
      "Train Epoch: 1 [19200/48000 (40%)]\tLoss: 0.063055\n",
      "Train Epoch: 1 [20480/48000 (43%)]\tLoss: 0.019925\n",
      "Train Epoch: 1 [21760/48000 (45%)]\tLoss: 0.026334\n",
      "Train Epoch: 1 [23040/48000 (48%)]\tLoss: 0.019013\n",
      "Train Epoch: 1 [24320/48000 (51%)]\tLoss: 0.010226\n",
      "Train Epoch: 1 [25600/48000 (53%)]\tLoss: 0.014565\n",
      "Train Epoch: 1 [26880/48000 (56%)]\tLoss: 0.051175\n",
      "Train Epoch: 1 [28160/48000 (59%)]\tLoss: 0.015969\n",
      "Train Epoch: 1 [29440/48000 (61%)]\tLoss: 0.018886\n",
      "Train Epoch: 1 [30720/48000 (64%)]\tLoss: 0.040689\n",
      "Train Epoch: 1 [32000/48000 (67%)]\tLoss: 0.017885\n",
      "Train Epoch: 1 [33280/48000 (69%)]\tLoss: 0.028411\n",
      "Train Epoch: 1 [34560/48000 (72%)]\tLoss: 0.065979\n",
      "Train Epoch: 1 [35840/48000 (75%)]\tLoss: 0.006061\n",
      "Train Epoch: 1 [37120/48000 (77%)]\tLoss: 0.007300\n",
      "Train Epoch: 1 [38400/48000 (80%)]\tLoss: 0.003902\n",
      "Train Epoch: 1 [39680/48000 (83%)]\tLoss: 0.003372\n",
      "Train Epoch: 1 [40960/48000 (85%)]\tLoss: 0.008698\n",
      "Train Epoch: 1 [42240/48000 (88%)]\tLoss: 0.003726\n",
      "Train Epoch: 1 [43520/48000 (91%)]\tLoss: 0.004252\n",
      "Train Epoch: 1 [44800/48000 (93%)]\tLoss: 0.010177\n",
      "Train Epoch: 1 [46080/48000 (96%)]\tLoss: 0.007733\n",
      "Train Epoch: 1 [47360/48000 (99%)]\tLoss: 0.016439\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 7689/8000 (96%)\n",
      "Train Epoch: 2 [0/48000 (0%)]\tLoss: 0.028531\n",
      "Train Epoch: 2 [1280/48000 (3%)]\tLoss: 0.009689\n",
      "Train Epoch: 2 [2560/48000 (5%)]\tLoss: 0.003851\n",
      "Train Epoch: 2 [3840/48000 (8%)]\tLoss: 0.018068\n",
      "Train Epoch: 2 [5120/48000 (11%)]\tLoss: 0.003732\n",
      "Train Epoch: 2 [6400/48000 (13%)]\tLoss: 0.003063\n",
      "Train Epoch: 2 [7680/48000 (16%)]\tLoss: 0.001743\n",
      "Train Epoch: 2 [8960/48000 (19%)]\tLoss: 0.009161\n",
      "Train Epoch: 2 [10240/48000 (21%)]\tLoss: 0.013506\n",
      "Train Epoch: 2 [11520/48000 (24%)]\tLoss: 0.001806\n",
      "Train Epoch: 2 [12800/48000 (27%)]\tLoss: 0.020900\n",
      "Train Epoch: 2 [14080/48000 (29%)]\tLoss: 0.002265\n",
      "Train Epoch: 2 [15360/48000 (32%)]\tLoss: 0.011936\n",
      "Train Epoch: 2 [16640/48000 (35%)]\tLoss: 0.007625\n",
      "Train Epoch: 2 [17920/48000 (37%)]\tLoss: 0.015992\n",
      "Train Epoch: 2 [19200/48000 (40%)]\tLoss: 0.004369\n",
      "Train Epoch: 2 [20480/48000 (43%)]\tLoss: 0.002391\n",
      "Train Epoch: 2 [21760/48000 (45%)]\tLoss: 0.004982\n",
      "Train Epoch: 2 [23040/48000 (48%)]\tLoss: 0.001050\n",
      "Train Epoch: 2 [24320/48000 (51%)]\tLoss: 0.001244\n",
      "Train Epoch: 2 [25600/48000 (53%)]\tLoss: 0.006432\n",
      "Train Epoch: 2 [26880/48000 (56%)]\tLoss: 0.020361\n",
      "Train Epoch: 2 [28160/48000 (59%)]\tLoss: 0.009079\n",
      "Train Epoch: 2 [29440/48000 (61%)]\tLoss: 0.016560\n",
      "Train Epoch: 2 [30720/48000 (64%)]\tLoss: 0.133107\n",
      "Train Epoch: 2 [32000/48000 (67%)]\tLoss: 0.006986\n",
      "Train Epoch: 2 [33280/48000 (69%)]\tLoss: 0.002289\n",
      "Train Epoch: 2 [34560/48000 (72%)]\tLoss: 0.013122\n",
      "Train Epoch: 2 [35840/48000 (75%)]\tLoss: 0.002030\n",
      "Train Epoch: 2 [37120/48000 (77%)]\tLoss: 0.003437\n",
      "Train Epoch: 2 [38400/48000 (80%)]\tLoss: 0.003005\n",
      "Train Epoch: 2 [39680/48000 (83%)]\tLoss: 0.011375\n",
      "Train Epoch: 2 [40960/48000 (85%)]\tLoss: 0.001993\n",
      "Train Epoch: 2 [42240/48000 (88%)]\tLoss: 0.002296\n",
      "Train Epoch: 2 [43520/48000 (91%)]\tLoss: 0.003753\n",
      "Train Epoch: 2 [44800/48000 (93%)]\tLoss: 0.001107\n",
      "Train Epoch: 2 [46080/48000 (96%)]\tLoss: 0.001210\n",
      "Train Epoch: 2 [47360/48000 (99%)]\tLoss: 0.013529\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 7704/8000 (96%)\n",
      "Train Epoch: 3 [0/48000 (0%)]\tLoss: 0.003302\n",
      "Train Epoch: 3 [1280/48000 (3%)]\tLoss: 0.003830\n",
      "Train Epoch: 3 [2560/48000 (5%)]\tLoss: 0.001892\n",
      "Train Epoch: 3 [3840/48000 (8%)]\tLoss: 0.001929\n",
      "Train Epoch: 3 [5120/48000 (11%)]\tLoss: 0.009091\n",
      "Train Epoch: 3 [6400/48000 (13%)]\tLoss: 0.018009\n",
      "Train Epoch: 3 [7680/48000 (16%)]\tLoss: 0.001314\n",
      "Train Epoch: 3 [8960/48000 (19%)]\tLoss: 0.000920\n",
      "Train Epoch: 3 [10240/48000 (21%)]\tLoss: 0.036448\n",
      "Train Epoch: 3 [11520/48000 (24%)]\tLoss: 0.001314\n",
      "Train Epoch: 3 [12800/48000 (27%)]\tLoss: 0.000477\n",
      "Train Epoch: 3 [14080/48000 (29%)]\tLoss: 0.006729\n",
      "Train Epoch: 3 [15360/48000 (32%)]\tLoss: 0.009041\n",
      "Train Epoch: 3 [16640/48000 (35%)]\tLoss: 0.001698\n",
      "Train Epoch: 3 [17920/48000 (37%)]\tLoss: 0.000901\n",
      "Train Epoch: 3 [19200/48000 (40%)]\tLoss: 0.003984\n",
      "Train Epoch: 3 [20480/48000 (43%)]\tLoss: 0.002763\n",
      "Train Epoch: 3 [21760/48000 (45%)]\tLoss: 0.003648\n",
      "Train Epoch: 3 [23040/48000 (48%)]\tLoss: 0.005472\n",
      "Train Epoch: 3 [24320/48000 (51%)]\tLoss: 0.015120\n",
      "Train Epoch: 3 [25600/48000 (53%)]\tLoss: 0.001478\n",
      "Train Epoch: 3 [26880/48000 (56%)]\tLoss: 0.002429\n",
      "Train Epoch: 3 [28160/48000 (59%)]\tLoss: 0.005637\n",
      "Train Epoch: 3 [29440/48000 (61%)]\tLoss: 0.005137\n",
      "Train Epoch: 3 [30720/48000 (64%)]\tLoss: 0.017822\n",
      "Train Epoch: 3 [32000/48000 (67%)]\tLoss: 0.002637\n",
      "Train Epoch: 3 [33280/48000 (69%)]\tLoss: 0.001176\n",
      "Train Epoch: 3 [34560/48000 (72%)]\tLoss: 0.011077\n",
      "Train Epoch: 3 [35840/48000 (75%)]\tLoss: 0.001193\n",
      "Train Epoch: 3 [37120/48000 (77%)]\tLoss: 0.001241\n",
      "Train Epoch: 3 [38400/48000 (80%)]\tLoss: 0.002164\n",
      "Train Epoch: 3 [39680/48000 (83%)]\tLoss: 0.007674\n",
      "Train Epoch: 3 [40960/48000 (85%)]\tLoss: 0.003968\n",
      "Train Epoch: 3 [42240/48000 (88%)]\tLoss: 0.000655\n",
      "Train Epoch: 3 [43520/48000 (91%)]\tLoss: 0.000692\n",
      "Train Epoch: 3 [44800/48000 (93%)]\tLoss: 0.001022\n",
      "Train Epoch: 3 [46080/48000 (96%)]\tLoss: 0.000441\n",
      "Train Epoch: 3 [47360/48000 (99%)]\tLoss: 0.000892\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 7725/8000 (97%)\n",
      "Train Epoch: 4 [0/48000 (0%)]\tLoss: 0.003004\n",
      "Train Epoch: 4 [1280/48000 (3%)]\tLoss: 0.000399\n",
      "Train Epoch: 4 [2560/48000 (5%)]\tLoss: 0.000419\n",
      "Train Epoch: 4 [3840/48000 (8%)]\tLoss: 0.000451\n",
      "Train Epoch: 4 [5120/48000 (11%)]\tLoss: 0.008091\n",
      "Train Epoch: 4 [6400/48000 (13%)]\tLoss: 0.004717\n",
      "Train Epoch: 4 [7680/48000 (16%)]\tLoss: 0.000583\n",
      "Train Epoch: 4 [8960/48000 (19%)]\tLoss: 0.001406\n",
      "Train Epoch: 4 [10240/48000 (21%)]\tLoss: 0.001217\n",
      "Train Epoch: 4 [11520/48000 (24%)]\tLoss: 0.012944\n",
      "Train Epoch: 4 [12800/48000 (27%)]\tLoss: 0.004183\n",
      "Train Epoch: 4 [14080/48000 (29%)]\tLoss: 0.003656\n",
      "Train Epoch: 4 [15360/48000 (32%)]\tLoss: 0.004471\n",
      "Train Epoch: 4 [16640/48000 (35%)]\tLoss: 0.003206\n",
      "Train Epoch: 4 [17920/48000 (37%)]\tLoss: 0.137011\n",
      "Train Epoch: 4 [19200/48000 (40%)]\tLoss: 0.000730\n",
      "Train Epoch: 4 [20480/48000 (43%)]\tLoss: 0.001912\n",
      "Train Epoch: 4 [21760/48000 (45%)]\tLoss: 0.000658\n",
      "Train Epoch: 4 [23040/48000 (48%)]\tLoss: 0.003399\n",
      "Train Epoch: 4 [24320/48000 (51%)]\tLoss: 0.000257\n",
      "Train Epoch: 4 [25600/48000 (53%)]\tLoss: 0.007315\n",
      "Train Epoch: 4 [26880/48000 (56%)]\tLoss: 0.000720\n",
      "Train Epoch: 4 [28160/48000 (59%)]\tLoss: 0.001223\n",
      "Train Epoch: 4 [29440/48000 (61%)]\tLoss: 0.001244\n",
      "Train Epoch: 4 [30720/48000 (64%)]\tLoss: 0.001878\n",
      "Train Epoch: 4 [32000/48000 (67%)]\tLoss: 0.000890\n",
      "Train Epoch: 4 [33280/48000 (69%)]\tLoss: 0.021189\n",
      "Train Epoch: 4 [34560/48000 (72%)]\tLoss: 0.041659\n",
      "Train Epoch: 4 [35840/48000 (75%)]\tLoss: 0.014820\n",
      "Train Epoch: 4 [37120/48000 (77%)]\tLoss: 0.002137\n",
      "Train Epoch: 4 [38400/48000 (80%)]\tLoss: 0.002652\n",
      "Train Epoch: 4 [39680/48000 (83%)]\tLoss: 0.011877\n",
      "Train Epoch: 4 [40960/48000 (85%)]\tLoss: 0.001296\n",
      "Train Epoch: 4 [42240/48000 (88%)]\tLoss: 0.001667\n",
      "Train Epoch: 4 [43520/48000 (91%)]\tLoss: 0.000730\n",
      "Train Epoch: 4 [44800/48000 (93%)]\tLoss: 0.001872\n",
      "Train Epoch: 4 [46080/48000 (96%)]\tLoss: 0.000898\n",
      "Train Epoch: 4 [47360/48000 (99%)]\tLoss: 0.009730\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 7686/8000 (96%)\n",
      "Train Epoch: 5 [0/48000 (0%)]\tLoss: 0.000906\n",
      "Train Epoch: 5 [1280/48000 (3%)]\tLoss: 0.002466\n",
      "Train Epoch: 5 [2560/48000 (5%)]\tLoss: 0.000810\n",
      "Train Epoch: 5 [3840/48000 (8%)]\tLoss: 0.000298\n",
      "Train Epoch: 5 [5120/48000 (11%)]\tLoss: 0.001388\n",
      "Train Epoch: 5 [6400/48000 (13%)]\tLoss: 0.001136\n",
      "Train Epoch: 5 [7680/48000 (16%)]\tLoss: 0.000382\n",
      "Train Epoch: 5 [8960/48000 (19%)]\tLoss: 0.001148\n",
      "Train Epoch: 5 [10240/48000 (21%)]\tLoss: 0.003513\n",
      "Train Epoch: 5 [11520/48000 (24%)]\tLoss: 0.005411\n",
      "Train Epoch: 5 [12800/48000 (27%)]\tLoss: 0.004121\n",
      "Train Epoch: 5 [14080/48000 (29%)]\tLoss: 0.011989\n",
      "Train Epoch: 5 [15360/48000 (32%)]\tLoss: 0.001160\n",
      "Train Epoch: 5 [16640/48000 (35%)]\tLoss: 0.003860\n",
      "Train Epoch: 5 [17920/48000 (37%)]\tLoss: 0.001483\n",
      "Train Epoch: 5 [19200/48000 (40%)]\tLoss: 0.002084\n",
      "Train Epoch: 5 [20480/48000 (43%)]\tLoss: 0.002321\n",
      "Train Epoch: 5 [21760/48000 (45%)]\tLoss: 0.003939\n",
      "Train Epoch: 5 [23040/48000 (48%)]\tLoss: 0.001158\n",
      "Train Epoch: 5 [24320/48000 (51%)]\tLoss: 0.001844\n",
      "Train Epoch: 5 [25600/48000 (53%)]\tLoss: 0.018153\n",
      "Train Epoch: 5 [26880/48000 (56%)]\tLoss: 0.001082\n",
      "Train Epoch: 5 [28160/48000 (59%)]\tLoss: 0.002061\n",
      "Train Epoch: 5 [29440/48000 (61%)]\tLoss: 0.001643\n",
      "Train Epoch: 5 [30720/48000 (64%)]\tLoss: 0.000618\n",
      "Train Epoch: 5 [32000/48000 (67%)]\tLoss: 0.001080\n",
      "Train Epoch: 5 [33280/48000 (69%)]\tLoss: 0.000219\n",
      "Train Epoch: 5 [34560/48000 (72%)]\tLoss: 0.000341\n",
      "Train Epoch: 5 [35840/48000 (75%)]\tLoss: 0.000279\n",
      "Train Epoch: 5 [37120/48000 (77%)]\tLoss: 0.000586\n",
      "Train Epoch: 5 [38400/48000 (80%)]\tLoss: 0.001062\n",
      "Train Epoch: 5 [39680/48000 (83%)]\tLoss: 0.001510\n",
      "Train Epoch: 5 [40960/48000 (85%)]\tLoss: 0.002061\n",
      "Train Epoch: 5 [42240/48000 (88%)]\tLoss: 0.002283\n",
      "Train Epoch: 5 [43520/48000 (91%)]\tLoss: 0.000464\n",
      "Train Epoch: 5 [44800/48000 (93%)]\tLoss: 0.029850\n",
      "Train Epoch: 5 [46080/48000 (96%)]\tLoss: 0.002121\n",
      "Train Epoch: 5 [47360/48000 (99%)]\tLoss: 0.000321\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 7727/8000 (97%)\n",
      "Train Epoch: 6 [0/48000 (0%)]\tLoss: 0.021138\n",
      "Train Epoch: 6 [1280/48000 (3%)]\tLoss: 0.000461\n",
      "Train Epoch: 6 [2560/48000 (5%)]\tLoss: 0.009725\n",
      "Train Epoch: 6 [3840/48000 (8%)]\tLoss: 0.000720\n",
      "Train Epoch: 6 [5120/48000 (11%)]\tLoss: 0.000410\n",
      "Train Epoch: 6 [6400/48000 (13%)]\tLoss: 0.000770\n",
      "Train Epoch: 6 [7680/48000 (16%)]\tLoss: 0.002459\n",
      "Train Epoch: 6 [8960/48000 (19%)]\tLoss: 0.006676\n",
      "Train Epoch: 6 [10240/48000 (21%)]\tLoss: 0.001650\n",
      "Train Epoch: 6 [11520/48000 (24%)]\tLoss: 0.040397\n",
      "Train Epoch: 6 [12800/48000 (27%)]\tLoss: 0.001734\n",
      "Train Epoch: 6 [14080/48000 (29%)]\tLoss: 0.002475\n",
      "Train Epoch: 6 [15360/48000 (32%)]\tLoss: 0.002813\n",
      "Train Epoch: 6 [16640/48000 (35%)]\tLoss: 0.006428\n",
      "Train Epoch: 6 [17920/48000 (37%)]\tLoss: 0.001559\n",
      "Train Epoch: 6 [19200/48000 (40%)]\tLoss: 0.022644\n",
      "Train Epoch: 6 [20480/48000 (43%)]\tLoss: 0.000652\n",
      "Train Epoch: 6 [21760/48000 (45%)]\tLoss: 0.000642\n",
      "Train Epoch: 6 [23040/48000 (48%)]\tLoss: 0.000816\n",
      "Train Epoch: 6 [24320/48000 (51%)]\tLoss: 0.000415\n",
      "Train Epoch: 6 [25600/48000 (53%)]\tLoss: 0.000639\n",
      "Train Epoch: 6 [26880/48000 (56%)]\tLoss: 0.001927\n",
      "Train Epoch: 6 [28160/48000 (59%)]\tLoss: 0.000327\n",
      "Train Epoch: 6 [29440/48000 (61%)]\tLoss: 0.000390\n",
      "Train Epoch: 6 [30720/48000 (64%)]\tLoss: 0.001345\n",
      "Train Epoch: 6 [32000/48000 (67%)]\tLoss: 0.008903\n",
      "Train Epoch: 6 [33280/48000 (69%)]\tLoss: 0.000276\n",
      "Train Epoch: 6 [34560/48000 (72%)]\tLoss: 0.001192\n",
      "Train Epoch: 6 [35840/48000 (75%)]\tLoss: 0.000442\n",
      "Train Epoch: 6 [37120/48000 (77%)]\tLoss: 0.000682\n",
      "Train Epoch: 6 [38400/48000 (80%)]\tLoss: 0.001222\n",
      "Train Epoch: 6 [39680/48000 (83%)]\tLoss: 0.000212\n",
      "Train Epoch: 6 [40960/48000 (85%)]\tLoss: 0.000299\n",
      "Train Epoch: 6 [42240/48000 (88%)]\tLoss: 0.000262\n",
      "Train Epoch: 6 [43520/48000 (91%)]\tLoss: 0.000201\n",
      "Train Epoch: 6 [44800/48000 (93%)]\tLoss: 0.000165\n",
      "Train Epoch: 6 [46080/48000 (96%)]\tLoss: 0.002374\n",
      "Train Epoch: 6 [47360/48000 (99%)]\tLoss: 0.000608\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 7797/8000 (97%)\n",
      "Train Epoch: 7 [0/48000 (0%)]\tLoss: 0.002517\n",
      "Train Epoch: 7 [1280/48000 (3%)]\tLoss: 0.022260\n",
      "Train Epoch: 7 [2560/48000 (5%)]\tLoss: 0.000217\n",
      "Train Epoch: 7 [3840/48000 (8%)]\tLoss: 0.009092\n",
      "Train Epoch: 7 [5120/48000 (11%)]\tLoss: 0.000797\n",
      "Train Epoch: 7 [6400/48000 (13%)]\tLoss: 0.000352\n",
      "Train Epoch: 7 [7680/48000 (16%)]\tLoss: 0.000519\n",
      "Train Epoch: 7 [8960/48000 (19%)]\tLoss: 0.001527\n",
      "Train Epoch: 7 [10240/48000 (21%)]\tLoss: 0.006311\n",
      "Train Epoch: 7 [11520/48000 (24%)]\tLoss: 0.000532\n",
      "Train Epoch: 7 [12800/48000 (27%)]\tLoss: 0.005106\n",
      "Train Epoch: 7 [14080/48000 (29%)]\tLoss: 0.000191\n",
      "Train Epoch: 7 [15360/48000 (32%)]\tLoss: 0.000659\n",
      "Train Epoch: 7 [16640/48000 (35%)]\tLoss: 0.000478\n",
      "Train Epoch: 7 [17920/48000 (37%)]\tLoss: 0.001046\n",
      "Train Epoch: 7 [19200/48000 (40%)]\tLoss: 0.000626\n",
      "Train Epoch: 7 [20480/48000 (43%)]\tLoss: 0.005390\n",
      "Train Epoch: 7 [21760/48000 (45%)]\tLoss: 0.000216\n",
      "Train Epoch: 7 [23040/48000 (48%)]\tLoss: 0.000674\n",
      "Train Epoch: 7 [24320/48000 (51%)]\tLoss: 0.000233\n",
      "Train Epoch: 7 [25600/48000 (53%)]\tLoss: 0.000731\n",
      "Train Epoch: 7 [26880/48000 (56%)]\tLoss: 0.000731\n",
      "Train Epoch: 7 [28160/48000 (59%)]\tLoss: 0.000150\n",
      "Train Epoch: 7 [29440/48000 (61%)]\tLoss: 0.000615\n",
      "Train Epoch: 7 [30720/48000 (64%)]\tLoss: 0.000186\n",
      "Train Epoch: 7 [32000/48000 (67%)]\tLoss: 0.000256\n",
      "Train Epoch: 7 [33280/48000 (69%)]\tLoss: 0.000113\n",
      "Train Epoch: 7 [34560/48000 (72%)]\tLoss: 0.000975\n",
      "Train Epoch: 7 [35840/48000 (75%)]\tLoss: 0.001308\n",
      "Train Epoch: 7 [37120/48000 (77%)]\tLoss: 0.000203\n",
      "Train Epoch: 7 [38400/48000 (80%)]\tLoss: 0.000191\n",
      "Train Epoch: 7 [39680/48000 (83%)]\tLoss: 0.000106\n",
      "Train Epoch: 7 [40960/48000 (85%)]\tLoss: 0.000191\n",
      "Train Epoch: 7 [42240/48000 (88%)]\tLoss: 0.000092\n",
      "Train Epoch: 7 [43520/48000 (91%)]\tLoss: 0.000082\n",
      "Train Epoch: 7 [44800/48000 (93%)]\tLoss: 0.000072\n",
      "Train Epoch: 7 [46080/48000 (96%)]\tLoss: 0.000387\n",
      "Train Epoch: 7 [47360/48000 (99%)]\tLoss: 0.000423\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 7822/8000 (98%)\n",
      "Train Epoch: 8 [0/48000 (0%)]\tLoss: 0.000721\n",
      "Train Epoch: 8 [1280/48000 (3%)]\tLoss: 0.000091\n",
      "Train Epoch: 8 [2560/48000 (5%)]\tLoss: 0.000138\n",
      "Train Epoch: 8 [3840/48000 (8%)]\tLoss: 0.000115\n",
      "Train Epoch: 8 [5120/48000 (11%)]\tLoss: 0.000119\n",
      "Train Epoch: 8 [6400/48000 (13%)]\tLoss: 0.000235\n",
      "Train Epoch: 8 [7680/48000 (16%)]\tLoss: 0.000090\n",
      "Train Epoch: 8 [8960/48000 (19%)]\tLoss: 0.000264\n",
      "Train Epoch: 8 [10240/48000 (21%)]\tLoss: 0.000070\n",
      "Train Epoch: 8 [11520/48000 (24%)]\tLoss: 0.000201\n",
      "Train Epoch: 8 [12800/48000 (27%)]\tLoss: 0.001031\n",
      "Train Epoch: 8 [14080/48000 (29%)]\tLoss: 0.000115\n",
      "Train Epoch: 8 [15360/48000 (32%)]\tLoss: 0.000141\n",
      "Train Epoch: 8 [16640/48000 (35%)]\tLoss: 0.000082\n",
      "Train Epoch: 8 [17920/48000 (37%)]\tLoss: 0.000188\n",
      "Train Epoch: 8 [19200/48000 (40%)]\tLoss: 0.000126\n",
      "Train Epoch: 8 [20480/48000 (43%)]\tLoss: 0.000125\n",
      "Train Epoch: 8 [21760/48000 (45%)]\tLoss: 0.000077\n",
      "Train Epoch: 8 [23040/48000 (48%)]\tLoss: 0.000058\n",
      "Train Epoch: 8 [24320/48000 (51%)]\tLoss: 0.000063\n",
      "Train Epoch: 8 [25600/48000 (53%)]\tLoss: 0.000130\n",
      "Train Epoch: 8 [26880/48000 (56%)]\tLoss: 0.000122\n",
      "Train Epoch: 8 [28160/48000 (59%)]\tLoss: 0.000189\n",
      "Train Epoch: 8 [29440/48000 (61%)]\tLoss: 0.000060\n",
      "Train Epoch: 8 [30720/48000 (64%)]\tLoss: 0.000042\n",
      "Train Epoch: 8 [32000/48000 (67%)]\tLoss: 0.000042\n",
      "Train Epoch: 8 [33280/48000 (69%)]\tLoss: 0.000280\n",
      "Train Epoch: 8 [34560/48000 (72%)]\tLoss: 0.000058\n",
      "Train Epoch: 8 [35840/48000 (75%)]\tLoss: 0.000045\n",
      "Train Epoch: 8 [37120/48000 (77%)]\tLoss: 0.000090\n",
      "Train Epoch: 8 [38400/48000 (80%)]\tLoss: 0.000208\n",
      "Train Epoch: 8 [39680/48000 (83%)]\tLoss: 0.000769\n",
      "Train Epoch: 8 [40960/48000 (85%)]\tLoss: 0.000066\n",
      "Train Epoch: 8 [42240/48000 (88%)]\tLoss: 0.000141\n",
      "Train Epoch: 8 [43520/48000 (91%)]\tLoss: 0.000086\n",
      "Train Epoch: 8 [44800/48000 (93%)]\tLoss: 0.000028\n",
      "Train Epoch: 8 [46080/48000 (96%)]\tLoss: 0.000090\n",
      "Train Epoch: 8 [47360/48000 (99%)]\tLoss: 0.000049\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 7786/8000 (97%)\n",
      "Train Epoch: 9 [0/48000 (0%)]\tLoss: 0.000222\n",
      "Train Epoch: 9 [1280/48000 (3%)]\tLoss: 0.000096\n",
      "Train Epoch: 9 [2560/48000 (5%)]\tLoss: 0.000089\n",
      "Train Epoch: 9 [3840/48000 (8%)]\tLoss: 0.025455\n",
      "Train Epoch: 9 [5120/48000 (11%)]\tLoss: 0.000415\n",
      "Train Epoch: 9 [6400/48000 (13%)]\tLoss: 0.004617\n",
      "Train Epoch: 9 [7680/48000 (16%)]\tLoss: 0.001167\n",
      "Train Epoch: 9 [8960/48000 (19%)]\tLoss: 0.000446\n",
      "Train Epoch: 9 [10240/48000 (21%)]\tLoss: 0.007678\n",
      "Train Epoch: 9 [11520/48000 (24%)]\tLoss: 0.000169\n",
      "Train Epoch: 9 [12800/48000 (27%)]\tLoss: 0.000183\n",
      "Train Epoch: 9 [14080/48000 (29%)]\tLoss: 0.002552\n",
      "Train Epoch: 9 [15360/48000 (32%)]\tLoss: 0.000430\n",
      "Train Epoch: 9 [16640/48000 (35%)]\tLoss: 0.067171\n",
      "Train Epoch: 9 [17920/48000 (37%)]\tLoss: 0.010197\n",
      "Train Epoch: 9 [19200/48000 (40%)]\tLoss: 0.013295\n",
      "Train Epoch: 9 [20480/48000 (43%)]\tLoss: 0.014107\n",
      "Train Epoch: 9 [21760/48000 (45%)]\tLoss: 0.023128\n",
      "Train Epoch: 9 [23040/48000 (48%)]\tLoss: 0.077354\n",
      "Train Epoch: 9 [24320/48000 (51%)]\tLoss: 0.028512\n",
      "Train Epoch: 9 [25600/48000 (53%)]\tLoss: 0.002470\n",
      "Train Epoch: 9 [26880/48000 (56%)]\tLoss: 0.014145\n",
      "Train Epoch: 9 [28160/48000 (59%)]\tLoss: 0.021518\n",
      "Train Epoch: 9 [29440/48000 (61%)]\tLoss: 0.012605\n",
      "Train Epoch: 9 [30720/48000 (64%)]\tLoss: 0.060630\n",
      "Train Epoch: 9 [32000/48000 (67%)]\tLoss: 0.001022\n",
      "Train Epoch: 9 [33280/48000 (69%)]\tLoss: 0.039520\n",
      "Train Epoch: 9 [34560/48000 (72%)]\tLoss: 0.002267\n",
      "Train Epoch: 9 [35840/48000 (75%)]\tLoss: 0.007342\n",
      "Train Epoch: 9 [37120/48000 (77%)]\tLoss: 0.051220\n",
      "Train Epoch: 9 [38400/48000 (80%)]\tLoss: 0.000610\n",
      "Train Epoch: 9 [39680/48000 (83%)]\tLoss: 0.000519\n",
      "Train Epoch: 9 [40960/48000 (85%)]\tLoss: 0.023104\n",
      "Train Epoch: 9 [42240/48000 (88%)]\tLoss: 0.018732\n",
      "Train Epoch: 9 [43520/48000 (91%)]\tLoss: 0.001760\n",
      "Train Epoch: 9 [44800/48000 (93%)]\tLoss: 0.001254\n",
      "Train Epoch: 9 [46080/48000 (96%)]\tLoss: 0.000394\n",
      "Train Epoch: 9 [47360/48000 (99%)]\tLoss: 0.000654\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 7747/8000 (97%)\n",
      "Train Epoch: 10 [0/48000 (0%)]\tLoss: 0.000252\n",
      "Train Epoch: 10 [1280/48000 (3%)]\tLoss: 0.000667\n",
      "Train Epoch: 10 [2560/48000 (5%)]\tLoss: 0.000501\n",
      "Train Epoch: 10 [3840/48000 (8%)]\tLoss: 0.000455\n",
      "Train Epoch: 10 [5120/48000 (11%)]\tLoss: 0.000975\n",
      "Train Epoch: 10 [6400/48000 (13%)]\tLoss: 0.000425\n",
      "Train Epoch: 10 [7680/48000 (16%)]\tLoss: 0.000218\n",
      "Train Epoch: 10 [8960/48000 (19%)]\tLoss: 0.000224\n",
      "Train Epoch: 10 [10240/48000 (21%)]\tLoss: 0.000216\n",
      "Train Epoch: 10 [11520/48000 (24%)]\tLoss: 0.001586\n",
      "Train Epoch: 10 [12800/48000 (27%)]\tLoss: 0.000321\n",
      "Train Epoch: 10 [14080/48000 (29%)]\tLoss: 0.000717\n",
      "Train Epoch: 10 [15360/48000 (32%)]\tLoss: 0.000260\n",
      "Train Epoch: 10 [16640/48000 (35%)]\tLoss: 0.000134\n",
      "Train Epoch: 10 [17920/48000 (37%)]\tLoss: 0.014789\n",
      "Train Epoch: 10 [19200/48000 (40%)]\tLoss: 0.000472\n",
      "Train Epoch: 10 [20480/48000 (43%)]\tLoss: 0.000380\n",
      "Train Epoch: 10 [21760/48000 (45%)]\tLoss: 0.000552\n",
      "Train Epoch: 10 [23040/48000 (48%)]\tLoss: 0.000328\n",
      "Train Epoch: 10 [24320/48000 (51%)]\tLoss: 0.000112\n",
      "Train Epoch: 10 [25600/48000 (53%)]\tLoss: 0.000063\n",
      "Train Epoch: 10 [26880/48000 (56%)]\tLoss: 0.000132\n",
      "Train Epoch: 10 [28160/48000 (59%)]\tLoss: 0.000134\n",
      "Train Epoch: 10 [29440/48000 (61%)]\tLoss: 0.000085\n",
      "Train Epoch: 10 [30720/48000 (64%)]\tLoss: 0.000831\n",
      "Train Epoch: 10 [32000/48000 (67%)]\tLoss: 0.000331\n",
      "Train Epoch: 10 [33280/48000 (69%)]\tLoss: 0.000115\n",
      "Train Epoch: 10 [34560/48000 (72%)]\tLoss: 0.000083\n",
      "Train Epoch: 10 [35840/48000 (75%)]\tLoss: 0.000129\n",
      "Train Epoch: 10 [37120/48000 (77%)]\tLoss: 0.001894\n",
      "Train Epoch: 10 [38400/48000 (80%)]\tLoss: 0.000088\n",
      "Train Epoch: 10 [39680/48000 (83%)]\tLoss: 0.000059\n",
      "Train Epoch: 10 [40960/48000 (85%)]\tLoss: 0.000091\n",
      "Train Epoch: 10 [42240/48000 (88%)]\tLoss: 0.000071\n",
      "Train Epoch: 10 [43520/48000 (91%)]\tLoss: 0.000090\n",
      "Train Epoch: 10 [44800/48000 (93%)]\tLoss: 0.000120\n",
      "Train Epoch: 10 [46080/48000 (96%)]\tLoss: 0.000097\n",
      "Train Epoch: 10 [47360/48000 (99%)]\tLoss: 0.001014\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 7794/8000 (97%)\n",
      "Train Epoch: 11 [0/48000 (0%)]\tLoss: 0.000080\n",
      "Train Epoch: 11 [1280/48000 (3%)]\tLoss: 0.000067\n",
      "Train Epoch: 11 [2560/48000 (5%)]\tLoss: 0.000184\n",
      "Train Epoch: 11 [3840/48000 (8%)]\tLoss: 0.000110\n",
      "Train Epoch: 11 [5120/48000 (11%)]\tLoss: 0.000043\n",
      "Train Epoch: 11 [6400/48000 (13%)]\tLoss: 0.000093\n",
      "Train Epoch: 11 [7680/48000 (16%)]\tLoss: 0.000043\n",
      "Train Epoch: 11 [8960/48000 (19%)]\tLoss: 0.000046\n",
      "Train Epoch: 11 [10240/48000 (21%)]\tLoss: 0.001784\n",
      "Train Epoch: 11 [11520/48000 (24%)]\tLoss: 0.000067\n",
      "Train Epoch: 11 [12800/48000 (27%)]\tLoss: 0.000041\n",
      "Train Epoch: 11 [14080/48000 (29%)]\tLoss: 0.000038\n",
      "Train Epoch: 11 [15360/48000 (32%)]\tLoss: 0.000035\n",
      "Train Epoch: 11 [16640/48000 (35%)]\tLoss: 0.001577\n",
      "Train Epoch: 11 [17920/48000 (37%)]\tLoss: 0.000204\n",
      "Train Epoch: 11 [19200/48000 (40%)]\tLoss: 0.001778\n",
      "Train Epoch: 11 [20480/48000 (43%)]\tLoss: 0.000233\n",
      "Train Epoch: 11 [21760/48000 (45%)]\tLoss: 0.000036\n",
      "Train Epoch: 11 [23040/48000 (48%)]\tLoss: 0.021140\n",
      "Train Epoch: 11 [24320/48000 (51%)]\tLoss: 0.011402\n",
      "Train Epoch: 11 [25600/48000 (53%)]\tLoss: 0.000121\n",
      "Train Epoch: 11 [26880/48000 (56%)]\tLoss: 0.000053\n",
      "Train Epoch: 11 [28160/48000 (59%)]\tLoss: 0.000055\n",
      "Train Epoch: 11 [29440/48000 (61%)]\tLoss: 0.002535\n",
      "Train Epoch: 11 [30720/48000 (64%)]\tLoss: 0.006037\n",
      "Train Epoch: 11 [32000/48000 (67%)]\tLoss: 0.000207\n",
      "Train Epoch: 11 [33280/48000 (69%)]\tLoss: 0.000031\n",
      "Train Epoch: 11 [34560/48000 (72%)]\tLoss: 0.000082\n",
      "Train Epoch: 11 [35840/48000 (75%)]\tLoss: 0.001047\n",
      "Train Epoch: 11 [37120/48000 (77%)]\tLoss: 0.000036\n",
      "Train Epoch: 11 [38400/48000 (80%)]\tLoss: 0.000065\n",
      "Train Epoch: 11 [39680/48000 (83%)]\tLoss: 0.000083\n",
      "Train Epoch: 11 [40960/48000 (85%)]\tLoss: 0.000132\n",
      "Train Epoch: 11 [42240/48000 (88%)]\tLoss: 0.000063\n",
      "Train Epoch: 11 [43520/48000 (91%)]\tLoss: 0.000043\n",
      "Train Epoch: 11 [44800/48000 (93%)]\tLoss: 0.000055\n",
      "Train Epoch: 11 [46080/48000 (96%)]\tLoss: 0.000049\n",
      "Train Epoch: 11 [47360/48000 (99%)]\tLoss: 0.000055\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 7792/8000 (97%)\n",
      "Train Epoch: 12 [0/48000 (0%)]\tLoss: 0.000078\n",
      "Train Epoch: 12 [1280/48000 (3%)]\tLoss: 0.000052\n",
      "Train Epoch: 12 [2560/48000 (5%)]\tLoss: 0.000041\n",
      "Train Epoch: 12 [3840/48000 (8%)]\tLoss: 0.000087\n",
      "Train Epoch: 12 [5120/48000 (11%)]\tLoss: 0.000077\n",
      "Train Epoch: 12 [6400/48000 (13%)]\tLoss: 0.000410\n",
      "Train Epoch: 12 [7680/48000 (16%)]\tLoss: 0.000102\n",
      "Train Epoch: 12 [8960/48000 (19%)]\tLoss: 0.000036\n",
      "Train Epoch: 12 [10240/48000 (21%)]\tLoss: 0.000028\n",
      "Train Epoch: 12 [11520/48000 (24%)]\tLoss: 0.000043\n",
      "Train Epoch: 12 [12800/48000 (27%)]\tLoss: 0.000063\n",
      "Train Epoch: 12 [14080/48000 (29%)]\tLoss: 0.000028\n",
      "Train Epoch: 12 [15360/48000 (32%)]\tLoss: 0.000559\n",
      "Train Epoch: 12 [16640/48000 (35%)]\tLoss: 0.000028\n",
      "Train Epoch: 12 [17920/48000 (37%)]\tLoss: 0.000031\n",
      "Train Epoch: 12 [19200/48000 (40%)]\tLoss: 0.000046\n",
      "Train Epoch: 12 [20480/48000 (43%)]\tLoss: 0.000063\n",
      "Train Epoch: 12 [21760/48000 (45%)]\tLoss: 0.000028\n",
      "Train Epoch: 12 [23040/48000 (48%)]\tLoss: 0.000121\n",
      "Train Epoch: 12 [24320/48000 (51%)]\tLoss: 0.000054\n",
      "Train Epoch: 12 [25600/48000 (53%)]\tLoss: 0.000138\n",
      "Train Epoch: 12 [26880/48000 (56%)]\tLoss: 0.000057\n",
      "Train Epoch: 12 [28160/48000 (59%)]\tLoss: 0.000021\n",
      "Train Epoch: 12 [29440/48000 (61%)]\tLoss: 0.000019\n",
      "Train Epoch: 12 [30720/48000 (64%)]\tLoss: 0.000039\n",
      "Train Epoch: 12 [32000/48000 (67%)]\tLoss: 0.000015\n",
      "Train Epoch: 12 [33280/48000 (69%)]\tLoss: 0.000018\n",
      "Train Epoch: 12 [34560/48000 (72%)]\tLoss: 0.000019\n",
      "Train Epoch: 12 [35840/48000 (75%)]\tLoss: 0.000077\n",
      "Train Epoch: 12 [37120/48000 (77%)]\tLoss: 0.000040\n",
      "Train Epoch: 12 [38400/48000 (80%)]\tLoss: 0.000029\n",
      "Train Epoch: 12 [39680/48000 (83%)]\tLoss: 0.000039\n",
      "Train Epoch: 12 [40960/48000 (85%)]\tLoss: 0.000018\n",
      "Train Epoch: 12 [42240/48000 (88%)]\tLoss: 0.000027\n",
      "Train Epoch: 12 [43520/48000 (91%)]\tLoss: 0.000020\n",
      "Train Epoch: 12 [44800/48000 (93%)]\tLoss: 0.000049\n",
      "Train Epoch: 12 [46080/48000 (96%)]\tLoss: 0.000024\n",
      "Train Epoch: 12 [47360/48000 (99%)]\tLoss: 0.000040\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 7781/8000 (97%)\n",
      "Train Epoch: 13 [0/48000 (0%)]\tLoss: 0.000039\n",
      "Train Epoch: 13 [1280/48000 (3%)]\tLoss: 0.000013\n",
      "Train Epoch: 13 [2560/48000 (5%)]\tLoss: 0.000246\n",
      "Train Epoch: 13 [3840/48000 (8%)]\tLoss: 0.000047\n",
      "Train Epoch: 13 [5120/48000 (11%)]\tLoss: 0.000020\n",
      "Train Epoch: 13 [6400/48000 (13%)]\tLoss: 0.000019\n",
      "Train Epoch: 13 [7680/48000 (16%)]\tLoss: 0.000032\n",
      "Train Epoch: 13 [8960/48000 (19%)]\tLoss: 0.000084\n",
      "Train Epoch: 13 [10240/48000 (21%)]\tLoss: 0.000061\n",
      "Train Epoch: 13 [11520/48000 (24%)]\tLoss: 0.000033\n",
      "Train Epoch: 13 [12800/48000 (27%)]\tLoss: 0.000015\n",
      "Train Epoch: 13 [14080/48000 (29%)]\tLoss: 0.000030\n",
      "Train Epoch: 13 [15360/48000 (32%)]\tLoss: 0.000047\n",
      "Train Epoch: 13 [16640/48000 (35%)]\tLoss: 0.000027\n",
      "Train Epoch: 13 [17920/48000 (37%)]\tLoss: 0.000037\n",
      "Train Epoch: 13 [19200/48000 (40%)]\tLoss: 0.000018\n",
      "Train Epoch: 13 [20480/48000 (43%)]\tLoss: 0.000031\n",
      "Train Epoch: 13 [21760/48000 (45%)]\tLoss: 0.000025\n",
      "Train Epoch: 13 [23040/48000 (48%)]\tLoss: 0.000043\n",
      "Train Epoch: 13 [24320/48000 (51%)]\tLoss: 0.000017\n",
      "Train Epoch: 13 [25600/48000 (53%)]\tLoss: 0.000021\n",
      "Train Epoch: 13 [26880/48000 (56%)]\tLoss: 0.000029\n",
      "Train Epoch: 13 [28160/48000 (59%)]\tLoss: 0.000016\n",
      "Train Epoch: 13 [29440/48000 (61%)]\tLoss: 0.000015\n",
      "Train Epoch: 13 [30720/48000 (64%)]\tLoss: 0.000091\n",
      "Train Epoch: 13 [32000/48000 (67%)]\tLoss: 0.000027\n",
      "Train Epoch: 13 [33280/48000 (69%)]\tLoss: 0.000091\n",
      "Train Epoch: 13 [34560/48000 (72%)]\tLoss: 0.000021\n",
      "Train Epoch: 13 [35840/48000 (75%)]\tLoss: 0.000013\n",
      "Train Epoch: 13 [37120/48000 (77%)]\tLoss: 0.000018\n",
      "Train Epoch: 13 [38400/48000 (80%)]\tLoss: 0.000015\n",
      "Train Epoch: 13 [39680/48000 (83%)]\tLoss: 0.000015\n",
      "Train Epoch: 13 [40960/48000 (85%)]\tLoss: 0.000062\n",
      "Train Epoch: 13 [42240/48000 (88%)]\tLoss: 0.000021\n",
      "Train Epoch: 13 [43520/48000 (91%)]\tLoss: 0.000011\n",
      "Train Epoch: 13 [44800/48000 (93%)]\tLoss: 0.000009\n",
      "Train Epoch: 13 [46080/48000 (96%)]\tLoss: 0.000012\n",
      "Train Epoch: 13 [47360/48000 (99%)]\tLoss: 0.000009\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 7812/8000 (98%)\n",
      "Train Epoch: 14 [0/48000 (0%)]\tLoss: 0.000044\n",
      "Train Epoch: 14 [1280/48000 (3%)]\tLoss: 0.000018\n",
      "Train Epoch: 14 [2560/48000 (5%)]\tLoss: 0.000014\n",
      "Train Epoch: 14 [3840/48000 (8%)]\tLoss: 0.000017\n",
      "Train Epoch: 14 [5120/48000 (11%)]\tLoss: 0.000011\n",
      "Train Epoch: 14 [6400/48000 (13%)]\tLoss: 0.000024\n",
      "Train Epoch: 14 [7680/48000 (16%)]\tLoss: 0.000037\n",
      "Train Epoch: 14 [8960/48000 (19%)]\tLoss: 0.000014\n",
      "Train Epoch: 14 [10240/48000 (21%)]\tLoss: 0.000017\n",
      "Train Epoch: 14 [11520/48000 (24%)]\tLoss: 0.000020\n",
      "Train Epoch: 14 [12800/48000 (27%)]\tLoss: 0.000023\n",
      "Train Epoch: 14 [14080/48000 (29%)]\tLoss: 0.000012\n",
      "Train Epoch: 14 [15360/48000 (32%)]\tLoss: 0.000019\n",
      "Train Epoch: 14 [16640/48000 (35%)]\tLoss: 0.000019\n",
      "Train Epoch: 14 [17920/48000 (37%)]\tLoss: 0.000033\n",
      "Train Epoch: 14 [19200/48000 (40%)]\tLoss: 0.000012\n",
      "Train Epoch: 14 [20480/48000 (43%)]\tLoss: 0.000035\n",
      "Train Epoch: 14 [21760/48000 (45%)]\tLoss: 0.000007\n",
      "Train Epoch: 14 [23040/48000 (48%)]\tLoss: 0.000018\n",
      "Train Epoch: 14 [24320/48000 (51%)]\tLoss: 0.000012\n",
      "Train Epoch: 14 [25600/48000 (53%)]\tLoss: 0.000009\n",
      "Train Epoch: 14 [26880/48000 (56%)]\tLoss: 0.000010\n",
      "Train Epoch: 14 [28160/48000 (59%)]\tLoss: 0.000025\n",
      "Train Epoch: 14 [29440/48000 (61%)]\tLoss: 0.000015\n",
      "Train Epoch: 14 [30720/48000 (64%)]\tLoss: 0.000009\n",
      "Train Epoch: 14 [32000/48000 (67%)]\tLoss: 0.000021\n",
      "Train Epoch: 14 [33280/48000 (69%)]\tLoss: 0.000010\n",
      "Train Epoch: 14 [34560/48000 (72%)]\tLoss: 0.000067\n",
      "Train Epoch: 14 [35840/48000 (75%)]\tLoss: 0.000016\n",
      "Train Epoch: 14 [37120/48000 (77%)]\tLoss: 0.000009\n",
      "Train Epoch: 14 [38400/48000 (80%)]\tLoss: 0.000022\n",
      "Train Epoch: 14 [39680/48000 (83%)]\tLoss: 0.000013\n",
      "Train Epoch: 14 [40960/48000 (85%)]\tLoss: 0.000019\n",
      "Train Epoch: 14 [42240/48000 (88%)]\tLoss: 0.000018\n",
      "Train Epoch: 14 [43520/48000 (91%)]\tLoss: 0.000009\n",
      "Train Epoch: 14 [44800/48000 (93%)]\tLoss: 0.000022\n",
      "Train Epoch: 14 [46080/48000 (96%)]\tLoss: 0.000039\n",
      "Train Epoch: 14 [47360/48000 (99%)]\tLoss: 0.000008\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 7821/8000 (98%)\n",
      "Train Epoch: 15 [0/48000 (0%)]\tLoss: 0.000031\n",
      "Train Epoch: 15 [1280/48000 (3%)]\tLoss: 0.000019\n",
      "Train Epoch: 15 [2560/48000 (5%)]\tLoss: 0.000020\n",
      "Train Epoch: 15 [3840/48000 (8%)]\tLoss: 0.000019\n",
      "Train Epoch: 15 [5120/48000 (11%)]\tLoss: 0.000012\n",
      "Train Epoch: 15 [6400/48000 (13%)]\tLoss: 0.000012\n",
      "Train Epoch: 15 [7680/48000 (16%)]\tLoss: 0.000017\n",
      "Train Epoch: 15 [8960/48000 (19%)]\tLoss: 0.000008\n",
      "Train Epoch: 15 [10240/48000 (21%)]\tLoss: 0.000009\n",
      "Train Epoch: 15 [11520/48000 (24%)]\tLoss: 0.000009\n",
      "Train Epoch: 15 [12800/48000 (27%)]\tLoss: 0.000018\n",
      "Train Epoch: 15 [14080/48000 (29%)]\tLoss: 0.000013\n",
      "Train Epoch: 15 [15360/48000 (32%)]\tLoss: 0.000008\n",
      "Train Epoch: 15 [16640/48000 (35%)]\tLoss: 0.000018\n",
      "Train Epoch: 15 [17920/48000 (37%)]\tLoss: 0.000012\n",
      "Train Epoch: 15 [19200/48000 (40%)]\tLoss: 0.000014\n",
      "Train Epoch: 15 [20480/48000 (43%)]\tLoss: 0.000011\n",
      "Train Epoch: 15 [21760/48000 (45%)]\tLoss: 0.000042\n",
      "Train Epoch: 15 [23040/48000 (48%)]\tLoss: 0.000014\n",
      "Train Epoch: 15 [24320/48000 (51%)]\tLoss: 0.000007\n",
      "Train Epoch: 15 [25600/48000 (53%)]\tLoss: 0.000012\n",
      "Train Epoch: 15 [26880/48000 (56%)]\tLoss: 0.000014\n",
      "Train Epoch: 15 [28160/48000 (59%)]\tLoss: 0.000011\n",
      "Train Epoch: 15 [29440/48000 (61%)]\tLoss: 0.000008\n",
      "Train Epoch: 15 [30720/48000 (64%)]\tLoss: 0.000013\n",
      "Train Epoch: 15 [32000/48000 (67%)]\tLoss: 0.000009\n",
      "Train Epoch: 15 [33280/48000 (69%)]\tLoss: 0.000013\n",
      "Train Epoch: 15 [34560/48000 (72%)]\tLoss: 0.000021\n",
      "Train Epoch: 15 [35840/48000 (75%)]\tLoss: 0.000005\n",
      "Train Epoch: 15 [37120/48000 (77%)]\tLoss: 0.000008\n",
      "Train Epoch: 15 [38400/48000 (80%)]\tLoss: 0.000010\n",
      "Train Epoch: 15 [39680/48000 (83%)]\tLoss: 0.000008\n",
      "Train Epoch: 15 [40960/48000 (85%)]\tLoss: 0.000007\n",
      "Train Epoch: 15 [42240/48000 (88%)]\tLoss: 0.000007\n",
      "Train Epoch: 15 [43520/48000 (91%)]\tLoss: 0.000009\n",
      "Train Epoch: 15 [44800/48000 (93%)]\tLoss: 0.000017\n",
      "Train Epoch: 15 [46080/48000 (96%)]\tLoss: 0.000011\n",
      "Train Epoch: 15 [47360/48000 (99%)]\tLoss: 0.000006\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 7803/8000 (98%)\n",
      "Train Epoch: 16 [0/48000 (0%)]\tLoss: 0.000007\n",
      "Train Epoch: 16 [1280/48000 (3%)]\tLoss: 0.000008\n",
      "Train Epoch: 16 [2560/48000 (5%)]\tLoss: 0.000006\n",
      "Train Epoch: 16 [3840/48000 (8%)]\tLoss: 0.000009\n",
      "Train Epoch: 16 [5120/48000 (11%)]\tLoss: 0.000035\n",
      "Train Epoch: 16 [6400/48000 (13%)]\tLoss: 0.000045\n",
      "Train Epoch: 16 [7680/48000 (16%)]\tLoss: 0.000012\n",
      "Train Epoch: 16 [8960/48000 (19%)]\tLoss: 0.002507\n",
      "Train Epoch: 16 [10240/48000 (21%)]\tLoss: 0.114298\n",
      "Train Epoch: 16 [11520/48000 (24%)]\tLoss: 0.038031\n",
      "Train Epoch: 16 [12800/48000 (27%)]\tLoss: 0.010013\n",
      "Train Epoch: 16 [14080/48000 (29%)]\tLoss: 0.028704\n",
      "Train Epoch: 16 [15360/48000 (32%)]\tLoss: 0.040092\n",
      "Train Epoch: 16 [16640/48000 (35%)]\tLoss: 0.011041\n",
      "Train Epoch: 16 [17920/48000 (37%)]\tLoss: 0.032767\n",
      "Train Epoch: 16 [19200/48000 (40%)]\tLoss: 0.003289\n",
      "Train Epoch: 16 [20480/48000 (43%)]\tLoss: 0.013574\n",
      "Train Epoch: 16 [21760/48000 (45%)]\tLoss: 0.007768\n",
      "Train Epoch: 16 [23040/48000 (48%)]\tLoss: 0.014471\n",
      "Train Epoch: 16 [24320/48000 (51%)]\tLoss: 0.006900\n",
      "Train Epoch: 16 [25600/48000 (53%)]\tLoss: 0.011150\n",
      "Train Epoch: 16 [26880/48000 (56%)]\tLoss: 0.003889\n",
      "Train Epoch: 16 [28160/48000 (59%)]\tLoss: 0.003742\n",
      "Train Epoch: 16 [29440/48000 (61%)]\tLoss: 0.001017\n",
      "Train Epoch: 16 [30720/48000 (64%)]\tLoss: 0.001148\n",
      "Train Epoch: 16 [32000/48000 (67%)]\tLoss: 0.000696\n",
      "Train Epoch: 16 [33280/48000 (69%)]\tLoss: 0.001204\n",
      "Train Epoch: 16 [34560/48000 (72%)]\tLoss: 0.001844\n",
      "Train Epoch: 16 [35840/48000 (75%)]\tLoss: 0.000457\n",
      "Train Epoch: 16 [37120/48000 (77%)]\tLoss: 0.000841\n",
      "Train Epoch: 16 [38400/48000 (80%)]\tLoss: 0.003659\n",
      "Train Epoch: 16 [39680/48000 (83%)]\tLoss: 0.000375\n",
      "Train Epoch: 16 [40960/48000 (85%)]\tLoss: 0.000537\n",
      "Train Epoch: 16 [42240/48000 (88%)]\tLoss: 0.001266\n",
      "Train Epoch: 16 [43520/48000 (91%)]\tLoss: 0.017370\n",
      "Train Epoch: 16 [44800/48000 (93%)]\tLoss: 0.007138\n",
      "Train Epoch: 16 [46080/48000 (96%)]\tLoss: 0.002096\n",
      "Train Epoch: 16 [47360/48000 (99%)]\tLoss: 0.000698\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 7761/8000 (97%)\n",
      "Train Epoch: 17 [0/48000 (0%)]\tLoss: 0.001404\n",
      "Train Epoch: 17 [1280/48000 (3%)]\tLoss: 0.002011\n",
      "Train Epoch: 17 [2560/48000 (5%)]\tLoss: 0.001867\n",
      "Train Epoch: 17 [3840/48000 (8%)]\tLoss: 0.001710\n",
      "Train Epoch: 17 [5120/48000 (11%)]\tLoss: 0.001031\n",
      "Train Epoch: 17 [6400/48000 (13%)]\tLoss: 0.002363\n",
      "Train Epoch: 17 [7680/48000 (16%)]\tLoss: 0.000948\n",
      "Train Epoch: 17 [8960/48000 (19%)]\tLoss: 0.000291\n",
      "Train Epoch: 17 [10240/48000 (21%)]\tLoss: 0.008083\n",
      "Train Epoch: 17 [11520/48000 (24%)]\tLoss: 0.000203\n",
      "Train Epoch: 17 [12800/48000 (27%)]\tLoss: 0.000922\n",
      "Train Epoch: 17 [14080/48000 (29%)]\tLoss: 0.016593\n",
      "Train Epoch: 17 [15360/48000 (32%)]\tLoss: 0.022609\n",
      "Train Epoch: 17 [16640/48000 (35%)]\tLoss: 0.000886\n",
      "Train Epoch: 17 [17920/48000 (37%)]\tLoss: 0.021263\n",
      "Train Epoch: 17 [19200/48000 (40%)]\tLoss: 0.003207\n",
      "Train Epoch: 17 [20480/48000 (43%)]\tLoss: 0.000454\n",
      "Train Epoch: 17 [21760/48000 (45%)]\tLoss: 0.000511\n",
      "Train Epoch: 17 [23040/48000 (48%)]\tLoss: 0.000497\n",
      "Train Epoch: 17 [24320/48000 (51%)]\tLoss: 0.000127\n",
      "Train Epoch: 17 [25600/48000 (53%)]\tLoss: 0.016601\n",
      "Train Epoch: 17 [26880/48000 (56%)]\tLoss: 0.000673\n",
      "Train Epoch: 17 [28160/48000 (59%)]\tLoss: 0.034666\n",
      "Train Epoch: 17 [29440/48000 (61%)]\tLoss: 0.000678\n",
      "Train Epoch: 17 [30720/48000 (64%)]\tLoss: 0.000189\n",
      "Train Epoch: 17 [32000/48000 (67%)]\tLoss: 0.000510\n",
      "Train Epoch: 17 [33280/48000 (69%)]\tLoss: 0.034898\n",
      "Train Epoch: 17 [34560/48000 (72%)]\tLoss: 0.000503\n",
      "Train Epoch: 17 [35840/48000 (75%)]\tLoss: 0.042145\n",
      "Train Epoch: 17 [37120/48000 (77%)]\tLoss: 0.000598\n",
      "Train Epoch: 17 [38400/48000 (80%)]\tLoss: 0.001863\n",
      "Train Epoch: 17 [39680/48000 (83%)]\tLoss: 0.012217\n",
      "Train Epoch: 17 [40960/48000 (85%)]\tLoss: 0.000512\n",
      "Train Epoch: 17 [42240/48000 (88%)]\tLoss: 0.000722\n",
      "Train Epoch: 17 [43520/48000 (91%)]\tLoss: 0.003035\n",
      "Train Epoch: 17 [44800/48000 (93%)]\tLoss: 0.001717\n",
      "Train Epoch: 17 [46080/48000 (96%)]\tLoss: 0.017965\n",
      "Train Epoch: 17 [47360/48000 (99%)]\tLoss: 0.000429\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 7797/8000 (97%)\n",
      "Train Epoch: 18 [0/48000 (0%)]\tLoss: 0.000495\n",
      "Train Epoch: 18 [1280/48000 (3%)]\tLoss: 0.000681\n",
      "Train Epoch: 18 [2560/48000 (5%)]\tLoss: 0.000511\n",
      "Train Epoch: 18 [3840/48000 (8%)]\tLoss: 0.000210\n",
      "Train Epoch: 18 [5120/48000 (11%)]\tLoss: 0.000371\n",
      "Train Epoch: 18 [6400/48000 (13%)]\tLoss: 0.003974\n",
      "Train Epoch: 18 [7680/48000 (16%)]\tLoss: 0.000200\n",
      "Train Epoch: 18 [8960/48000 (19%)]\tLoss: 0.001194\n",
      "Train Epoch: 18 [10240/48000 (21%)]\tLoss: 0.000322\n",
      "Train Epoch: 18 [11520/48000 (24%)]\tLoss: 0.000503\n",
      "Train Epoch: 18 [12800/48000 (27%)]\tLoss: 0.000401\n",
      "Train Epoch: 18 [14080/48000 (29%)]\tLoss: 0.000257\n",
      "Train Epoch: 18 [15360/48000 (32%)]\tLoss: 0.000178\n",
      "Train Epoch: 18 [16640/48000 (35%)]\tLoss: 0.032207\n",
      "Train Epoch: 18 [17920/48000 (37%)]\tLoss: 0.000438\n",
      "Train Epoch: 18 [19200/48000 (40%)]\tLoss: 0.004006\n",
      "Train Epoch: 18 [20480/48000 (43%)]\tLoss: 0.000251\n",
      "Train Epoch: 18 [21760/48000 (45%)]\tLoss: 0.000203\n",
      "Train Epoch: 18 [23040/48000 (48%)]\tLoss: 0.000322\n",
      "Train Epoch: 18 [24320/48000 (51%)]\tLoss: 0.000476\n",
      "Train Epoch: 18 [25600/48000 (53%)]\tLoss: 0.000309\n",
      "Train Epoch: 18 [26880/48000 (56%)]\tLoss: 0.000251\n",
      "Train Epoch: 18 [28160/48000 (59%)]\tLoss: 0.000298\n",
      "Train Epoch: 18 [29440/48000 (61%)]\tLoss: 0.000333\n",
      "Train Epoch: 18 [30720/48000 (64%)]\tLoss: 0.000377\n",
      "Train Epoch: 18 [32000/48000 (67%)]\tLoss: 0.000987\n",
      "Train Epoch: 18 [33280/48000 (69%)]\tLoss: 0.000187\n",
      "Train Epoch: 18 [34560/48000 (72%)]\tLoss: 0.000424\n",
      "Train Epoch: 18 [35840/48000 (75%)]\tLoss: 0.000219\n",
      "Train Epoch: 18 [37120/48000 (77%)]\tLoss: 0.000191\n",
      "Train Epoch: 18 [38400/48000 (80%)]\tLoss: 0.000313\n",
      "Train Epoch: 18 [39680/48000 (83%)]\tLoss: 0.000254\n",
      "Train Epoch: 18 [40960/48000 (85%)]\tLoss: 0.000098\n",
      "Train Epoch: 18 [42240/48000 (88%)]\tLoss: 0.000081\n",
      "Train Epoch: 18 [43520/48000 (91%)]\tLoss: 0.000131\n",
      "Train Epoch: 18 [44800/48000 (93%)]\tLoss: 0.000104\n",
      "Train Epoch: 18 [46080/48000 (96%)]\tLoss: 0.000098\n",
      "Train Epoch: 18 [47360/48000 (99%)]\tLoss: 0.000940\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 7808/8000 (98%)\n",
      "Train Epoch: 19 [0/48000 (0%)]\tLoss: 0.000100\n",
      "Train Epoch: 19 [1280/48000 (3%)]\tLoss: 0.000219\n",
      "Train Epoch: 19 [2560/48000 (5%)]\tLoss: 0.000504\n",
      "Train Epoch: 19 [3840/48000 (8%)]\tLoss: 0.000080\n",
      "Train Epoch: 19 [5120/48000 (11%)]\tLoss: 0.000041\n",
      "Train Epoch: 19 [6400/48000 (13%)]\tLoss: 0.000042\n",
      "Train Epoch: 19 [7680/48000 (16%)]\tLoss: 0.000092\n",
      "Train Epoch: 19 [8960/48000 (19%)]\tLoss: 0.000064\n",
      "Train Epoch: 19 [10240/48000 (21%)]\tLoss: 0.000108\n",
      "Train Epoch: 19 [11520/48000 (24%)]\tLoss: 0.000055\n",
      "Train Epoch: 19 [12800/48000 (27%)]\tLoss: 0.000062\n",
      "Train Epoch: 19 [14080/48000 (29%)]\tLoss: 0.000146\n",
      "Train Epoch: 19 [15360/48000 (32%)]\tLoss: 0.000087\n",
      "Train Epoch: 19 [16640/48000 (35%)]\tLoss: 0.000061\n",
      "Train Epoch: 19 [17920/48000 (37%)]\tLoss: 0.000550\n",
      "Train Epoch: 19 [19200/48000 (40%)]\tLoss: 0.000075\n",
      "Train Epoch: 19 [20480/48000 (43%)]\tLoss: 0.000135\n",
      "Train Epoch: 19 [21760/48000 (45%)]\tLoss: 0.000063\n",
      "Train Epoch: 19 [23040/48000 (48%)]\tLoss: 0.000058\n",
      "Train Epoch: 19 [24320/48000 (51%)]\tLoss: 0.000278\n",
      "Train Epoch: 19 [25600/48000 (53%)]\tLoss: 0.000046\n",
      "Train Epoch: 19 [26880/48000 (56%)]\tLoss: 0.000083\n",
      "Train Epoch: 19 [28160/48000 (59%)]\tLoss: 0.000095\n",
      "Train Epoch: 19 [29440/48000 (61%)]\tLoss: 0.000069\n",
      "Train Epoch: 19 [30720/48000 (64%)]\tLoss: 0.000616\n",
      "Train Epoch: 19 [32000/48000 (67%)]\tLoss: 0.000129\n",
      "Train Epoch: 19 [33280/48000 (69%)]\tLoss: 0.032003\n",
      "Train Epoch: 19 [34560/48000 (72%)]\tLoss: 0.000195\n",
      "Train Epoch: 19 [35840/48000 (75%)]\tLoss: 0.000091\n",
      "Train Epoch: 19 [37120/48000 (77%)]\tLoss: 0.000157\n",
      "Train Epoch: 19 [38400/48000 (80%)]\tLoss: 0.000083\n",
      "Train Epoch: 19 [39680/48000 (83%)]\tLoss: 0.000063\n",
      "Train Epoch: 19 [40960/48000 (85%)]\tLoss: 0.001022\n",
      "Train Epoch: 19 [42240/48000 (88%)]\tLoss: 0.000252\n",
      "Train Epoch: 19 [43520/48000 (91%)]\tLoss: 0.022443\n",
      "Train Epoch: 19 [44800/48000 (93%)]\tLoss: 0.000546\n",
      "Train Epoch: 19 [46080/48000 (96%)]\tLoss: 0.000274\n",
      "Train Epoch: 19 [47360/48000 (99%)]\tLoss: 0.000101\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 7773/8000 (97%)\n",
      "Train Epoch: 20 [0/48000 (0%)]\tLoss: 0.084385\n",
      "Train Epoch: 20 [1280/48000 (3%)]\tLoss: 0.000201\n",
      "Train Epoch: 20 [2560/48000 (5%)]\tLoss: 0.000069\n",
      "Train Epoch: 20 [3840/48000 (8%)]\tLoss: 0.000185\n",
      "Train Epoch: 20 [5120/48000 (11%)]\tLoss: 0.000086\n",
      "Train Epoch: 20 [6400/48000 (13%)]\tLoss: 0.000371\n",
      "Train Epoch: 20 [7680/48000 (16%)]\tLoss: 0.000104\n",
      "Train Epoch: 20 [8960/48000 (19%)]\tLoss: 0.000070\n",
      "Train Epoch: 20 [10240/48000 (21%)]\tLoss: 0.000546\n",
      "Train Epoch: 20 [11520/48000 (24%)]\tLoss: 0.000099\n",
      "Train Epoch: 20 [12800/48000 (27%)]\tLoss: 0.000114\n",
      "Train Epoch: 20 [14080/48000 (29%)]\tLoss: 0.002566\n",
      "Train Epoch: 20 [15360/48000 (32%)]\tLoss: 0.000117\n",
      "Train Epoch: 20 [16640/48000 (35%)]\tLoss: 0.000057\n",
      "Train Epoch: 20 [17920/48000 (37%)]\tLoss: 0.000092\n",
      "Train Epoch: 20 [19200/48000 (40%)]\tLoss: 0.000051\n",
      "Train Epoch: 20 [20480/48000 (43%)]\tLoss: 0.000102\n",
      "Train Epoch: 20 [21760/48000 (45%)]\tLoss: 0.000063\n",
      "Train Epoch: 20 [23040/48000 (48%)]\tLoss: 0.000053\n",
      "Train Epoch: 20 [24320/48000 (51%)]\tLoss: 0.001057\n",
      "Train Epoch: 20 [25600/48000 (53%)]\tLoss: 0.000424\n",
      "Train Epoch: 20 [26880/48000 (56%)]\tLoss: 0.000241\n",
      "Train Epoch: 20 [28160/48000 (59%)]\tLoss: 0.061263\n",
      "Train Epoch: 20 [29440/48000 (61%)]\tLoss: 0.008484\n",
      "Train Epoch: 20 [30720/48000 (64%)]\tLoss: 0.003367\n",
      "Train Epoch: 20 [32000/48000 (67%)]\tLoss: 0.000903\n",
      "Train Epoch: 20 [33280/48000 (69%)]\tLoss: 0.000072\n",
      "Train Epoch: 20 [34560/48000 (72%)]\tLoss: 0.000101\n",
      "Train Epoch: 20 [35840/48000 (75%)]\tLoss: 0.014798\n",
      "Train Epoch: 20 [37120/48000 (77%)]\tLoss: 0.000767\n",
      "Train Epoch: 20 [38400/48000 (80%)]\tLoss: 0.000190\n",
      "Train Epoch: 20 [39680/48000 (83%)]\tLoss: 0.000496\n",
      "Train Epoch: 20 [40960/48000 (85%)]\tLoss: 0.000179\n",
      "Train Epoch: 20 [42240/48000 (88%)]\tLoss: 0.000466\n",
      "Train Epoch: 20 [43520/48000 (91%)]\tLoss: 0.000065\n",
      "Train Epoch: 20 [44800/48000 (93%)]\tLoss: 0.000078\n",
      "Train Epoch: 20 [46080/48000 (96%)]\tLoss: 0.000147\n",
      "Train Epoch: 20 [47360/48000 (99%)]\tLoss: 0.000216\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 7816/8000 (98%)\n",
      "Train Epoch: 21 [0/48000 (0%)]\tLoss: 0.000336\n",
      "Train Epoch: 21 [1280/48000 (3%)]\tLoss: 0.022573\n",
      "Train Epoch: 21 [2560/48000 (5%)]\tLoss: 0.007763\n",
      "Train Epoch: 21 [3840/48000 (8%)]\tLoss: 0.000206\n",
      "Train Epoch: 21 [5120/48000 (11%)]\tLoss: 0.005226\n",
      "Train Epoch: 21 [6400/48000 (13%)]\tLoss: 0.000273\n",
      "Train Epoch: 21 [7680/48000 (16%)]\tLoss: 0.000084\n",
      "Train Epoch: 21 [8960/48000 (19%)]\tLoss: 0.000361\n",
      "Train Epoch: 21 [10240/48000 (21%)]\tLoss: 0.000072\n",
      "Train Epoch: 21 [11520/48000 (24%)]\tLoss: 0.000072\n",
      "Train Epoch: 21 [12800/48000 (27%)]\tLoss: 0.000160\n",
      "Train Epoch: 21 [14080/48000 (29%)]\tLoss: 0.000038\n",
      "Train Epoch: 21 [15360/48000 (32%)]\tLoss: 0.001287\n",
      "Train Epoch: 21 [16640/48000 (35%)]\tLoss: 0.000035\n",
      "Train Epoch: 21 [17920/48000 (37%)]\tLoss: 0.000070\n",
      "Train Epoch: 21 [19200/48000 (40%)]\tLoss: 0.000056\n",
      "Train Epoch: 21 [20480/48000 (43%)]\tLoss: 0.000054\n",
      "Train Epoch: 21 [21760/48000 (45%)]\tLoss: 0.000248\n",
      "Train Epoch: 21 [23040/48000 (48%)]\tLoss: 0.000102\n",
      "Train Epoch: 21 [24320/48000 (51%)]\tLoss: 0.000140\n",
      "Train Epoch: 21 [25600/48000 (53%)]\tLoss: 0.000040\n",
      "Train Epoch: 21 [26880/48000 (56%)]\tLoss: 0.000271\n",
      "Train Epoch: 21 [28160/48000 (59%)]\tLoss: 0.000057\n",
      "Train Epoch: 21 [29440/48000 (61%)]\tLoss: 0.000158\n",
      "Train Epoch: 21 [30720/48000 (64%)]\tLoss: 0.000136\n",
      "Train Epoch: 21 [32000/48000 (67%)]\tLoss: 0.000297\n",
      "Train Epoch: 21 [33280/48000 (69%)]\tLoss: 0.000020\n",
      "Train Epoch: 21 [34560/48000 (72%)]\tLoss: 0.000048\n",
      "Train Epoch: 21 [35840/48000 (75%)]\tLoss: 0.000039\n",
      "Train Epoch: 21 [37120/48000 (77%)]\tLoss: 0.000086\n",
      "Train Epoch: 21 [38400/48000 (80%)]\tLoss: 0.000106\n",
      "Train Epoch: 21 [39680/48000 (83%)]\tLoss: 0.000073\n",
      "Train Epoch: 21 [40960/48000 (85%)]\tLoss: 0.000042\n",
      "Train Epoch: 21 [42240/48000 (88%)]\tLoss: 0.000031\n",
      "Train Epoch: 21 [43520/48000 (91%)]\tLoss: 0.003103\n",
      "Train Epoch: 21 [44800/48000 (93%)]\tLoss: 0.000025\n",
      "Train Epoch: 21 [46080/48000 (96%)]\tLoss: 0.000036\n",
      "Train Epoch: 21 [47360/48000 (99%)]\tLoss: 0.000023\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 7813/8000 (98%)\n",
      "Train Epoch: 22 [0/48000 (0%)]\tLoss: 0.000029\n",
      "Train Epoch: 22 [1280/48000 (3%)]\tLoss: 0.000071\n",
      "Train Epoch: 22 [2560/48000 (5%)]\tLoss: 0.000029\n",
      "Train Epoch: 22 [3840/48000 (8%)]\tLoss: 0.000026\n",
      "Train Epoch: 22 [5120/48000 (11%)]\tLoss: 0.000040\n",
      "Train Epoch: 22 [6400/48000 (13%)]\tLoss: 0.000124\n",
      "Train Epoch: 22 [7680/48000 (16%)]\tLoss: 0.000036\n",
      "Train Epoch: 22 [8960/48000 (19%)]\tLoss: 0.000044\n",
      "Train Epoch: 22 [10240/48000 (21%)]\tLoss: 0.000205\n",
      "Train Epoch: 22 [11520/48000 (24%)]\tLoss: 0.000029\n",
      "Train Epoch: 22 [12800/48000 (27%)]\tLoss: 0.000029\n",
      "Train Epoch: 22 [14080/48000 (29%)]\tLoss: 0.000038\n",
      "Train Epoch: 22 [15360/48000 (32%)]\tLoss: 0.000033\n",
      "Train Epoch: 22 [16640/48000 (35%)]\tLoss: 0.000018\n",
      "Train Epoch: 22 [17920/48000 (37%)]\tLoss: 0.000033\n",
      "Train Epoch: 22 [19200/48000 (40%)]\tLoss: 0.000049\n",
      "Train Epoch: 22 [20480/48000 (43%)]\tLoss: 0.000035\n",
      "Train Epoch: 22 [21760/48000 (45%)]\tLoss: 0.000020\n",
      "Train Epoch: 22 [23040/48000 (48%)]\tLoss: 0.000013\n",
      "Train Epoch: 22 [24320/48000 (51%)]\tLoss: 0.000034\n",
      "Train Epoch: 22 [25600/48000 (53%)]\tLoss: 0.000203\n",
      "Train Epoch: 22 [26880/48000 (56%)]\tLoss: 0.000034\n",
      "Train Epoch: 22 [28160/48000 (59%)]\tLoss: 0.000201\n",
      "Train Epoch: 22 [29440/48000 (61%)]\tLoss: 0.000011\n",
      "Train Epoch: 22 [30720/48000 (64%)]\tLoss: 0.000031\n",
      "Train Epoch: 22 [32000/48000 (67%)]\tLoss: 0.000009\n",
      "Train Epoch: 22 [33280/48000 (69%)]\tLoss: 0.000053\n",
      "Train Epoch: 22 [34560/48000 (72%)]\tLoss: 0.000024\n",
      "Train Epoch: 22 [35840/48000 (75%)]\tLoss: 0.000014\n",
      "Train Epoch: 22 [37120/48000 (77%)]\tLoss: 0.000059\n",
      "Train Epoch: 22 [38400/48000 (80%)]\tLoss: 0.000018\n",
      "Train Epoch: 22 [39680/48000 (83%)]\tLoss: 0.000026\n",
      "Train Epoch: 22 [40960/48000 (85%)]\tLoss: 0.000127\n",
      "Train Epoch: 22 [42240/48000 (88%)]\tLoss: 0.000536\n",
      "Train Epoch: 22 [43520/48000 (91%)]\tLoss: 0.000014\n",
      "Train Epoch: 22 [44800/48000 (93%)]\tLoss: 0.000015\n",
      "Train Epoch: 22 [46080/48000 (96%)]\tLoss: 0.000018\n",
      "Train Epoch: 22 [47360/48000 (99%)]\tLoss: 0.000013\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 7813/8000 (98%)\n",
      "Train Epoch: 23 [0/48000 (0%)]\tLoss: 0.000040\n",
      "Train Epoch: 23 [1280/48000 (3%)]\tLoss: 0.000027\n",
      "Train Epoch: 23 [2560/48000 (5%)]\tLoss: 0.000012\n",
      "Train Epoch: 23 [3840/48000 (8%)]\tLoss: 0.000009\n",
      "Train Epoch: 23 [5120/48000 (11%)]\tLoss: 0.000014\n",
      "Train Epoch: 23 [6400/48000 (13%)]\tLoss: 0.000023\n",
      "Train Epoch: 23 [7680/48000 (16%)]\tLoss: 0.000011\n",
      "Train Epoch: 23 [8960/48000 (19%)]\tLoss: 0.000033\n",
      "Train Epoch: 23 [10240/48000 (21%)]\tLoss: 0.000023\n",
      "Train Epoch: 23 [11520/48000 (24%)]\tLoss: 0.000020\n",
      "Train Epoch: 23 [12800/48000 (27%)]\tLoss: 0.000015\n",
      "Train Epoch: 23 [14080/48000 (29%)]\tLoss: 0.000011\n",
      "Train Epoch: 23 [15360/48000 (32%)]\tLoss: 0.000025\n",
      "Train Epoch: 23 [16640/48000 (35%)]\tLoss: 0.000011\n",
      "Train Epoch: 23 [17920/48000 (37%)]\tLoss: 0.000026\n",
      "Train Epoch: 23 [19200/48000 (40%)]\tLoss: 0.000011\n",
      "Train Epoch: 23 [20480/48000 (43%)]\tLoss: 0.000028\n",
      "Train Epoch: 23 [21760/48000 (45%)]\tLoss: 0.000013\n",
      "Train Epoch: 23 [23040/48000 (48%)]\tLoss: 0.000017\n",
      "Train Epoch: 23 [24320/48000 (51%)]\tLoss: 0.000014\n",
      "Train Epoch: 23 [25600/48000 (53%)]\tLoss: 0.000013\n",
      "Train Epoch: 23 [26880/48000 (56%)]\tLoss: 0.000064\n",
      "Train Epoch: 23 [28160/48000 (59%)]\tLoss: 0.000031\n",
      "Train Epoch: 23 [29440/48000 (61%)]\tLoss: 0.000009\n",
      "Train Epoch: 23 [30720/48000 (64%)]\tLoss: 0.000018\n",
      "Train Epoch: 23 [32000/48000 (67%)]\tLoss: 0.000012\n",
      "Train Epoch: 23 [33280/48000 (69%)]\tLoss: 0.000018\n",
      "Train Epoch: 23 [34560/48000 (72%)]\tLoss: 0.000024\n",
      "Train Epoch: 23 [35840/48000 (75%)]\tLoss: 0.000032\n",
      "Train Epoch: 23 [37120/48000 (77%)]\tLoss: 0.000014\n",
      "Train Epoch: 23 [38400/48000 (80%)]\tLoss: 0.000013\n",
      "Train Epoch: 23 [39680/48000 (83%)]\tLoss: 0.000011\n",
      "Train Epoch: 23 [40960/48000 (85%)]\tLoss: 0.000017\n",
      "Train Epoch: 23 [42240/48000 (88%)]\tLoss: 0.000047\n",
      "Train Epoch: 23 [43520/48000 (91%)]\tLoss: 0.000007\n",
      "Train Epoch: 23 [44800/48000 (93%)]\tLoss: 0.000008\n",
      "Train Epoch: 23 [46080/48000 (96%)]\tLoss: 0.000027\n",
      "Train Epoch: 23 [47360/48000 (99%)]\tLoss: 0.000011\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 7802/8000 (98%)\n",
      "Train Epoch: 24 [0/48000 (0%)]\tLoss: 0.000030\n",
      "Train Epoch: 24 [1280/48000 (3%)]\tLoss: 0.000021\n",
      "Train Epoch: 24 [2560/48000 (5%)]\tLoss: 0.000018\n",
      "Train Epoch: 24 [3840/48000 (8%)]\tLoss: 0.000011\n",
      "Train Epoch: 24 [5120/48000 (11%)]\tLoss: 0.000017\n",
      "Train Epoch: 24 [6400/48000 (13%)]\tLoss: 0.000094\n",
      "Train Epoch: 24 [7680/48000 (16%)]\tLoss: 0.000009\n",
      "Train Epoch: 24 [8960/48000 (19%)]\tLoss: 0.000005\n",
      "Train Epoch: 24 [10240/48000 (21%)]\tLoss: 0.000054\n",
      "Train Epoch: 24 [11520/48000 (24%)]\tLoss: 0.000013\n",
      "Train Epoch: 24 [12800/48000 (27%)]\tLoss: 0.000011\n",
      "Train Epoch: 24 [14080/48000 (29%)]\tLoss: 0.000016\n",
      "Train Epoch: 24 [15360/48000 (32%)]\tLoss: 0.000019\n",
      "Train Epoch: 24 [16640/48000 (35%)]\tLoss: 0.000050\n",
      "Train Epoch: 24 [17920/48000 (37%)]\tLoss: 0.000335\n",
      "Train Epoch: 24 [19200/48000 (40%)]\tLoss: 0.000020\n",
      "Train Epoch: 24 [20480/48000 (43%)]\tLoss: 0.000026\n",
      "Train Epoch: 24 [21760/48000 (45%)]\tLoss: 0.003144\n",
      "Train Epoch: 24 [23040/48000 (48%)]\tLoss: 0.015532\n",
      "Train Epoch: 24 [24320/48000 (51%)]\tLoss: 0.013518\n",
      "Train Epoch: 24 [25600/48000 (53%)]\tLoss: 0.029067\n",
      "Train Epoch: 24 [26880/48000 (56%)]\tLoss: 0.000180\n",
      "Train Epoch: 24 [28160/48000 (59%)]\tLoss: 0.000855\n",
      "Train Epoch: 24 [29440/48000 (61%)]\tLoss: 0.000471\n",
      "Train Epoch: 24 [30720/48000 (64%)]\tLoss: 0.001091\n",
      "Train Epoch: 24 [32000/48000 (67%)]\tLoss: 0.003560\n",
      "Train Epoch: 24 [33280/48000 (69%)]\tLoss: 0.041807\n",
      "Train Epoch: 24 [34560/48000 (72%)]\tLoss: 0.020697\n",
      "Train Epoch: 24 [35840/48000 (75%)]\tLoss: 0.001303\n",
      "Train Epoch: 24 [37120/48000 (77%)]\tLoss: 0.012595\n",
      "Train Epoch: 24 [38400/48000 (80%)]\tLoss: 0.001401\n",
      "Train Epoch: 24 [39680/48000 (83%)]\tLoss: 0.008936\n",
      "Train Epoch: 24 [40960/48000 (85%)]\tLoss: 0.011556\n",
      "Train Epoch: 24 [42240/48000 (88%)]\tLoss: 0.001110\n",
      "Train Epoch: 24 [43520/48000 (91%)]\tLoss: 0.000582\n",
      "Train Epoch: 24 [44800/48000 (93%)]\tLoss: 0.000182\n",
      "Train Epoch: 24 [46080/48000 (96%)]\tLoss: 0.001373\n",
      "Train Epoch: 24 [47360/48000 (99%)]\tLoss: 0.000688\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 7799/8000 (97%)\n",
      "Train Epoch: 25 [0/48000 (0%)]\tLoss: 0.003156\n",
      "Train Epoch: 25 [1280/48000 (3%)]\tLoss: 0.035190\n",
      "Train Epoch: 25 [2560/48000 (5%)]\tLoss: 0.001303\n",
      "Train Epoch: 25 [3840/48000 (8%)]\tLoss: 0.000461\n",
      "Train Epoch: 25 [5120/48000 (11%)]\tLoss: 0.000349\n",
      "Train Epoch: 25 [6400/48000 (13%)]\tLoss: 0.000323\n",
      "Train Epoch: 25 [7680/48000 (16%)]\tLoss: 0.000275\n",
      "Train Epoch: 25 [8960/48000 (19%)]\tLoss: 0.000167\n",
      "Train Epoch: 25 [10240/48000 (21%)]\tLoss: 0.000093\n",
      "Train Epoch: 25 [11520/48000 (24%)]\tLoss: 0.000365\n",
      "Train Epoch: 25 [12800/48000 (27%)]\tLoss: 0.001592\n",
      "Train Epoch: 25 [14080/48000 (29%)]\tLoss: 0.000672\n",
      "Train Epoch: 25 [15360/48000 (32%)]\tLoss: 0.000081\n",
      "Train Epoch: 25 [16640/48000 (35%)]\tLoss: 0.000204\n",
      "Train Epoch: 25 [17920/48000 (37%)]\tLoss: 0.000214\n",
      "Train Epoch: 25 [19200/48000 (40%)]\tLoss: 0.000059\n",
      "Train Epoch: 25 [20480/48000 (43%)]\tLoss: 0.000420\n",
      "Train Epoch: 25 [21760/48000 (45%)]\tLoss: 0.000100\n",
      "Train Epoch: 25 [23040/48000 (48%)]\tLoss: 0.000101\n",
      "Train Epoch: 25 [24320/48000 (51%)]\tLoss: 0.000257\n",
      "Train Epoch: 25 [25600/48000 (53%)]\tLoss: 0.003250\n",
      "Train Epoch: 25 [26880/48000 (56%)]\tLoss: 0.000121\n",
      "Train Epoch: 25 [28160/48000 (59%)]\tLoss: 0.000242\n",
      "Train Epoch: 25 [29440/48000 (61%)]\tLoss: 0.000081\n",
      "Train Epoch: 25 [30720/48000 (64%)]\tLoss: 0.000072\n",
      "Train Epoch: 25 [32000/48000 (67%)]\tLoss: 0.000406\n",
      "Train Epoch: 25 [33280/48000 (69%)]\tLoss: 0.000046\n",
      "Train Epoch: 25 [34560/48000 (72%)]\tLoss: 0.000119\n",
      "Train Epoch: 25 [35840/48000 (75%)]\tLoss: 0.000080\n",
      "Train Epoch: 25 [37120/48000 (77%)]\tLoss: 0.010897\n",
      "Train Epoch: 25 [38400/48000 (80%)]\tLoss: 0.012371\n",
      "Train Epoch: 25 [39680/48000 (83%)]\tLoss: 0.000103\n",
      "Train Epoch: 25 [40960/48000 (85%)]\tLoss: 0.000279\n",
      "Train Epoch: 25 [42240/48000 (88%)]\tLoss: 0.000174\n",
      "Train Epoch: 25 [43520/48000 (91%)]\tLoss: 0.000054\n",
      "Train Epoch: 25 [44800/48000 (93%)]\tLoss: 0.000162\n",
      "Train Epoch: 25 [46080/48000 (96%)]\tLoss: 0.000322\n",
      "Train Epoch: 25 [47360/48000 (99%)]\tLoss: 0.000158\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 7819/8000 (98%)\n",
      "Train Epoch: 26 [0/48000 (0%)]\tLoss: 0.000601\n",
      "Train Epoch: 26 [1280/48000 (3%)]\tLoss: 0.000342\n",
      "Train Epoch: 26 [2560/48000 (5%)]\tLoss: 0.000397\n",
      "Train Epoch: 26 [3840/48000 (8%)]\tLoss: 0.000227\n",
      "Train Epoch: 26 [5120/48000 (11%)]\tLoss: 0.000044\n",
      "Train Epoch: 26 [6400/48000 (13%)]\tLoss: 0.000106\n",
      "Train Epoch: 26 [7680/48000 (16%)]\tLoss: 0.001420\n",
      "Train Epoch: 26 [8960/48000 (19%)]\tLoss: 0.000650\n",
      "Train Epoch: 26 [10240/48000 (21%)]\tLoss: 0.000159\n",
      "Train Epoch: 26 [11520/48000 (24%)]\tLoss: 0.000123\n",
      "Train Epoch: 26 [12800/48000 (27%)]\tLoss: 0.000087\n",
      "Train Epoch: 26 [14080/48000 (29%)]\tLoss: 0.000164\n",
      "Train Epoch: 26 [15360/48000 (32%)]\tLoss: 0.000150\n",
      "Train Epoch: 26 [16640/48000 (35%)]\tLoss: 0.000475\n",
      "Train Epoch: 26 [17920/48000 (37%)]\tLoss: 0.000097\n",
      "Train Epoch: 26 [19200/48000 (40%)]\tLoss: 0.000116\n",
      "Train Epoch: 26 [20480/48000 (43%)]\tLoss: 0.000220\n",
      "Train Epoch: 26 [21760/48000 (45%)]\tLoss: 0.000293\n",
      "Train Epoch: 26 [23040/48000 (48%)]\tLoss: 0.000063\n",
      "Train Epoch: 26 [24320/48000 (51%)]\tLoss: 0.000282\n",
      "Train Epoch: 26 [25600/48000 (53%)]\tLoss: 0.007016\n",
      "Train Epoch: 26 [26880/48000 (56%)]\tLoss: 0.000071\n",
      "Train Epoch: 26 [28160/48000 (59%)]\tLoss: 0.000183\n",
      "Train Epoch: 26 [29440/48000 (61%)]\tLoss: 0.005662\n",
      "Train Epoch: 26 [30720/48000 (64%)]\tLoss: 0.000140\n",
      "Train Epoch: 26 [32000/48000 (67%)]\tLoss: 0.000196\n",
      "Train Epoch: 26 [33280/48000 (69%)]\tLoss: 0.021964\n",
      "Train Epoch: 26 [34560/48000 (72%)]\tLoss: 0.000941\n",
      "Train Epoch: 26 [35840/48000 (75%)]\tLoss: 0.000251\n",
      "Train Epoch: 26 [37120/48000 (77%)]\tLoss: 0.000618\n",
      "Train Epoch: 26 [38400/48000 (80%)]\tLoss: 0.000259\n",
      "Train Epoch: 26 [39680/48000 (83%)]\tLoss: 0.000858\n",
      "Train Epoch: 26 [40960/48000 (85%)]\tLoss: 0.019545\n",
      "Train Epoch: 26 [42240/48000 (88%)]\tLoss: 0.021091\n",
      "Train Epoch: 26 [43520/48000 (91%)]\tLoss: 0.000185\n",
      "Train Epoch: 26 [44800/48000 (93%)]\tLoss: 0.020665\n",
      "Train Epoch: 26 [46080/48000 (96%)]\tLoss: 0.002108\n",
      "Train Epoch: 26 [47360/48000 (99%)]\tLoss: 0.000484\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 7747/8000 (97%)\n",
      "Train Epoch: 27 [0/48000 (0%)]\tLoss: 0.007834\n",
      "Train Epoch: 27 [1280/48000 (3%)]\tLoss: 0.001434\n",
      "Train Epoch: 27 [2560/48000 (5%)]\tLoss: 0.000380\n",
      "Train Epoch: 27 [3840/48000 (8%)]\tLoss: 0.000425\n",
      "Train Epoch: 27 [5120/48000 (11%)]\tLoss: 0.026532\n",
      "Train Epoch: 27 [6400/48000 (13%)]\tLoss: 0.000175\n",
      "Train Epoch: 27 [7680/48000 (16%)]\tLoss: 0.000357\n",
      "Train Epoch: 27 [8960/48000 (19%)]\tLoss: 0.000422\n",
      "Train Epoch: 27 [10240/48000 (21%)]\tLoss: 0.001529\n",
      "Train Epoch: 27 [11520/48000 (24%)]\tLoss: 0.000182\n",
      "Train Epoch: 27 [12800/48000 (27%)]\tLoss: 0.010138\n",
      "Train Epoch: 27 [14080/48000 (29%)]\tLoss: 0.031269\n",
      "Train Epoch: 27 [15360/48000 (32%)]\tLoss: 0.000327\n",
      "Train Epoch: 27 [16640/48000 (35%)]\tLoss: 0.000644\n",
      "Train Epoch: 27 [17920/48000 (37%)]\tLoss: 0.005068\n",
      "Train Epoch: 27 [19200/48000 (40%)]\tLoss: 0.000616\n",
      "Train Epoch: 27 [20480/48000 (43%)]\tLoss: 0.000129\n",
      "Train Epoch: 27 [21760/48000 (45%)]\tLoss: 0.000204\n",
      "Train Epoch: 27 [23040/48000 (48%)]\tLoss: 0.001315\n",
      "Train Epoch: 27 [24320/48000 (51%)]\tLoss: 0.000274\n",
      "Train Epoch: 27 [25600/48000 (53%)]\tLoss: 0.000904\n",
      "Train Epoch: 27 [26880/48000 (56%)]\tLoss: 0.004017\n",
      "Train Epoch: 27 [28160/48000 (59%)]\tLoss: 0.000746\n",
      "Train Epoch: 27 [29440/48000 (61%)]\tLoss: 0.000085\n",
      "Train Epoch: 27 [30720/48000 (64%)]\tLoss: 0.030861\n",
      "Train Epoch: 27 [32000/48000 (67%)]\tLoss: 0.000597\n",
      "Train Epoch: 27 [33280/48000 (69%)]\tLoss: 0.000144\n",
      "Train Epoch: 27 [34560/48000 (72%)]\tLoss: 0.004845\n",
      "Train Epoch: 27 [35840/48000 (75%)]\tLoss: 0.000321\n",
      "Train Epoch: 27 [37120/48000 (77%)]\tLoss: 0.000172\n",
      "Train Epoch: 27 [38400/48000 (80%)]\tLoss: 0.008838\n",
      "Train Epoch: 27 [39680/48000 (83%)]\tLoss: 0.006139\n",
      "Train Epoch: 27 [40960/48000 (85%)]\tLoss: 0.002282\n",
      "Train Epoch: 27 [42240/48000 (88%)]\tLoss: 0.000049\n",
      "Train Epoch: 27 [43520/48000 (91%)]\tLoss: 0.000102\n",
      "Train Epoch: 27 [44800/48000 (93%)]\tLoss: 0.000068\n",
      "Train Epoch: 27 [46080/48000 (96%)]\tLoss: 0.000077\n",
      "Train Epoch: 27 [47360/48000 (99%)]\tLoss: 0.033135\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 7788/8000 (97%)\n",
      "Train Epoch: 28 [0/48000 (0%)]\tLoss: 0.000415\n",
      "Train Epoch: 28 [1280/48000 (3%)]\tLoss: 0.000097\n",
      "Train Epoch: 28 [2560/48000 (5%)]\tLoss: 0.013494\n",
      "Train Epoch: 28 [3840/48000 (8%)]\tLoss: 0.000043\n",
      "Train Epoch: 28 [5120/48000 (11%)]\tLoss: 0.000066\n",
      "Train Epoch: 28 [6400/48000 (13%)]\tLoss: 0.000069\n",
      "Train Epoch: 28 [7680/48000 (16%)]\tLoss: 0.000064\n",
      "Train Epoch: 28 [8960/48000 (19%)]\tLoss: 0.000047\n",
      "Train Epoch: 28 [10240/48000 (21%)]\tLoss: 0.011207\n",
      "Train Epoch: 28 [11520/48000 (24%)]\tLoss: 0.000912\n",
      "Train Epoch: 28 [12800/48000 (27%)]\tLoss: 0.000136\n",
      "Train Epoch: 28 [14080/48000 (29%)]\tLoss: 0.056874\n",
      "Train Epoch: 28 [15360/48000 (32%)]\tLoss: 0.002594\n",
      "Train Epoch: 28 [16640/48000 (35%)]\tLoss: 0.000133\n",
      "Train Epoch: 28 [17920/48000 (37%)]\tLoss: 0.000319\n",
      "Train Epoch: 28 [19200/48000 (40%)]\tLoss: 0.002256\n",
      "Train Epoch: 28 [20480/48000 (43%)]\tLoss: 0.000077\n",
      "Train Epoch: 28 [21760/48000 (45%)]\tLoss: 0.000162\n",
      "Train Epoch: 28 [23040/48000 (48%)]\tLoss: 0.000102\n",
      "Train Epoch: 28 [24320/48000 (51%)]\tLoss: 0.000124\n",
      "Train Epoch: 28 [25600/48000 (53%)]\tLoss: 0.000065\n",
      "Train Epoch: 28 [26880/48000 (56%)]\tLoss: 0.005360\n",
      "Train Epoch: 28 [28160/48000 (59%)]\tLoss: 0.000076\n",
      "Train Epoch: 28 [29440/48000 (61%)]\tLoss: 0.000059\n",
      "Train Epoch: 28 [30720/48000 (64%)]\tLoss: 0.000077\n",
      "Train Epoch: 28 [32000/48000 (67%)]\tLoss: 0.000048\n",
      "Train Epoch: 28 [33280/48000 (69%)]\tLoss: 0.000038\n",
      "Train Epoch: 28 [34560/48000 (72%)]\tLoss: 0.000055\n",
      "Train Epoch: 28 [35840/48000 (75%)]\tLoss: 0.000040\n",
      "Train Epoch: 28 [37120/48000 (77%)]\tLoss: 0.000054\n",
      "Train Epoch: 28 [38400/48000 (80%)]\tLoss: 0.000061\n",
      "Train Epoch: 28 [39680/48000 (83%)]\tLoss: 0.000029\n",
      "Train Epoch: 28 [40960/48000 (85%)]\tLoss: 0.000080\n",
      "Train Epoch: 28 [42240/48000 (88%)]\tLoss: 0.000384\n",
      "Train Epoch: 28 [43520/48000 (91%)]\tLoss: 0.000037\n",
      "Train Epoch: 28 [44800/48000 (93%)]\tLoss: 0.000063\n",
      "Train Epoch: 28 [46080/48000 (96%)]\tLoss: 0.000037\n",
      "Train Epoch: 28 [47360/48000 (99%)]\tLoss: 0.000067\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 7834/8000 (98%)\n",
      "Train Epoch: 29 [0/48000 (0%)]\tLoss: 0.000028\n",
      "Train Epoch: 29 [1280/48000 (3%)]\tLoss: 0.005403\n",
      "Train Epoch: 29 [2560/48000 (5%)]\tLoss: 0.000024\n",
      "Train Epoch: 29 [3840/48000 (8%)]\tLoss: 0.000019\n",
      "Train Epoch: 29 [5120/48000 (11%)]\tLoss: 0.000121\n",
      "Train Epoch: 29 [6400/48000 (13%)]\tLoss: 0.000053\n",
      "Train Epoch: 29 [7680/48000 (16%)]\tLoss: 0.000146\n",
      "Train Epoch: 29 [8960/48000 (19%)]\tLoss: 0.000208\n",
      "Train Epoch: 29 [10240/48000 (21%)]\tLoss: 0.000118\n",
      "Train Epoch: 29 [11520/48000 (24%)]\tLoss: 0.000025\n",
      "Train Epoch: 29 [12800/48000 (27%)]\tLoss: 0.000047\n",
      "Train Epoch: 29 [14080/48000 (29%)]\tLoss: 0.037081\n",
      "Train Epoch: 29 [15360/48000 (32%)]\tLoss: 0.000082\n",
      "Train Epoch: 29 [16640/48000 (35%)]\tLoss: 0.032191\n",
      "Train Epoch: 29 [17920/48000 (37%)]\tLoss: 0.000071\n",
      "Train Epoch: 29 [19200/48000 (40%)]\tLoss: 0.000058\n",
      "Train Epoch: 29 [20480/48000 (43%)]\tLoss: 0.000094\n",
      "Train Epoch: 29 [21760/48000 (45%)]\tLoss: 0.000102\n",
      "Train Epoch: 29 [23040/48000 (48%)]\tLoss: 0.001493\n",
      "Train Epoch: 29 [24320/48000 (51%)]\tLoss: 0.000060\n",
      "Train Epoch: 29 [25600/48000 (53%)]\tLoss: 0.000177\n",
      "Train Epoch: 29 [26880/48000 (56%)]\tLoss: 0.000180\n",
      "Train Epoch: 29 [28160/48000 (59%)]\tLoss: 0.062161\n",
      "Train Epoch: 29 [29440/48000 (61%)]\tLoss: 0.000034\n",
      "Train Epoch: 29 [30720/48000 (64%)]\tLoss: 0.000196\n",
      "Train Epoch: 29 [32000/48000 (67%)]\tLoss: 0.000050\n",
      "Train Epoch: 29 [33280/48000 (69%)]\tLoss: 0.000039\n",
      "Train Epoch: 29 [34560/48000 (72%)]\tLoss: 0.000126\n",
      "Train Epoch: 29 [35840/48000 (75%)]\tLoss: 0.000045\n",
      "Train Epoch: 29 [37120/48000 (77%)]\tLoss: 0.000033\n",
      "Train Epoch: 29 [38400/48000 (80%)]\tLoss: 0.000027\n",
      "Train Epoch: 29 [39680/48000 (83%)]\tLoss: 0.000032\n",
      "Train Epoch: 29 [40960/48000 (85%)]\tLoss: 0.000037\n",
      "Train Epoch: 29 [42240/48000 (88%)]\tLoss: 0.000049\n",
      "Train Epoch: 29 [43520/48000 (91%)]\tLoss: 0.000017\n",
      "Train Epoch: 29 [44800/48000 (93%)]\tLoss: 0.000031\n",
      "Train Epoch: 29 [46080/48000 (96%)]\tLoss: 0.000026\n",
      "Train Epoch: 29 [47360/48000 (99%)]\tLoss: 0.000025\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 7826/8000 (98%)\n",
      "Train Epoch: 30 [0/48000 (0%)]\tLoss: 0.000081\n",
      "Train Epoch: 30 [1280/48000 (3%)]\tLoss: 0.000034\n",
      "Train Epoch: 30 [2560/48000 (5%)]\tLoss: 0.000032\n",
      "Train Epoch: 30 [3840/48000 (8%)]\tLoss: 0.000035\n",
      "Train Epoch: 30 [5120/48000 (11%)]\tLoss: 0.000024\n",
      "Train Epoch: 30 [6400/48000 (13%)]\tLoss: 0.000030\n",
      "Train Epoch: 30 [7680/48000 (16%)]\tLoss: 0.000025\n",
      "Train Epoch: 30 [8960/48000 (19%)]\tLoss: 0.000027\n",
      "Train Epoch: 30 [10240/48000 (21%)]\tLoss: 0.000019\n",
      "Train Epoch: 30 [11520/48000 (24%)]\tLoss: 0.000023\n",
      "Train Epoch: 30 [12800/48000 (27%)]\tLoss: 0.000023\n",
      "Train Epoch: 30 [14080/48000 (29%)]\tLoss: 0.000034\n",
      "Train Epoch: 30 [15360/48000 (32%)]\tLoss: 0.000373\n",
      "Train Epoch: 30 [16640/48000 (35%)]\tLoss: 0.000024\n",
      "Train Epoch: 30 [17920/48000 (37%)]\tLoss: 0.000020\n",
      "Train Epoch: 30 [19200/48000 (40%)]\tLoss: 0.000021\n",
      "Train Epoch: 30 [20480/48000 (43%)]\tLoss: 0.000037\n",
      "Train Epoch: 30 [21760/48000 (45%)]\tLoss: 0.000089\n",
      "Train Epoch: 30 [23040/48000 (48%)]\tLoss: 0.002250\n",
      "Train Epoch: 30 [24320/48000 (51%)]\tLoss: 0.000019\n",
      "Train Epoch: 30 [25600/48000 (53%)]\tLoss: 0.000044\n",
      "Train Epoch: 30 [26880/48000 (56%)]\tLoss: 0.000022\n",
      "Train Epoch: 30 [28160/48000 (59%)]\tLoss: 0.000054\n",
      "Train Epoch: 30 [29440/48000 (61%)]\tLoss: 0.000013\n",
      "Train Epoch: 30 [30720/48000 (64%)]\tLoss: 0.000054\n",
      "Train Epoch: 30 [32000/48000 (67%)]\tLoss: 0.000162\n",
      "Train Epoch: 30 [33280/48000 (69%)]\tLoss: 0.000022\n",
      "Train Epoch: 30 [34560/48000 (72%)]\tLoss: 0.005186\n",
      "Train Epoch: 30 [35840/48000 (75%)]\tLoss: 0.000103\n",
      "Train Epoch: 30 [37120/48000 (77%)]\tLoss: 0.000110\n",
      "Train Epoch: 30 [38400/48000 (80%)]\tLoss: 0.002912\n",
      "Train Epoch: 30 [39680/48000 (83%)]\tLoss: 0.006361\n",
      "Train Epoch: 30 [40960/48000 (85%)]\tLoss: 0.003613\n",
      "Train Epoch: 30 [42240/48000 (88%)]\tLoss: 0.007962\n",
      "Train Epoch: 30 [43520/48000 (91%)]\tLoss: 0.000888\n",
      "Train Epoch: 30 [44800/48000 (93%)]\tLoss: 0.000471\n",
      "Train Epoch: 30 [46080/48000 (96%)]\tLoss: 0.000848\n",
      "Train Epoch: 30 [47360/48000 (99%)]\tLoss: 0.000262\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 7773/8000 (97%)\n",
      "Train Epoch: 31 [0/48000 (0%)]\tLoss: 0.000294\n",
      "Train Epoch: 31 [1280/48000 (3%)]\tLoss: 0.005056\n",
      "Train Epoch: 31 [2560/48000 (5%)]\tLoss: 0.000165\n",
      "Train Epoch: 31 [3840/48000 (8%)]\tLoss: 0.000591\n",
      "Train Epoch: 31 [5120/48000 (11%)]\tLoss: 0.001066\n",
      "Train Epoch: 31 [6400/48000 (13%)]\tLoss: 0.000770\n",
      "Train Epoch: 31 [7680/48000 (16%)]\tLoss: 0.000443\n",
      "Train Epoch: 31 [8960/48000 (19%)]\tLoss: 0.000510\n",
      "Train Epoch: 31 [10240/48000 (21%)]\tLoss: 0.001985\n",
      "Train Epoch: 31 [11520/48000 (24%)]\tLoss: 0.000300\n",
      "Train Epoch: 31 [12800/48000 (27%)]\tLoss: 0.000197\n",
      "Train Epoch: 31 [14080/48000 (29%)]\tLoss: 0.000101\n",
      "Train Epoch: 31 [15360/48000 (32%)]\tLoss: 0.000302\n",
      "Train Epoch: 31 [16640/48000 (35%)]\tLoss: 0.000192\n",
      "Train Epoch: 31 [17920/48000 (37%)]\tLoss: 0.000157\n",
      "Train Epoch: 31 [19200/48000 (40%)]\tLoss: 0.000095\n",
      "Train Epoch: 31 [20480/48000 (43%)]\tLoss: 0.000119\n",
      "Train Epoch: 31 [21760/48000 (45%)]\tLoss: 0.000095\n",
      "Train Epoch: 31 [23040/48000 (48%)]\tLoss: 0.000169\n",
      "Train Epoch: 31 [24320/48000 (51%)]\tLoss: 0.000487\n",
      "Train Epoch: 31 [25600/48000 (53%)]\tLoss: 0.000080\n",
      "Train Epoch: 31 [26880/48000 (56%)]\tLoss: 0.000077\n",
      "Train Epoch: 31 [28160/48000 (59%)]\tLoss: 0.000084\n",
      "Train Epoch: 31 [29440/48000 (61%)]\tLoss: 0.000177\n",
      "Train Epoch: 31 [30720/48000 (64%)]\tLoss: 0.000093\n",
      "Train Epoch: 31 [32000/48000 (67%)]\tLoss: 0.000068\n",
      "Train Epoch: 31 [33280/48000 (69%)]\tLoss: 0.000051\n",
      "Train Epoch: 31 [34560/48000 (72%)]\tLoss: 0.000093\n",
      "Train Epoch: 31 [35840/48000 (75%)]\tLoss: 0.000092\n",
      "Train Epoch: 31 [37120/48000 (77%)]\tLoss: 0.000092\n",
      "Train Epoch: 31 [38400/48000 (80%)]\tLoss: 0.000105\n",
      "Train Epoch: 31 [39680/48000 (83%)]\tLoss: 0.000038\n",
      "Train Epoch: 31 [40960/48000 (85%)]\tLoss: 0.000057\n",
      "Train Epoch: 31 [42240/48000 (88%)]\tLoss: 0.000054\n",
      "Train Epoch: 31 [43520/48000 (91%)]\tLoss: 0.000104\n",
      "Train Epoch: 31 [44800/48000 (93%)]\tLoss: 0.000366\n",
      "Train Epoch: 31 [46080/48000 (96%)]\tLoss: 0.000419\n",
      "Train Epoch: 31 [47360/48000 (99%)]\tLoss: 0.000071\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 7779/8000 (97%)\n",
      "Train Epoch: 32 [0/48000 (0%)]\tLoss: 0.000611\n",
      "Train Epoch: 32 [1280/48000 (3%)]\tLoss: 0.000051\n",
      "Train Epoch: 32 [2560/48000 (5%)]\tLoss: 0.000094\n",
      "Train Epoch: 32 [3840/48000 (8%)]\tLoss: 0.000180\n",
      "Train Epoch: 32 [5120/48000 (11%)]\tLoss: 0.000132\n",
      "Train Epoch: 32 [6400/48000 (13%)]\tLoss: 0.000282\n",
      "Train Epoch: 32 [7680/48000 (16%)]\tLoss: 0.000060\n",
      "Train Epoch: 32 [8960/48000 (19%)]\tLoss: 0.000051\n",
      "Train Epoch: 32 [10240/48000 (21%)]\tLoss: 0.000057\n",
      "Train Epoch: 32 [11520/48000 (24%)]\tLoss: 0.000063\n",
      "Train Epoch: 32 [12800/48000 (27%)]\tLoss: 0.000042\n",
      "Train Epoch: 32 [14080/48000 (29%)]\tLoss: 0.000063\n",
      "Train Epoch: 32 [15360/48000 (32%)]\tLoss: 0.000049\n",
      "Train Epoch: 32 [16640/48000 (35%)]\tLoss: 0.000039\n",
      "Train Epoch: 32 [17920/48000 (37%)]\tLoss: 0.000042\n",
      "Train Epoch: 32 [19200/48000 (40%)]\tLoss: 0.000050\n",
      "Train Epoch: 32 [20480/48000 (43%)]\tLoss: 0.000057\n",
      "Train Epoch: 32 [21760/48000 (45%)]\tLoss: 0.000036\n",
      "Train Epoch: 32 [23040/48000 (48%)]\tLoss: 0.000032\n",
      "Train Epoch: 32 [24320/48000 (51%)]\tLoss: 0.000051\n",
      "Train Epoch: 32 [25600/48000 (53%)]\tLoss: 0.000038\n",
      "Train Epoch: 32 [26880/48000 (56%)]\tLoss: 0.000028\n",
      "Train Epoch: 32 [28160/48000 (59%)]\tLoss: 0.000052\n",
      "Train Epoch: 32 [29440/48000 (61%)]\tLoss: 0.000029\n",
      "Train Epoch: 32 [30720/48000 (64%)]\tLoss: 0.000039\n",
      "Train Epoch: 32 [32000/48000 (67%)]\tLoss: 0.000032\n",
      "Train Epoch: 32 [33280/48000 (69%)]\tLoss: 0.000822\n",
      "Train Epoch: 32 [34560/48000 (72%)]\tLoss: 0.000042\n",
      "Train Epoch: 32 [35840/48000 (75%)]\tLoss: 0.000026\n",
      "Train Epoch: 32 [37120/48000 (77%)]\tLoss: 0.000042\n",
      "Train Epoch: 32 [38400/48000 (80%)]\tLoss: 0.000022\n",
      "Train Epoch: 32 [39680/48000 (83%)]\tLoss: 0.000016\n",
      "Train Epoch: 32 [40960/48000 (85%)]\tLoss: 0.000036\n",
      "Train Epoch: 32 [42240/48000 (88%)]\tLoss: 0.000046\n",
      "Train Epoch: 32 [43520/48000 (91%)]\tLoss: 0.000034\n",
      "Train Epoch: 32 [44800/48000 (93%)]\tLoss: 0.000016\n",
      "Train Epoch: 32 [46080/48000 (96%)]\tLoss: 0.000033\n",
      "Train Epoch: 32 [47360/48000 (99%)]\tLoss: 0.000024\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 7827/8000 (98%)\n",
      "Train Epoch: 33 [0/48000 (0%)]\tLoss: 0.000045\n",
      "Train Epoch: 33 [1280/48000 (3%)]\tLoss: 0.000032\n",
      "Train Epoch: 33 [2560/48000 (5%)]\tLoss: 0.000021\n",
      "Train Epoch: 33 [3840/48000 (8%)]\tLoss: 0.000020\n",
      "Train Epoch: 33 [5120/48000 (11%)]\tLoss: 0.000039\n",
      "Train Epoch: 33 [6400/48000 (13%)]\tLoss: 0.000043\n",
      "Train Epoch: 33 [7680/48000 (16%)]\tLoss: 0.000042\n",
      "Train Epoch: 33 [8960/48000 (19%)]\tLoss: 0.000037\n",
      "Train Epoch: 33 [10240/48000 (21%)]\tLoss: 0.000023\n",
      "Train Epoch: 33 [11520/48000 (24%)]\tLoss: 0.000016\n",
      "Train Epoch: 33 [12800/48000 (27%)]\tLoss: 0.000016\n",
      "Train Epoch: 33 [14080/48000 (29%)]\tLoss: 0.000027\n",
      "Train Epoch: 33 [15360/48000 (32%)]\tLoss: 0.000035\n",
      "Train Epoch: 33 [16640/48000 (35%)]\tLoss: 0.000023\n",
      "Train Epoch: 33 [17920/48000 (37%)]\tLoss: 0.000138\n",
      "Train Epoch: 33 [19200/48000 (40%)]\tLoss: 0.000031\n",
      "Train Epoch: 33 [20480/48000 (43%)]\tLoss: 0.000322\n",
      "Train Epoch: 33 [21760/48000 (45%)]\tLoss: 0.000086\n",
      "Train Epoch: 33 [23040/48000 (48%)]\tLoss: 0.001367\n",
      "Train Epoch: 33 [24320/48000 (51%)]\tLoss: 0.000025\n",
      "Train Epoch: 33 [25600/48000 (53%)]\tLoss: 0.000428\n",
      "Train Epoch: 33 [26880/48000 (56%)]\tLoss: 0.000029\n",
      "Train Epoch: 33 [28160/48000 (59%)]\tLoss: 0.000117\n",
      "Train Epoch: 33 [29440/48000 (61%)]\tLoss: 0.000085\n",
      "Train Epoch: 33 [30720/48000 (64%)]\tLoss: 0.000218\n",
      "Train Epoch: 33 [32000/48000 (67%)]\tLoss: 0.000113\n",
      "Train Epoch: 33 [33280/48000 (69%)]\tLoss: 0.018526\n",
      "Train Epoch: 33 [34560/48000 (72%)]\tLoss: 0.000419\n",
      "Train Epoch: 33 [35840/48000 (75%)]\tLoss: 0.000885\n",
      "Train Epoch: 33 [37120/48000 (77%)]\tLoss: 0.000047\n",
      "Train Epoch: 33 [38400/48000 (80%)]\tLoss: 0.000074\n",
      "Train Epoch: 33 [39680/48000 (83%)]\tLoss: 0.000163\n",
      "Train Epoch: 33 [40960/48000 (85%)]\tLoss: 0.000173\n",
      "Train Epoch: 33 [42240/48000 (88%)]\tLoss: 0.000921\n",
      "Train Epoch: 33 [43520/48000 (91%)]\tLoss: 0.000203\n",
      "Train Epoch: 33 [44800/48000 (93%)]\tLoss: 0.000613\n",
      "Train Epoch: 33 [46080/48000 (96%)]\tLoss: 0.000542\n",
      "Train Epoch: 33 [47360/48000 (99%)]\tLoss: 0.001234\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 7815/8000 (98%)\n",
      "Train Epoch: 34 [0/48000 (0%)]\tLoss: 0.000173\n",
      "Train Epoch: 34 [1280/48000 (3%)]\tLoss: 0.015932\n",
      "Train Epoch: 34 [2560/48000 (5%)]\tLoss: 0.000566\n",
      "Train Epoch: 34 [3840/48000 (8%)]\tLoss: 0.000083\n",
      "Train Epoch: 34 [5120/48000 (11%)]\tLoss: 0.003666\n",
      "Train Epoch: 34 [6400/48000 (13%)]\tLoss: 0.019819\n",
      "Train Epoch: 34 [7680/48000 (16%)]\tLoss: 0.006081\n",
      "Train Epoch: 34 [8960/48000 (19%)]\tLoss: 0.000047\n",
      "Train Epoch: 34 [10240/48000 (21%)]\tLoss: 0.000089\n",
      "Train Epoch: 34 [11520/48000 (24%)]\tLoss: 0.000072\n",
      "Train Epoch: 34 [12800/48000 (27%)]\tLoss: 0.000170\n",
      "Train Epoch: 34 [14080/48000 (29%)]\tLoss: 0.000165\n",
      "Train Epoch: 34 [15360/48000 (32%)]\tLoss: 0.000070\n",
      "Train Epoch: 34 [16640/48000 (35%)]\tLoss: 0.000128\n",
      "Train Epoch: 34 [17920/48000 (37%)]\tLoss: 0.000212\n",
      "Train Epoch: 34 [19200/48000 (40%)]\tLoss: 0.000036\n",
      "Train Epoch: 34 [20480/48000 (43%)]\tLoss: 0.043103\n",
      "Train Epoch: 34 [21760/48000 (45%)]\tLoss: 0.000103\n",
      "Train Epoch: 34 [23040/48000 (48%)]\tLoss: 0.000445\n",
      "Train Epoch: 34 [24320/48000 (51%)]\tLoss: 0.000088\n",
      "Train Epoch: 34 [25600/48000 (53%)]\tLoss: 0.000081\n",
      "Train Epoch: 34 [26880/48000 (56%)]\tLoss: 0.000114\n",
      "Train Epoch: 34 [28160/48000 (59%)]\tLoss: 0.000119\n",
      "Train Epoch: 34 [29440/48000 (61%)]\tLoss: 0.000072\n",
      "Train Epoch: 34 [30720/48000 (64%)]\tLoss: 0.000175\n",
      "Train Epoch: 34 [32000/48000 (67%)]\tLoss: 0.000152\n",
      "Train Epoch: 34 [33280/48000 (69%)]\tLoss: 0.000228\n",
      "Train Epoch: 34 [34560/48000 (72%)]\tLoss: 0.000353\n",
      "Train Epoch: 34 [35840/48000 (75%)]\tLoss: 0.000202\n",
      "Train Epoch: 34 [37120/48000 (77%)]\tLoss: 0.003031\n",
      "Train Epoch: 34 [38400/48000 (80%)]\tLoss: 0.000175\n",
      "Train Epoch: 34 [39680/48000 (83%)]\tLoss: 0.000098\n",
      "Train Epoch: 34 [40960/48000 (85%)]\tLoss: 0.000138\n",
      "Train Epoch: 34 [42240/48000 (88%)]\tLoss: 0.000570\n",
      "Train Epoch: 34 [43520/48000 (91%)]\tLoss: 0.000104\n",
      "Train Epoch: 34 [44800/48000 (93%)]\tLoss: 0.000506\n",
      "Train Epoch: 34 [46080/48000 (96%)]\tLoss: 0.000377\n",
      "Train Epoch: 34 [47360/48000 (99%)]\tLoss: 0.000339\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 7840/8000 (98%)\n",
      "Train Epoch: 35 [0/48000 (0%)]\tLoss: 0.000142\n",
      "Train Epoch: 35 [1280/48000 (3%)]\tLoss: 0.000331\n",
      "Train Epoch: 35 [2560/48000 (5%)]\tLoss: 0.000081\n",
      "Train Epoch: 35 [3840/48000 (8%)]\tLoss: 0.000132\n",
      "Train Epoch: 35 [5120/48000 (11%)]\tLoss: 0.000207\n",
      "Train Epoch: 35 [6400/48000 (13%)]\tLoss: 0.000081\n",
      "Train Epoch: 35 [7680/48000 (16%)]\tLoss: 0.000087\n",
      "Train Epoch: 35 [8960/48000 (19%)]\tLoss: 0.000040\n",
      "Train Epoch: 35 [10240/48000 (21%)]\tLoss: 0.000042\n",
      "Train Epoch: 35 [11520/48000 (24%)]\tLoss: 0.000126\n",
      "Train Epoch: 35 [12800/48000 (27%)]\tLoss: 0.000146\n",
      "Train Epoch: 35 [14080/48000 (29%)]\tLoss: 0.000061\n",
      "Train Epoch: 35 [15360/48000 (32%)]\tLoss: 0.000219\n",
      "Train Epoch: 35 [16640/48000 (35%)]\tLoss: 0.001733\n",
      "Train Epoch: 35 [17920/48000 (37%)]\tLoss: 0.000033\n",
      "Train Epoch: 35 [19200/48000 (40%)]\tLoss: 0.000030\n",
      "Train Epoch: 35 [20480/48000 (43%)]\tLoss: 0.000027\n",
      "Train Epoch: 35 [21760/48000 (45%)]\tLoss: 0.000041\n",
      "Train Epoch: 35 [23040/48000 (48%)]\tLoss: 0.000042\n",
      "Train Epoch: 35 [24320/48000 (51%)]\tLoss: 0.000146\n",
      "Train Epoch: 35 [25600/48000 (53%)]\tLoss: 0.000034\n",
      "Train Epoch: 35 [26880/48000 (56%)]\tLoss: 0.000031\n",
      "Train Epoch: 35 [28160/48000 (59%)]\tLoss: 0.000026\n",
      "Train Epoch: 35 [29440/48000 (61%)]\tLoss: 0.000023\n",
      "Train Epoch: 35 [30720/48000 (64%)]\tLoss: 0.000061\n",
      "Train Epoch: 35 [32000/48000 (67%)]\tLoss: 0.000096\n",
      "Train Epoch: 35 [33280/48000 (69%)]\tLoss: 0.000041\n",
      "Train Epoch: 35 [34560/48000 (72%)]\tLoss: 0.000066\n",
      "Train Epoch: 35 [35840/48000 (75%)]\tLoss: 0.000022\n",
      "Train Epoch: 35 [37120/48000 (77%)]\tLoss: 0.000025\n",
      "Train Epoch: 35 [38400/48000 (80%)]\tLoss: 0.000019\n",
      "Train Epoch: 35 [39680/48000 (83%)]\tLoss: 0.000310\n",
      "Train Epoch: 35 [40960/48000 (85%)]\tLoss: 0.000442\n",
      "Train Epoch: 35 [42240/48000 (88%)]\tLoss: 0.000159\n",
      "Train Epoch: 35 [43520/48000 (91%)]\tLoss: 0.000064\n",
      "Train Epoch: 35 [44800/48000 (93%)]\tLoss: 0.000026\n",
      "Train Epoch: 35 [46080/48000 (96%)]\tLoss: 0.000144\n",
      "Train Epoch: 35 [47360/48000 (99%)]\tLoss: 0.000051\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 7825/8000 (98%)\n",
      "Train Epoch: 36 [0/48000 (0%)]\tLoss: 0.000062\n",
      "Train Epoch: 36 [1280/48000 (3%)]\tLoss: 0.000085\n",
      "Train Epoch: 36 [2560/48000 (5%)]\tLoss: 0.001564\n",
      "Train Epoch: 36 [3840/48000 (8%)]\tLoss: 0.000045\n",
      "Train Epoch: 36 [5120/48000 (11%)]\tLoss: 0.000783\n",
      "Train Epoch: 36 [6400/48000 (13%)]\tLoss: 0.000273\n",
      "Train Epoch: 36 [7680/48000 (16%)]\tLoss: 0.000139\n",
      "Train Epoch: 36 [8960/48000 (19%)]\tLoss: 0.000031\n",
      "Train Epoch: 36 [10240/48000 (21%)]\tLoss: 0.000405\n",
      "Train Epoch: 36 [11520/48000 (24%)]\tLoss: 0.000054\n",
      "Train Epoch: 36 [12800/48000 (27%)]\tLoss: 0.000077\n",
      "Train Epoch: 36 [14080/48000 (29%)]\tLoss: 0.000140\n",
      "Train Epoch: 36 [15360/48000 (32%)]\tLoss: 0.000076\n",
      "Train Epoch: 36 [16640/48000 (35%)]\tLoss: 0.000030\n",
      "Train Epoch: 36 [17920/48000 (37%)]\tLoss: 0.000125\n",
      "Train Epoch: 36 [19200/48000 (40%)]\tLoss: 0.000168\n",
      "Train Epoch: 36 [20480/48000 (43%)]\tLoss: 0.037777\n",
      "Train Epoch: 36 [21760/48000 (45%)]\tLoss: 0.012798\n",
      "Train Epoch: 36 [23040/48000 (48%)]\tLoss: 0.002317\n",
      "Train Epoch: 36 [24320/48000 (51%)]\tLoss: 0.001085\n",
      "Train Epoch: 36 [25600/48000 (53%)]\tLoss: 0.000093\n",
      "Train Epoch: 36 [26880/48000 (56%)]\tLoss: 0.000534\n",
      "Train Epoch: 36 [28160/48000 (59%)]\tLoss: 0.000145\n",
      "Train Epoch: 36 [29440/48000 (61%)]\tLoss: 0.000188\n",
      "Train Epoch: 36 [30720/48000 (64%)]\tLoss: 0.000763\n",
      "Train Epoch: 36 [32000/48000 (67%)]\tLoss: 0.000102\n",
      "Train Epoch: 36 [33280/48000 (69%)]\tLoss: 0.001349\n",
      "Train Epoch: 36 [34560/48000 (72%)]\tLoss: 0.000170\n",
      "Train Epoch: 36 [35840/48000 (75%)]\tLoss: 0.000094\n",
      "Train Epoch: 36 [37120/48000 (77%)]\tLoss: 0.000343\n",
      "Train Epoch: 36 [38400/48000 (80%)]\tLoss: 0.001278\n",
      "Train Epoch: 36 [39680/48000 (83%)]\tLoss: 0.085267\n",
      "Train Epoch: 36 [40960/48000 (85%)]\tLoss: 0.001325\n",
      "Train Epoch: 36 [42240/48000 (88%)]\tLoss: 0.000689\n",
      "Train Epoch: 36 [43520/48000 (91%)]\tLoss: 0.000284\n",
      "Train Epoch: 36 [44800/48000 (93%)]\tLoss: 0.000482\n",
      "Train Epoch: 36 [46080/48000 (96%)]\tLoss: 0.000239\n",
      "Train Epoch: 36 [47360/48000 (99%)]\tLoss: 0.009270\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 7822/8000 (98%)\n",
      "Train Epoch: 37 [0/48000 (0%)]\tLoss: 0.000198\n",
      "Train Epoch: 37 [1280/48000 (3%)]\tLoss: 0.000318\n",
      "Train Epoch: 37 [2560/48000 (5%)]\tLoss: 0.000311\n",
      "Train Epoch: 37 [3840/48000 (8%)]\tLoss: 0.000175\n",
      "Train Epoch: 37 [5120/48000 (11%)]\tLoss: 0.000408\n",
      "Train Epoch: 37 [6400/48000 (13%)]\tLoss: 0.000072\n",
      "Train Epoch: 37 [7680/48000 (16%)]\tLoss: 0.000173\n",
      "Train Epoch: 37 [8960/48000 (19%)]\tLoss: 0.000066\n",
      "Train Epoch: 37 [10240/48000 (21%)]\tLoss: 0.000055\n",
      "Train Epoch: 37 [11520/48000 (24%)]\tLoss: 0.000125\n",
      "Train Epoch: 37 [12800/48000 (27%)]\tLoss: 0.000055\n",
      "Train Epoch: 37 [14080/48000 (29%)]\tLoss: 0.000100\n",
      "Train Epoch: 37 [15360/48000 (32%)]\tLoss: 0.000056\n",
      "Train Epoch: 37 [16640/48000 (35%)]\tLoss: 0.000078\n",
      "Train Epoch: 37 [17920/48000 (37%)]\tLoss: 0.000064\n",
      "Train Epoch: 37 [19200/48000 (40%)]\tLoss: 0.000064\n",
      "Train Epoch: 37 [20480/48000 (43%)]\tLoss: 0.000074\n",
      "Train Epoch: 37 [21760/48000 (45%)]\tLoss: 0.015618\n",
      "Train Epoch: 37 [23040/48000 (48%)]\tLoss: 0.000060\n",
      "Train Epoch: 37 [24320/48000 (51%)]\tLoss: 0.000104\n",
      "Train Epoch: 37 [25600/48000 (53%)]\tLoss: 0.000830\n",
      "Train Epoch: 37 [26880/48000 (56%)]\tLoss: 0.000122\n",
      "Train Epoch: 37 [28160/48000 (59%)]\tLoss: 0.000116\n",
      "Train Epoch: 37 [29440/48000 (61%)]\tLoss: 0.000166\n",
      "Train Epoch: 37 [30720/48000 (64%)]\tLoss: 0.000189\n",
      "Train Epoch: 37 [32000/48000 (67%)]\tLoss: 0.000045\n",
      "Train Epoch: 37 [33280/48000 (69%)]\tLoss: 0.000056\n",
      "Train Epoch: 37 [34560/48000 (72%)]\tLoss: 0.000036\n",
      "Train Epoch: 37 [35840/48000 (75%)]\tLoss: 0.000035\n",
      "Train Epoch: 37 [37120/48000 (77%)]\tLoss: 0.000038\n",
      "Train Epoch: 37 [38400/48000 (80%)]\tLoss: 0.000034\n",
      "Train Epoch: 37 [39680/48000 (83%)]\tLoss: 0.000041\n",
      "Train Epoch: 37 [40960/48000 (85%)]\tLoss: 0.000023\n",
      "Train Epoch: 37 [42240/48000 (88%)]\tLoss: 0.000240\n",
      "Train Epoch: 37 [43520/48000 (91%)]\tLoss: 0.000024\n",
      "Train Epoch: 37 [44800/48000 (93%)]\tLoss: 0.000043\n",
      "Train Epoch: 37 [46080/48000 (96%)]\tLoss: 0.000067\n",
      "Train Epoch: 37 [47360/48000 (99%)]\tLoss: 0.000057\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 7815/8000 (98%)\n",
      "Train Epoch: 38 [0/48000 (0%)]\tLoss: 0.000041\n",
      "Train Epoch: 38 [1280/48000 (3%)]\tLoss: 0.000023\n",
      "Train Epoch: 38 [2560/48000 (5%)]\tLoss: 0.000018\n",
      "Train Epoch: 38 [3840/48000 (8%)]\tLoss: 0.000023\n",
      "Train Epoch: 38 [5120/48000 (11%)]\tLoss: 0.000045\n",
      "Train Epoch: 38 [6400/48000 (13%)]\tLoss: 0.000021\n",
      "Train Epoch: 38 [7680/48000 (16%)]\tLoss: 0.000045\n",
      "Train Epoch: 38 [8960/48000 (19%)]\tLoss: 0.000033\n",
      "Train Epoch: 38 [10240/48000 (21%)]\tLoss: 0.000040\n",
      "Train Epoch: 38 [11520/48000 (24%)]\tLoss: 0.000046\n",
      "Train Epoch: 38 [12800/48000 (27%)]\tLoss: 0.000046\n",
      "Train Epoch: 38 [14080/48000 (29%)]\tLoss: 0.000017\n",
      "Train Epoch: 38 [15360/48000 (32%)]\tLoss: 0.000021\n",
      "Train Epoch: 38 [16640/48000 (35%)]\tLoss: 0.000059\n",
      "Train Epoch: 38 [17920/48000 (37%)]\tLoss: 0.000019\n",
      "Train Epoch: 38 [19200/48000 (40%)]\tLoss: 0.000025\n",
      "Train Epoch: 38 [20480/48000 (43%)]\tLoss: 0.000132\n",
      "Train Epoch: 38 [21760/48000 (45%)]\tLoss: 0.000053\n",
      "Train Epoch: 38 [23040/48000 (48%)]\tLoss: 0.000047\n",
      "Train Epoch: 38 [24320/48000 (51%)]\tLoss: 0.000064\n",
      "Train Epoch: 38 [25600/48000 (53%)]\tLoss: 0.000080\n",
      "Train Epoch: 38 [26880/48000 (56%)]\tLoss: 0.001786\n",
      "Train Epoch: 38 [28160/48000 (59%)]\tLoss: 0.000042\n",
      "Train Epoch: 38 [29440/48000 (61%)]\tLoss: 0.000024\n",
      "Train Epoch: 38 [30720/48000 (64%)]\tLoss: 0.000141\n",
      "Train Epoch: 38 [32000/48000 (67%)]\tLoss: 0.000108\n",
      "Train Epoch: 38 [33280/48000 (69%)]\tLoss: 0.000032\n",
      "Train Epoch: 38 [34560/48000 (72%)]\tLoss: 0.000031\n",
      "Train Epoch: 38 [35840/48000 (75%)]\tLoss: 0.000067\n",
      "Train Epoch: 38 [37120/48000 (77%)]\tLoss: 0.000079\n",
      "Train Epoch: 38 [38400/48000 (80%)]\tLoss: 0.000105\n",
      "Train Epoch: 38 [39680/48000 (83%)]\tLoss: 0.001233\n",
      "Train Epoch: 38 [40960/48000 (85%)]\tLoss: 0.001589\n",
      "Train Epoch: 38 [42240/48000 (88%)]\tLoss: 0.000588\n",
      "Train Epoch: 38 [43520/48000 (91%)]\tLoss: 0.000265\n",
      "Train Epoch: 38 [44800/48000 (93%)]\tLoss: 0.000070\n",
      "Train Epoch: 38 [46080/48000 (96%)]\tLoss: 0.000047\n",
      "Train Epoch: 38 [47360/48000 (99%)]\tLoss: 0.000083\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 7821/8000 (98%)\n",
      "Train Epoch: 39 [0/48000 (0%)]\tLoss: 0.000122\n",
      "Train Epoch: 39 [1280/48000 (3%)]\tLoss: 0.000124\n",
      "Train Epoch: 39 [2560/48000 (5%)]\tLoss: 0.005318\n",
      "Train Epoch: 39 [3840/48000 (8%)]\tLoss: 0.000042\n",
      "Train Epoch: 39 [5120/48000 (11%)]\tLoss: 0.000077\n",
      "Train Epoch: 39 [6400/48000 (13%)]\tLoss: 0.000184\n",
      "Train Epoch: 39 [7680/48000 (16%)]\tLoss: 0.000258\n",
      "Train Epoch: 39 [8960/48000 (19%)]\tLoss: 0.000138\n",
      "Train Epoch: 39 [10240/48000 (21%)]\tLoss: 0.002282\n",
      "Train Epoch: 39 [11520/48000 (24%)]\tLoss: 0.006279\n",
      "Train Epoch: 39 [12800/48000 (27%)]\tLoss: 0.000242\n",
      "Train Epoch: 39 [14080/48000 (29%)]\tLoss: 0.000117\n",
      "Train Epoch: 39 [15360/48000 (32%)]\tLoss: 0.002985\n",
      "Train Epoch: 39 [16640/48000 (35%)]\tLoss: 0.001225\n",
      "Train Epoch: 39 [17920/48000 (37%)]\tLoss: 0.000067\n",
      "Train Epoch: 39 [19200/48000 (40%)]\tLoss: 0.000380\n",
      "Train Epoch: 39 [20480/48000 (43%)]\tLoss: 0.000100\n",
      "Train Epoch: 39 [21760/48000 (45%)]\tLoss: 0.000183\n",
      "Train Epoch: 39 [23040/48000 (48%)]\tLoss: 0.000186\n",
      "Train Epoch: 39 [24320/48000 (51%)]\tLoss: 0.000777\n",
      "Train Epoch: 39 [25600/48000 (53%)]\tLoss: 0.003242\n",
      "Train Epoch: 39 [26880/48000 (56%)]\tLoss: 0.000204\n",
      "Train Epoch: 39 [28160/48000 (59%)]\tLoss: 0.000175\n",
      "Train Epoch: 39 [29440/48000 (61%)]\tLoss: 0.000148\n",
      "Train Epoch: 39 [30720/48000 (64%)]\tLoss: 0.000762\n",
      "Train Epoch: 39 [32000/48000 (67%)]\tLoss: 0.001185\n",
      "Train Epoch: 39 [33280/48000 (69%)]\tLoss: 0.000416\n",
      "Train Epoch: 39 [34560/48000 (72%)]\tLoss: 0.000176\n",
      "Train Epoch: 39 [35840/48000 (75%)]\tLoss: 0.000115\n",
      "Train Epoch: 39 [37120/48000 (77%)]\tLoss: 0.000223\n",
      "Train Epoch: 39 [38400/48000 (80%)]\tLoss: 0.000120\n",
      "Train Epoch: 39 [39680/48000 (83%)]\tLoss: 0.000079\n",
      "Train Epoch: 39 [40960/48000 (85%)]\tLoss: 0.000060\n",
      "Train Epoch: 39 [42240/48000 (88%)]\tLoss: 0.000148\n",
      "Train Epoch: 39 [43520/48000 (91%)]\tLoss: 0.000110\n",
      "Train Epoch: 39 [44800/48000 (93%)]\tLoss: 0.000054\n",
      "Train Epoch: 39 [46080/48000 (96%)]\tLoss: 0.000081\n",
      "Train Epoch: 39 [47360/48000 (99%)]\tLoss: 0.000040\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 7804/8000 (98%)\n",
      "Train Epoch: 40 [0/48000 (0%)]\tLoss: 0.000098\n",
      "Train Epoch: 40 [1280/48000 (3%)]\tLoss: 0.000100\n",
      "Train Epoch: 40 [2560/48000 (5%)]\tLoss: 0.000071\n",
      "Train Epoch: 40 [3840/48000 (8%)]\tLoss: 0.001346\n",
      "Train Epoch: 40 [5120/48000 (11%)]\tLoss: 0.000118\n",
      "Train Epoch: 40 [6400/48000 (13%)]\tLoss: 0.000036\n",
      "Train Epoch: 40 [7680/48000 (16%)]\tLoss: 0.000064\n",
      "Train Epoch: 40 [8960/48000 (19%)]\tLoss: 0.000074\n",
      "Train Epoch: 40 [10240/48000 (21%)]\tLoss: 0.000065\n",
      "Train Epoch: 40 [11520/48000 (24%)]\tLoss: 0.000054\n",
      "Train Epoch: 40 [12800/48000 (27%)]\tLoss: 0.000055\n",
      "Train Epoch: 40 [14080/48000 (29%)]\tLoss: 0.000063\n",
      "Train Epoch: 40 [15360/48000 (32%)]\tLoss: 0.000070\n",
      "Train Epoch: 40 [16640/48000 (35%)]\tLoss: 0.000030\n",
      "Train Epoch: 40 [17920/48000 (37%)]\tLoss: 0.000045\n",
      "Train Epoch: 40 [19200/48000 (40%)]\tLoss: 0.000039\n",
      "Train Epoch: 40 [20480/48000 (43%)]\tLoss: 0.000182\n",
      "Train Epoch: 40 [21760/48000 (45%)]\tLoss: 0.000063\n",
      "Train Epoch: 40 [23040/48000 (48%)]\tLoss: 0.000021\n",
      "Train Epoch: 40 [24320/48000 (51%)]\tLoss: 0.000379\n",
      "Train Epoch: 40 [25600/48000 (53%)]\tLoss: 0.000042\n",
      "Train Epoch: 40 [26880/48000 (56%)]\tLoss: 0.000036\n",
      "Train Epoch: 40 [28160/48000 (59%)]\tLoss: 0.000024\n",
      "Train Epoch: 40 [29440/48000 (61%)]\tLoss: 0.000046\n",
      "Train Epoch: 40 [30720/48000 (64%)]\tLoss: 0.000041\n",
      "Train Epoch: 40 [32000/48000 (67%)]\tLoss: 0.000017\n",
      "Train Epoch: 40 [33280/48000 (69%)]\tLoss: 0.000059\n",
      "Train Epoch: 40 [34560/48000 (72%)]\tLoss: 0.000029\n",
      "Train Epoch: 40 [35840/48000 (75%)]\tLoss: 0.000041\n",
      "Train Epoch: 40 [37120/48000 (77%)]\tLoss: 0.000100\n",
      "Train Epoch: 40 [38400/48000 (80%)]\tLoss: 0.000126\n",
      "Train Epoch: 40 [39680/48000 (83%)]\tLoss: 0.000024\n",
      "Train Epoch: 40 [40960/48000 (85%)]\tLoss: 0.000070\n",
      "Train Epoch: 40 [42240/48000 (88%)]\tLoss: 0.000055\n",
      "Train Epoch: 40 [43520/48000 (91%)]\tLoss: 0.000017\n",
      "Train Epoch: 40 [44800/48000 (93%)]\tLoss: 0.000200\n",
      "Train Epoch: 40 [46080/48000 (96%)]\tLoss: 0.000043\n",
      "Train Epoch: 40 [47360/48000 (99%)]\tLoss: 0.000017\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 7825/8000 (98%)\n",
      "Train Epoch: 41 [0/48000 (0%)]\tLoss: 0.000018\n",
      "Train Epoch: 41 [1280/48000 (3%)]\tLoss: 0.000027\n",
      "Train Epoch: 41 [2560/48000 (5%)]\tLoss: 0.000035\n",
      "Train Epoch: 41 [3840/48000 (8%)]\tLoss: 0.000018\n",
      "Train Epoch: 41 [5120/48000 (11%)]\tLoss: 0.000028\n",
      "Train Epoch: 41 [6400/48000 (13%)]\tLoss: 0.000023\n",
      "Train Epoch: 41 [7680/48000 (16%)]\tLoss: 0.000013\n",
      "Train Epoch: 41 [8960/48000 (19%)]\tLoss: 0.000025\n",
      "Train Epoch: 41 [10240/48000 (21%)]\tLoss: 0.000013\n",
      "Train Epoch: 41 [11520/48000 (24%)]\tLoss: 0.000036\n",
      "Train Epoch: 41 [12800/48000 (27%)]\tLoss: 0.000030\n",
      "Train Epoch: 41 [14080/48000 (29%)]\tLoss: 0.000017\n",
      "Train Epoch: 41 [15360/48000 (32%)]\tLoss: 0.000024\n",
      "Train Epoch: 41 [16640/48000 (35%)]\tLoss: 0.000024\n",
      "Train Epoch: 41 [17920/48000 (37%)]\tLoss: 0.000017\n",
      "Train Epoch: 41 [19200/48000 (40%)]\tLoss: 0.000012\n",
      "Train Epoch: 41 [20480/48000 (43%)]\tLoss: 0.000024\n",
      "Train Epoch: 41 [21760/48000 (45%)]\tLoss: 0.000022\n",
      "Train Epoch: 41 [23040/48000 (48%)]\tLoss: 0.000012\n",
      "Train Epoch: 41 [24320/48000 (51%)]\tLoss: 0.000020\n",
      "Train Epoch: 41 [25600/48000 (53%)]\tLoss: 0.000029\n",
      "Train Epoch: 41 [26880/48000 (56%)]\tLoss: 0.000027\n",
      "Train Epoch: 41 [28160/48000 (59%)]\tLoss: 0.000020\n",
      "Train Epoch: 41 [29440/48000 (61%)]\tLoss: 0.000017\n",
      "Train Epoch: 41 [30720/48000 (64%)]\tLoss: 0.000020\n",
      "Train Epoch: 41 [32000/48000 (67%)]\tLoss: 0.000015\n",
      "Train Epoch: 41 [33280/48000 (69%)]\tLoss: 0.000025\n",
      "Train Epoch: 41 [34560/48000 (72%)]\tLoss: 0.000018\n",
      "Train Epoch: 41 [35840/48000 (75%)]\tLoss: 0.000016\n",
      "Train Epoch: 41 [37120/48000 (77%)]\tLoss: 0.000021\n",
      "Train Epoch: 41 [38400/48000 (80%)]\tLoss: 0.000011\n",
      "Train Epoch: 41 [39680/48000 (83%)]\tLoss: 0.000010\n",
      "Train Epoch: 41 [40960/48000 (85%)]\tLoss: 0.000013\n",
      "Train Epoch: 41 [42240/48000 (88%)]\tLoss: 0.000209\n",
      "Train Epoch: 41 [43520/48000 (91%)]\tLoss: 0.000012\n",
      "Train Epoch: 41 [44800/48000 (93%)]\tLoss: 0.000025\n",
      "Train Epoch: 41 [46080/48000 (96%)]\tLoss: 0.000011\n",
      "Train Epoch: 41 [47360/48000 (99%)]\tLoss: 0.000010\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 7812/8000 (98%)\n",
      "Train Epoch: 42 [0/48000 (0%)]\tLoss: 0.000015\n",
      "Train Epoch: 42 [1280/48000 (3%)]\tLoss: 0.000033\n",
      "Train Epoch: 42 [2560/48000 (5%)]\tLoss: 0.000019\n",
      "Train Epoch: 42 [3840/48000 (8%)]\tLoss: 0.000015\n",
      "Train Epoch: 42 [5120/48000 (11%)]\tLoss: 0.000017\n",
      "Train Epoch: 42 [6400/48000 (13%)]\tLoss: 0.000011\n",
      "Train Epoch: 42 [7680/48000 (16%)]\tLoss: 0.000012\n",
      "Train Epoch: 42 [8960/48000 (19%)]\tLoss: 0.000061\n",
      "Train Epoch: 42 [10240/48000 (21%)]\tLoss: 0.000031\n",
      "Train Epoch: 42 [11520/48000 (24%)]\tLoss: 0.000007\n",
      "Train Epoch: 42 [12800/48000 (27%)]\tLoss: 0.000012\n",
      "Train Epoch: 42 [14080/48000 (29%)]\tLoss: 0.000011\n",
      "Train Epoch: 42 [15360/48000 (32%)]\tLoss: 0.000050\n",
      "Train Epoch: 42 [16640/48000 (35%)]\tLoss: 0.000013\n",
      "Train Epoch: 42 [17920/48000 (37%)]\tLoss: 0.000007\n",
      "Train Epoch: 42 [19200/48000 (40%)]\tLoss: 0.000016\n",
      "Train Epoch: 42 [20480/48000 (43%)]\tLoss: 0.000008\n",
      "Train Epoch: 42 [21760/48000 (45%)]\tLoss: 0.000010\n",
      "Train Epoch: 42 [23040/48000 (48%)]\tLoss: 0.000012\n",
      "Train Epoch: 42 [24320/48000 (51%)]\tLoss: 0.000029\n",
      "Train Epoch: 42 [25600/48000 (53%)]\tLoss: 0.000014\n",
      "Train Epoch: 42 [26880/48000 (56%)]\tLoss: 0.000017\n",
      "Train Epoch: 42 [28160/48000 (59%)]\tLoss: 0.000006\n",
      "Train Epoch: 42 [29440/48000 (61%)]\tLoss: 0.000012\n",
      "Train Epoch: 42 [30720/48000 (64%)]\tLoss: 0.000008\n",
      "Train Epoch: 42 [32000/48000 (67%)]\tLoss: 0.000004\n",
      "Train Epoch: 42 [33280/48000 (69%)]\tLoss: 0.000006\n",
      "Train Epoch: 42 [34560/48000 (72%)]\tLoss: 0.000011\n",
      "Train Epoch: 42 [35840/48000 (75%)]\tLoss: 0.000010\n",
      "Train Epoch: 42 [37120/48000 (77%)]\tLoss: 0.000009\n",
      "Train Epoch: 42 [38400/48000 (80%)]\tLoss: 0.000009\n",
      "Train Epoch: 42 [39680/48000 (83%)]\tLoss: 0.000012\n",
      "Train Epoch: 42 [40960/48000 (85%)]\tLoss: 0.000006\n",
      "Train Epoch: 42 [42240/48000 (88%)]\tLoss: 0.000007\n",
      "Train Epoch: 42 [43520/48000 (91%)]\tLoss: 0.000034\n",
      "Train Epoch: 42 [44800/48000 (93%)]\tLoss: 0.000045\n",
      "Train Epoch: 42 [46080/48000 (96%)]\tLoss: 0.000010\n",
      "Train Epoch: 42 [47360/48000 (99%)]\tLoss: 0.000010\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 7817/8000 (98%)\n",
      "Train Epoch: 43 [0/48000 (0%)]\tLoss: 0.000013\n",
      "Train Epoch: 43 [1280/48000 (3%)]\tLoss: 0.000005\n",
      "Train Epoch: 43 [2560/48000 (5%)]\tLoss: 0.000010\n",
      "Train Epoch: 43 [3840/48000 (8%)]\tLoss: 0.000005\n",
      "Train Epoch: 43 [5120/48000 (11%)]\tLoss: 0.000006\n",
      "Train Epoch: 43 [6400/48000 (13%)]\tLoss: 0.000032\n",
      "Train Epoch: 43 [7680/48000 (16%)]\tLoss: 0.000005\n",
      "Train Epoch: 43 [8960/48000 (19%)]\tLoss: 0.000007\n",
      "Train Epoch: 43 [10240/48000 (21%)]\tLoss: 0.000013\n",
      "Train Epoch: 43 [11520/48000 (24%)]\tLoss: 0.000007\n",
      "Train Epoch: 43 [12800/48000 (27%)]\tLoss: 0.000040\n",
      "Train Epoch: 43 [14080/48000 (29%)]\tLoss: 0.000005\n",
      "Train Epoch: 43 [15360/48000 (32%)]\tLoss: 0.000013\n",
      "Train Epoch: 43 [16640/48000 (35%)]\tLoss: 0.000011\n",
      "Train Epoch: 43 [17920/48000 (37%)]\tLoss: 0.000004\n",
      "Train Epoch: 43 [19200/48000 (40%)]\tLoss: 0.000008\n",
      "Train Epoch: 43 [20480/48000 (43%)]\tLoss: 0.000006\n",
      "Train Epoch: 43 [21760/48000 (45%)]\tLoss: 0.000006\n",
      "Train Epoch: 43 [23040/48000 (48%)]\tLoss: 0.000005\n",
      "Train Epoch: 43 [24320/48000 (51%)]\tLoss: 0.000012\n",
      "Train Epoch: 43 [25600/48000 (53%)]\tLoss: 0.000006\n",
      "Train Epoch: 43 [26880/48000 (56%)]\tLoss: 0.000008\n",
      "Train Epoch: 43 [28160/48000 (59%)]\tLoss: 0.000008\n",
      "Train Epoch: 43 [29440/48000 (61%)]\tLoss: 0.000007\n",
      "Train Epoch: 43 [30720/48000 (64%)]\tLoss: 0.000005\n",
      "Train Epoch: 43 [32000/48000 (67%)]\tLoss: 0.000006\n",
      "Train Epoch: 43 [33280/48000 (69%)]\tLoss: 0.000009\n",
      "Train Epoch: 43 [34560/48000 (72%)]\tLoss: 0.000005\n",
      "Train Epoch: 43 [35840/48000 (75%)]\tLoss: 0.000006\n",
      "Train Epoch: 43 [37120/48000 (77%)]\tLoss: 0.000011\n",
      "Train Epoch: 43 [38400/48000 (80%)]\tLoss: 0.000005\n",
      "Train Epoch: 43 [39680/48000 (83%)]\tLoss: 0.000005\n",
      "Train Epoch: 43 [40960/48000 (85%)]\tLoss: 0.000004\n",
      "Train Epoch: 43 [42240/48000 (88%)]\tLoss: 0.000007\n",
      "Train Epoch: 43 [43520/48000 (91%)]\tLoss: 0.000007\n",
      "Train Epoch: 43 [44800/48000 (93%)]\tLoss: 0.000005\n",
      "Train Epoch: 43 [46080/48000 (96%)]\tLoss: 0.000011\n",
      "Train Epoch: 43 [47360/48000 (99%)]\tLoss: 0.000005\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 7823/8000 (98%)\n",
      "Train Epoch: 44 [0/48000 (0%)]\tLoss: 0.000005\n",
      "Train Epoch: 44 [1280/48000 (3%)]\tLoss: 0.000006\n",
      "Train Epoch: 44 [2560/48000 (5%)]\tLoss: 0.000004\n",
      "Train Epoch: 44 [3840/48000 (8%)]\tLoss: 0.000005\n",
      "Train Epoch: 44 [5120/48000 (11%)]\tLoss: 0.000010\n",
      "Train Epoch: 44 [6400/48000 (13%)]\tLoss: 0.000006\n",
      "Train Epoch: 44 [7680/48000 (16%)]\tLoss: 0.000004\n",
      "Train Epoch: 44 [8960/48000 (19%)]\tLoss: 0.000003\n",
      "Train Epoch: 44 [10240/48000 (21%)]\tLoss: 0.000003\n",
      "Train Epoch: 44 [11520/48000 (24%)]\tLoss: 0.000003\n",
      "Train Epoch: 44 [12800/48000 (27%)]\tLoss: 0.000006\n",
      "Train Epoch: 44 [14080/48000 (29%)]\tLoss: 0.000003\n",
      "Train Epoch: 44 [15360/48000 (32%)]\tLoss: 0.000003\n",
      "Train Epoch: 44 [16640/48000 (35%)]\tLoss: 0.000005\n",
      "Train Epoch: 44 [17920/48000 (37%)]\tLoss: 0.000003\n",
      "Train Epoch: 44 [19200/48000 (40%)]\tLoss: 0.000008\n",
      "Train Epoch: 44 [20480/48000 (43%)]\tLoss: 0.000014\n",
      "Train Epoch: 44 [21760/48000 (45%)]\tLoss: 0.000007\n",
      "Train Epoch: 44 [23040/48000 (48%)]\tLoss: 0.000006\n",
      "Train Epoch: 44 [24320/48000 (51%)]\tLoss: 0.000045\n",
      "Train Epoch: 44 [25600/48000 (53%)]\tLoss: 0.000005\n",
      "Train Epoch: 44 [26880/48000 (56%)]\tLoss: 0.000005\n",
      "Train Epoch: 44 [28160/48000 (59%)]\tLoss: 0.000008\n",
      "Train Epoch: 44 [29440/48000 (61%)]\tLoss: 0.000005\n",
      "Train Epoch: 44 [30720/48000 (64%)]\tLoss: 0.000007\n",
      "Train Epoch: 44 [32000/48000 (67%)]\tLoss: 0.000005\n",
      "Train Epoch: 44 [33280/48000 (69%)]\tLoss: 0.000008\n",
      "Train Epoch: 44 [34560/48000 (72%)]\tLoss: 0.000009\n",
      "Train Epoch: 44 [35840/48000 (75%)]\tLoss: 0.000002\n",
      "Train Epoch: 44 [37120/48000 (77%)]\tLoss: 0.000005\n",
      "Train Epoch: 44 [38400/48000 (80%)]\tLoss: 0.000006\n",
      "Train Epoch: 44 [39680/48000 (83%)]\tLoss: 0.000011\n",
      "Train Epoch: 44 [40960/48000 (85%)]\tLoss: 0.000007\n",
      "Train Epoch: 44 [42240/48000 (88%)]\tLoss: 0.000003\n",
      "Train Epoch: 44 [43520/48000 (91%)]\tLoss: 0.000007\n",
      "Train Epoch: 44 [44800/48000 (93%)]\tLoss: 0.000009\n",
      "Train Epoch: 44 [46080/48000 (96%)]\tLoss: 0.000006\n",
      "Train Epoch: 44 [47360/48000 (99%)]\tLoss: 0.000003\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 7820/8000 (98%)\n",
      "Train Epoch: 45 [0/48000 (0%)]\tLoss: 0.000008\n",
      "Train Epoch: 45 [1280/48000 (3%)]\tLoss: 0.000004\n",
      "Train Epoch: 45 [2560/48000 (5%)]\tLoss: 0.000002\n",
      "Train Epoch: 45 [3840/48000 (8%)]\tLoss: 0.000006\n",
      "Train Epoch: 45 [5120/48000 (11%)]\tLoss: 0.000004\n",
      "Train Epoch: 45 [6400/48000 (13%)]\tLoss: 0.000008\n",
      "Train Epoch: 45 [7680/48000 (16%)]\tLoss: 0.000008\n",
      "Train Epoch: 45 [8960/48000 (19%)]\tLoss: 0.000004\n",
      "Train Epoch: 45 [10240/48000 (21%)]\tLoss: 0.000003\n",
      "Train Epoch: 45 [11520/48000 (24%)]\tLoss: 0.000016\n",
      "Train Epoch: 45 [12800/48000 (27%)]\tLoss: 0.000002\n",
      "Train Epoch: 45 [14080/48000 (29%)]\tLoss: 0.000005\n",
      "Train Epoch: 45 [15360/48000 (32%)]\tLoss: 0.000002\n",
      "Train Epoch: 45 [16640/48000 (35%)]\tLoss: 0.000003\n",
      "Train Epoch: 45 [17920/48000 (37%)]\tLoss: 0.000004\n",
      "Train Epoch: 45 [19200/48000 (40%)]\tLoss: 0.000004\n",
      "Train Epoch: 45 [20480/48000 (43%)]\tLoss: 0.000009\n",
      "Train Epoch: 45 [21760/48000 (45%)]\tLoss: 0.000014\n",
      "Train Epoch: 45 [23040/48000 (48%)]\tLoss: 0.000017\n",
      "Train Epoch: 45 [24320/48000 (51%)]\tLoss: 0.000004\n",
      "Train Epoch: 45 [25600/48000 (53%)]\tLoss: 0.000002\n",
      "Train Epoch: 45 [26880/48000 (56%)]\tLoss: 0.000009\n",
      "Train Epoch: 45 [28160/48000 (59%)]\tLoss: 0.000002\n",
      "Train Epoch: 45 [29440/48000 (61%)]\tLoss: 0.000003\n",
      "Train Epoch: 45 [30720/48000 (64%)]\tLoss: 0.000004\n",
      "Train Epoch: 45 [32000/48000 (67%)]\tLoss: 0.000005\n",
      "Train Epoch: 45 [33280/48000 (69%)]\tLoss: 0.000002\n",
      "Train Epoch: 45 [34560/48000 (72%)]\tLoss: 0.000002\n",
      "Train Epoch: 45 [35840/48000 (75%)]\tLoss: 0.000004\n",
      "Train Epoch: 45 [37120/48000 (77%)]\tLoss: 0.000003\n",
      "Train Epoch: 45 [38400/48000 (80%)]\tLoss: 0.000002\n",
      "Train Epoch: 45 [39680/48000 (83%)]\tLoss: 0.000007\n",
      "Train Epoch: 45 [40960/48000 (85%)]\tLoss: 0.000009\n",
      "Train Epoch: 45 [42240/48000 (88%)]\tLoss: 0.000015\n",
      "Train Epoch: 45 [43520/48000 (91%)]\tLoss: 0.000002\n",
      "Train Epoch: 45 [44800/48000 (93%)]\tLoss: 0.000005\n",
      "Train Epoch: 45 [46080/48000 (96%)]\tLoss: 0.000003\n",
      "Train Epoch: 45 [47360/48000 (99%)]\tLoss: 0.000005\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 7827/8000 (98%)\n",
      "Train Epoch: 46 [0/48000 (0%)]\tLoss: 0.000003\n",
      "Train Epoch: 46 [1280/48000 (3%)]\tLoss: 0.000002\n",
      "Train Epoch: 46 [2560/48000 (5%)]\tLoss: 0.000003\n",
      "Train Epoch: 46 [3840/48000 (8%)]\tLoss: 0.000002\n",
      "Train Epoch: 46 [5120/48000 (11%)]\tLoss: 0.000007\n",
      "Train Epoch: 46 [6400/48000 (13%)]\tLoss: 0.000005\n",
      "Train Epoch: 46 [7680/48000 (16%)]\tLoss: 0.000004\n",
      "Train Epoch: 46 [8960/48000 (19%)]\tLoss: 0.000003\n",
      "Train Epoch: 46 [10240/48000 (21%)]\tLoss: 0.000003\n",
      "Train Epoch: 46 [11520/48000 (24%)]\tLoss: 0.000001\n",
      "Train Epoch: 46 [12800/48000 (27%)]\tLoss: 0.000002\n",
      "Train Epoch: 46 [14080/48000 (29%)]\tLoss: 0.000002\n",
      "Train Epoch: 46 [15360/48000 (32%)]\tLoss: 0.000002\n",
      "Train Epoch: 46 [16640/48000 (35%)]\tLoss: 0.000002\n",
      "Train Epoch: 46 [17920/48000 (37%)]\tLoss: 0.000005\n",
      "Train Epoch: 46 [19200/48000 (40%)]\tLoss: 0.000004\n",
      "Train Epoch: 46 [20480/48000 (43%)]\tLoss: 0.000004\n",
      "Train Epoch: 46 [21760/48000 (45%)]\tLoss: 0.000002\n",
      "Train Epoch: 46 [23040/48000 (48%)]\tLoss: 0.000004\n",
      "Train Epoch: 46 [24320/48000 (51%)]\tLoss: 0.000006\n",
      "Train Epoch: 46 [25600/48000 (53%)]\tLoss: 0.000094\n",
      "Train Epoch: 46 [26880/48000 (56%)]\tLoss: 0.000003\n",
      "Train Epoch: 46 [28160/48000 (59%)]\tLoss: 0.009948\n",
      "Train Epoch: 46 [29440/48000 (61%)]\tLoss: 0.002492\n",
      "Train Epoch: 46 [30720/48000 (64%)]\tLoss: 0.053973\n",
      "Train Epoch: 46 [32000/48000 (67%)]\tLoss: 0.040424\n",
      "Train Epoch: 46 [33280/48000 (69%)]\tLoss: 0.101316\n",
      "Train Epoch: 46 [34560/48000 (72%)]\tLoss: 0.028805\n",
      "Train Epoch: 46 [35840/48000 (75%)]\tLoss: 0.041285\n",
      "Train Epoch: 46 [37120/48000 (77%)]\tLoss: 0.012914\n",
      "Train Epoch: 46 [38400/48000 (80%)]\tLoss: 0.008207\n",
      "Train Epoch: 46 [39680/48000 (83%)]\tLoss: 0.044178\n",
      "Train Epoch: 46 [40960/48000 (85%)]\tLoss: 0.012016\n",
      "Train Epoch: 46 [42240/48000 (88%)]\tLoss: 0.000937\n",
      "Train Epoch: 46 [43520/48000 (91%)]\tLoss: 0.001267\n",
      "Train Epoch: 46 [44800/48000 (93%)]\tLoss: 0.001114\n",
      "Train Epoch: 46 [46080/48000 (96%)]\tLoss: 0.000405\n",
      "Train Epoch: 46 [47360/48000 (99%)]\tLoss: 0.000108\n",
      "\n",
      "Test set: Average loss: 0.0009, Accuracy: 7825/8000 (98%)\n",
      "Train Epoch: 47 [0/48000 (0%)]\tLoss: 0.000163\n",
      "Train Epoch: 47 [1280/48000 (3%)]\tLoss: 0.000163\n",
      "Train Epoch: 47 [2560/48000 (5%)]\tLoss: 0.000179\n",
      "Train Epoch: 47 [3840/48000 (8%)]\tLoss: 0.000305\n",
      "Train Epoch: 47 [5120/48000 (11%)]\tLoss: 0.000146\n",
      "Train Epoch: 47 [6400/48000 (13%)]\tLoss: 0.000093\n",
      "Train Epoch: 47 [7680/48000 (16%)]\tLoss: 0.000119\n",
      "Train Epoch: 47 [8960/48000 (19%)]\tLoss: 0.000119\n",
      "Train Epoch: 47 [10240/48000 (21%)]\tLoss: 0.000040\n",
      "Train Epoch: 47 [11520/48000 (24%)]\tLoss: 0.000134\n",
      "Train Epoch: 47 [12800/48000 (27%)]\tLoss: 0.000243\n",
      "Train Epoch: 47 [14080/48000 (29%)]\tLoss: 0.000130\n",
      "Train Epoch: 47 [15360/48000 (32%)]\tLoss: 0.000112\n",
      "Train Epoch: 47 [16640/48000 (35%)]\tLoss: 0.000077\n",
      "Train Epoch: 47 [17920/48000 (37%)]\tLoss: 0.000042\n",
      "Train Epoch: 47 [19200/48000 (40%)]\tLoss: 0.000287\n",
      "Train Epoch: 47 [20480/48000 (43%)]\tLoss: 0.000999\n",
      "Train Epoch: 47 [21760/48000 (45%)]\tLoss: 0.000188\n",
      "Train Epoch: 47 [23040/48000 (48%)]\tLoss: 0.000072\n",
      "Train Epoch: 47 [24320/48000 (51%)]\tLoss: 0.010938\n",
      "Train Epoch: 47 [25600/48000 (53%)]\tLoss: 0.001838\n",
      "Train Epoch: 47 [26880/48000 (56%)]\tLoss: 0.000039\n",
      "Train Epoch: 47 [28160/48000 (59%)]\tLoss: 0.000057\n",
      "Train Epoch: 47 [29440/48000 (61%)]\tLoss: 0.000811\n",
      "Train Epoch: 47 [30720/48000 (64%)]\tLoss: 0.001195\n",
      "Train Epoch: 47 [32000/48000 (67%)]\tLoss: 0.022796\n",
      "Train Epoch: 47 [33280/48000 (69%)]\tLoss: 0.000340\n",
      "Train Epoch: 47 [34560/48000 (72%)]\tLoss: 0.001015\n",
      "Train Epoch: 47 [35840/48000 (75%)]\tLoss: 0.000635\n",
      "Train Epoch: 47 [37120/48000 (77%)]\tLoss: 0.001708\n",
      "Train Epoch: 47 [38400/48000 (80%)]\tLoss: 0.028774\n",
      "Train Epoch: 47 [39680/48000 (83%)]\tLoss: 0.000162\n",
      "Train Epoch: 47 [40960/48000 (85%)]\tLoss: 0.000175\n",
      "Train Epoch: 47 [42240/48000 (88%)]\tLoss: 0.023976\n",
      "Train Epoch: 47 [43520/48000 (91%)]\tLoss: 0.000569\n",
      "Train Epoch: 47 [44800/48000 (93%)]\tLoss: 0.000138\n",
      "Train Epoch: 47 [46080/48000 (96%)]\tLoss: 0.000074\n",
      "Train Epoch: 47 [47360/48000 (99%)]\tLoss: 0.000096\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 7778/8000 (97%)\n",
      "Train Epoch: 48 [0/48000 (0%)]\tLoss: 0.000033\n",
      "Train Epoch: 48 [1280/48000 (3%)]\tLoss: 0.000081\n",
      "Train Epoch: 48 [2560/48000 (5%)]\tLoss: 0.000054\n",
      "Train Epoch: 48 [3840/48000 (8%)]\tLoss: 0.005521\n",
      "Train Epoch: 48 [5120/48000 (11%)]\tLoss: 0.000106\n",
      "Train Epoch: 48 [6400/48000 (13%)]\tLoss: 0.000107\n",
      "Train Epoch: 48 [7680/48000 (16%)]\tLoss: 0.000079\n",
      "Train Epoch: 48 [8960/48000 (19%)]\tLoss: 0.000036\n",
      "Train Epoch: 48 [10240/48000 (21%)]\tLoss: 0.000312\n",
      "Train Epoch: 48 [11520/48000 (24%)]\tLoss: 0.000100\n",
      "Train Epoch: 48 [12800/48000 (27%)]\tLoss: 0.000060\n",
      "Train Epoch: 48 [14080/48000 (29%)]\tLoss: 0.000064\n",
      "Train Epoch: 48 [15360/48000 (32%)]\tLoss: 0.000097\n",
      "Train Epoch: 48 [16640/48000 (35%)]\tLoss: 0.000068\n",
      "Train Epoch: 48 [17920/48000 (37%)]\tLoss: 0.000077\n",
      "Train Epoch: 48 [19200/48000 (40%)]\tLoss: 0.000028\n",
      "Train Epoch: 48 [20480/48000 (43%)]\tLoss: 0.000151\n",
      "Train Epoch: 48 [21760/48000 (45%)]\tLoss: 0.000039\n",
      "Train Epoch: 48 [23040/48000 (48%)]\tLoss: 0.000031\n",
      "Train Epoch: 48 [24320/48000 (51%)]\tLoss: 0.000035\n",
      "Train Epoch: 48 [25600/48000 (53%)]\tLoss: 0.000030\n",
      "Train Epoch: 48 [26880/48000 (56%)]\tLoss: 0.000089\n",
      "Train Epoch: 48 [28160/48000 (59%)]\tLoss: 0.000023\n",
      "Train Epoch: 48 [29440/48000 (61%)]\tLoss: 0.000094\n",
      "Train Epoch: 48 [30720/48000 (64%)]\tLoss: 0.000315\n",
      "Train Epoch: 48 [32000/48000 (67%)]\tLoss: 0.000068\n",
      "Train Epoch: 48 [33280/48000 (69%)]\tLoss: 0.000043\n",
      "Train Epoch: 48 [34560/48000 (72%)]\tLoss: 0.000084\n",
      "Train Epoch: 48 [35840/48000 (75%)]\tLoss: 0.000029\n",
      "Train Epoch: 48 [37120/48000 (77%)]\tLoss: 0.000069\n",
      "Train Epoch: 48 [38400/48000 (80%)]\tLoss: 0.000035\n",
      "Train Epoch: 48 [39680/48000 (83%)]\tLoss: 0.000434\n",
      "Train Epoch: 48 [40960/48000 (85%)]\tLoss: 0.000799\n",
      "Train Epoch: 48 [42240/48000 (88%)]\tLoss: 0.000025\n",
      "Train Epoch: 48 [43520/48000 (91%)]\tLoss: 0.000017\n",
      "Train Epoch: 48 [44800/48000 (93%)]\tLoss: 0.000030\n",
      "Train Epoch: 48 [46080/48000 (96%)]\tLoss: 0.000013\n",
      "Train Epoch: 48 [47360/48000 (99%)]\tLoss: 0.000014\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 7788/8000 (97%)\n",
      "Train Epoch: 49 [0/48000 (0%)]\tLoss: 0.000029\n",
      "Train Epoch: 49 [1280/48000 (3%)]\tLoss: 0.000027\n",
      "Train Epoch: 49 [2560/48000 (5%)]\tLoss: 0.000016\n",
      "Train Epoch: 49 [3840/48000 (8%)]\tLoss: 0.000049\n",
      "Train Epoch: 49 [5120/48000 (11%)]\tLoss: 0.000015\n",
      "Train Epoch: 49 [6400/48000 (13%)]\tLoss: 0.000044\n",
      "Train Epoch: 49 [7680/48000 (16%)]\tLoss: 0.000038\n",
      "Train Epoch: 49 [8960/48000 (19%)]\tLoss: 0.000010\n",
      "Train Epoch: 49 [10240/48000 (21%)]\tLoss: 0.000011\n",
      "Train Epoch: 49 [11520/48000 (24%)]\tLoss: 0.000031\n",
      "Train Epoch: 49 [12800/48000 (27%)]\tLoss: 0.000019\n",
      "Train Epoch: 49 [14080/48000 (29%)]\tLoss: 0.000014\n",
      "Train Epoch: 49 [15360/48000 (32%)]\tLoss: 0.000013\n",
      "Train Epoch: 49 [16640/48000 (35%)]\tLoss: 0.000017\n",
      "Train Epoch: 49 [17920/48000 (37%)]\tLoss: 0.000011\n",
      "Train Epoch: 49 [19200/48000 (40%)]\tLoss: 0.000026\n",
      "Train Epoch: 49 [20480/48000 (43%)]\tLoss: 0.000024\n",
      "Train Epoch: 49 [21760/48000 (45%)]\tLoss: 0.000024\n",
      "Train Epoch: 49 [23040/48000 (48%)]\tLoss: 0.000014\n",
      "Train Epoch: 49 [24320/48000 (51%)]\tLoss: 0.000062\n",
      "Train Epoch: 49 [25600/48000 (53%)]\tLoss: 0.000021\n",
      "Train Epoch: 49 [26880/48000 (56%)]\tLoss: 0.000010\n",
      "Train Epoch: 49 [28160/48000 (59%)]\tLoss: 0.000020\n",
      "Train Epoch: 49 [29440/48000 (61%)]\tLoss: 0.000021\n",
      "Train Epoch: 49 [30720/48000 (64%)]\tLoss: 0.000023\n",
      "Train Epoch: 49 [32000/48000 (67%)]\tLoss: 0.000013\n",
      "Train Epoch: 49 [33280/48000 (69%)]\tLoss: 0.000013\n",
      "Train Epoch: 49 [34560/48000 (72%)]\tLoss: 0.000105\n",
      "Train Epoch: 49 [35840/48000 (75%)]\tLoss: 0.000010\n",
      "Train Epoch: 49 [37120/48000 (77%)]\tLoss: 0.000010\n",
      "Train Epoch: 49 [38400/48000 (80%)]\tLoss: 0.000013\n",
      "Train Epoch: 49 [39680/48000 (83%)]\tLoss: 0.000014\n",
      "Train Epoch: 49 [40960/48000 (85%)]\tLoss: 0.000015\n",
      "Train Epoch: 49 [42240/48000 (88%)]\tLoss: 0.000010\n",
      "Train Epoch: 49 [43520/48000 (91%)]\tLoss: 0.000029\n",
      "Train Epoch: 49 [44800/48000 (93%)]\tLoss: 0.000010\n",
      "Train Epoch: 49 [46080/48000 (96%)]\tLoss: 0.000010\n",
      "Train Epoch: 49 [47360/48000 (99%)]\tLoss: 0.000035\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 7804/8000 (98%)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Accuracy: 100.00%\n",
      "Final Test Accuracy: 97.55%\n",
      "Final Test Accuracy(classified):\n",
      "equal: 95.85%, different: 99.25%\n"
     ]
    }
   ],
   "source": [
    "# final accuracy on train and test set\n",
    "print(\"Final Train Accuracy: {:.2f}%\".format(train_acc[-1]))\n",
    "print(\"Final Test Accuracy: {:.2f}%\".format(test_acc[-1]))\n",
    "\n",
    "torch.save(model.state_dict(), './model/siamese_network.pth')\n",
    "\n",
    "# calculate accuracy on equal/different pairs\n",
    "def test_equal_unequal():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_equal = 0\n",
    "    correct_different = 0\n",
    "    tot_equal = 0\n",
    "    tot_different = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, targets) in enumerate(test_loader):\n",
    "            images_1 = images[:, 0, :, :].cuda()\n",
    "            images_2 = images[:, 1, :, :].cuda()\n",
    "            targets = targets.cuda()\n",
    "            outputs = model(images_1, images_2).squeeze()\n",
    "            loss = criterion(outputs, targets).item()\n",
    "            test_loss += loss\n",
    "            pred = torch.round(outputs)\n",
    "            tot_equal += targets.eq(1).sum().item()\n",
    "            tot_different += targets.eq(0).sum().item()\n",
    "            correct_equal += pred.eq(targets.view_as(pred))[targets.eq(1)].sum().item()\n",
    "            correct_different += pred.eq(targets.view_as(pred))[targets.eq(0)].sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    acc_equal = 100. * float(correct_equal) / float(tot_equal)\n",
    "    acc_different = 100. * float(correct_different) / float(tot_different)\n",
    "    return acc_equal, acc_different\n",
    "\n",
    "acc_equal, acc_different = test_equal_unequal()\n",
    "# print(acc_equal, acc_different)\n",
    "print(f\"Final Test Accuracy(classified):\\nequal: {acc_equal:.2f}%, different: {acc_different:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化\n",
    "\n",
    "将训练、测试 loss 和测试 accuracy 以可视化的方式展现出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0wAAAF0CAYAAAAQK7leAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB/lElEQVR4nO3deVxUVf8H8M8wG6sgO6gs7iKuUAruG+65lVuZZpn+tCeRzC0ts1wzs3JrMdMstR41fUpT3FAT19x3DcQFRFxYRIEZzu+P64wODMsAIwx83q/XvGTunHvuudeZc+c7Z5MJIQSIiIiIiIgoF6vSLgAREREREVFZxYCJiIiIiIgoDwyYiIiIiIiI8sCAiYiIiIiIKA8MmIiIiIiIiPLAgImIiIiIiCgPDJiIiIiIiIjywICJiIiIiIgoDwyYiIiIiIiI8sCAiZ67H3/8ETKZDEePHi3tohDRc/bVV19BJpMhMDCwtItCVOHx81g4M2bMQEBAALKzs03az8/PD8OGDTNPoQpB930rNjbWYPvUqVPh4+MDhUIBJycnAEDbtm3Rtm3bEj1+zvPfuXMn7O3tcfPmzRI9zvPAgImIiJ6bH374AQBw9uxZHDp0qJRLQ1Sx8fNYsFu3bmHevHmYMWMGrKws62tz9+7dER0dDS8vL/22TZs2YebMmXj99dcRFRWFHTt2AACWLFmCJUuWmLU8HTp0wIsvvogpU6aY9TjmYFn/80REZLGOHj2KkydPonv37gCA5cuXl3KJjEtPTy/tIhCZHT+PhfPll1/CyckJffv2LdVyFIWbmxuaN28OtVqt33bmzBkAwLvvvosWLVogODgYABAQEICAgACzl2nMmDH4+eefcf36dbMfqyQxYKIyaf/+/ejQoQMcHBxga2uL0NBQ/PnnnwZp0tPTMX78ePj7+8Pa2hrOzs4IDg7GmjVr9Gn+/fdfDBw4EN7e3lCr1fDw8ECHDh1w4sSJ53xGRKT7QjZnzhyEhoZi7dq1ub4M3bx5E2+//TaqVasGlUoFb29vvPzyy7h9+7Y+zYMHD/Dee++hevXqUKvVcHd3R7du3XDhwgUAwJ49eyCTybBnzx6DvGNjYyGTyfDjjz/qtw0bNgz29vY4ffo0wsLC4ODggA4dOgAAIiMj0atXL1StWhXW1taoWbMmRo4ciaSkpFznduHCBQwaNAgeHh5Qq9Xw8fHB66+/joyMDMTGxkKhUGD27Nm59tu7dy9kMhl+++23Il1ToqLi57Hgz2NmZiaWL1+OwYMH52pdysjIwIwZM1CvXj1YW1vDxcUF7dq1w4EDB/K85o8fP8Z7772Hxo0bw9HREc7OzggJCcGmTZtypf3tt9/QrFkzODo6wtbWFtWrV8fw4cP1r2dnZ+PTTz9FnTp1YGNjAycnJzRs2BBffvmlPk3OLnl+fn6YOnUqAMDDwwMymQzTp08HYLxLXmZmJj799FPUrVsXarUabm5ueOONN3Dnzh2DdFlZWZgwYQI8PT1ha2uLli1b4vDhw0avQc+ePWFvb4/vvvsuz+tUFilKuwBEOUVFRaFTp05o2LAhli9fDrVajSVLlqBnz55Ys2YNBgwYAACIiIjATz/9hE8//RRNmjTBw4cPcebMGdy9e1efV7du3aDVajFv3jz4+PggKSkJBw4cwIMHD0rp7IgqpkePHmHNmjV44YUXEBgYiOHDh+Ott97Cb7/9hqFDhwKQvpy98MILyMrKwpQpU9CwYUPcvXsX27Ztw/379+Hh4YHU1FS0bNkSsbGxmDhxIpo1a4a0tDTs3bsX8fHxqFu3rslly8zMxEsvvYSRI0di0qRJ0Gg0AICrV68iJCQEb731FhwdHREbG4sFCxagZcuWOH36NJRKJQDg5MmTaNmyJVxdXTFjxgzUqlUL8fHx2Lx5MzIzM+Hn54eXXnoJy5Ytw4QJEyCXy/XHXrRoEby9vdGnT58SuMpEhcPPY+E+j4cOHcLdu3fRrl07gzJqNBp07doV+/btQ3h4ONq3bw+NRoODBw8iLi4OoaGhRs8tIyMD9+7dw/jx41GlShVkZmZix44d6Nu3L1asWIHXX38dABAdHY0BAwZgwIABmD59OqytrXHt2jXs2rVLn9e8efMwffp0TJ06Fa1bt0ZWVhYuXLiQ7/ebjRs3YvHixVi+fDn++usvODo6omrVqkbTZmdno1evXti3bx8mTJiA0NBQXLt2DR999BHatm2Lo0ePwsbGBgAwYsQIrFq1CuPHj0enTp1w5swZ9O3bF6mpqbnyValU+h/BZ8yYkWdZyxxB9JytWLFCABBHjhwx+nrz5s2Fu7u7SE1N1W/TaDQiMDBQVK1aVWRnZwshhAgMDBS9e/fO8zhJSUkCgFi4cGHJngARmWzVqlUCgFi2bJkQQojU1FRhb28vWrVqpU8zfPhwoVQqxblz5/LMZ8aMGQKAiIyMzDPN7t27BQCxe/dug+0xMTECgFixYoV+29ChQwUA8cMPP+Rb/uzsbJGVlSWuXbsmAIhNmzbpX2vfvr1wcnISiYmJBZZp48aN+m03b94UCoVCfPzxx/kem6ik8fNYuM/j3LlzBQCRkJBgsL/u+n333Xf5ltPX11cMHTo0z9c1Go3IysoSb775pmjSpIl++/z58wUA8eDBgzz37dGjh2jcuHG+x9d934qJidFv++ijjwQAcefOHYO0bdq0EW3atNE/X7NmjQAg1q9fb5DuyJEjAoBYsmSJEEKI8+fPCwBi3LhxBul+/vlnAcDo+X/wwQfCyspKpKWl5Vv+soRd8qhMefjwIQ4dOoSXX34Z9vb2+u1yuRxDhgzBjRs3cPHiRQDAiy++iK1bt2LSpEnYs2cPHj16ZJCXs7MzatSogc8++wwLFizA8ePHTZ7hhohKxvLly2FjY4OBAwcCAOzt7fHKK69g3759uHz5MgBg69ataNeuHerVq5dnPlu3bkXt2rXRsWPHEi1fv379cm1LTEzEqFGjUK1aNSgUCiiVSvj6+gIAzp8/D0DqGhwVFYX+/fvDzc0tz/zbtm2LRo0aYfHixfpty5Ytg0wmw9tvv12i50JUEH4eC/d5vHXrFmQyGVxdXQ3237p1K6ytrQ26yBXWb7/9hhYtWsDe3l5/HsuXL9efAwC88MILAID+/fvj119/NTqr3IsvvoiTJ09i9OjR2LZtG1JSUkwuS37++OMPODk5oWfPntBoNPpH48aN4enpqe9iuXv3bgDAq6++arB///79oVAY78jm7u6O7OxsJCQklGiZzYkBE5Up9+/fhxDCYEYXHW9vbwDQd7n76quvMHHiRPz+++9o164dnJ2d0bt3b31lL5PJsHPnTnTu3Bnz5s1D06ZN4ebmhnfffddoMzERmceVK1ewd+9edO/eHUIIPHjwAA8ePMDLL78M4OlMXXfu3Mmze4hOYdKYytbWFpUqVTLYlp2djbCwMGzYsAETJkzAzp07cfjwYRw8eBAA9D/Q3L9/H1qttlBlevfdd7Fz505cvHgRWVlZ+O677/Dyyy/D09OzRM+HKD/8PEoK83l89OgRlEqlQbc9QDpvb29vk2fN27BhA/r3748qVapg9erViI6OxpEjRzB8+HA8fvxYn65169b4/fffodFo8Prrr6Nq1aoIDAw0GKM9efJkzJ8/HwcPHkTXrl3h4uKCDh06lNiSLbdv38aDBw+gUqmgVCoNHgkJCfqxY7rvZDnrMYVCARcXF6N5W1tbA0CuH7rLMo5hojKlcuXKsLKyQnx8fK7Xbt26BQD6X3rs7Ozw8ccf4+OPP8bt27f1rU09e/bUDzb19fXVD2y9dOkSfv31V0yfPh2ZmZlYtmzZczoroorthx9+gBAC//3vf/Hf//431+srV67Ep59+Cjc3N9y4cSPfvAqTRnczzsjIMNhubHA4IP24ktOZM2dw8uRJ/Pjjj/oxHYD0ZfNZzs7OkMvlBZYJAAYPHoyJEydi8eLFaN68ORISEjBmzJgC9yMqSfw8SgrzeXR1dUVmZiYePnwIOzs7/XY3Nzfs378f2dnZJgVNq1evhr+/P9atW2dwnjmvDQD06tULvXr1QkZGBg4ePIjZs2dj8ODB8PPzQ0hICBQKBSIiIhAREYEHDx5gx44dmDJlCjp37ozr16/D1ta20OUyxtXVFS4uLvjrr7+Mvu7g4AAA+qAoISEBVapU0b+u0WgMxpQ/6969e/pjWAq2MFGZYmdnh2bNmmHDhg0GvzxkZ2dj9erVqFq1KmrXrp1rPw8PDwwbNgyDBg3CxYsXjU5DWrt2bUydOhUNGjTAP//8Y9bzICKJVqvFypUrUaNGDezevTvX47333kN8fDy2bt2Krl27Yvfu3fput8Z07doVly5dMhj8nJOfnx8A4NSpUwbbN2/eXOhy677MPDsdLwB88803Bs9tbGzQpk0b/Pbbb3l+AdSxtrbG22+/jZUrV2LBggVo3LgxWrRoUegyERUXP49PFebzqJu04urVqwbbu3btisePHxvM8FfY81CpVAbBUkJCgtFZ8nTUajXatGmDuXPnAgCOHz+eK42TkxNefvlljBkzBvfu3cu1UG1R9OjRA3fv3oVWq0VwcHCuR506dQBAP7Pezz//bLD/r7/+qp+wI6d///0XLi4u8PDwKHY5nxe2MFGp2bVrl9EP9ezZs9GpUye0a9cO48ePh0qlwpIlS3DmzBmsWbNGX9E0a9YMPXr0QMOGDVG5cmWcP38eP/30E0JCQmBra4tTp07hnXfewSuvvIJatWpBpVJh165dOHXqFCZNmvScz5aoYtq6dStu3bqFuXPnGl1FPjAwEIsWLcLy5cuxaNEibN26Fa1bt8aUKVPQoEEDPHjwAH/99RciIiJQt25dhIeHY926dejVqxcmTZqEF198EY8ePUJUVBR69OiBdu3awdPTEx07dsTs2bNRuXJl+Pr6YufOndiwYUOhy123bl3UqFEDkyZNghACzs7O+N///ofIyMhcaXUzdTVr1gyTJk1CzZo1cfv2bWzevBnffPON/pdYABg9ejTmzZuHY8eO4fvvvy/SNSUqKn4eTfs86q7RwYMH0bBhQ/32QYMGYcWKFRg1ahQuXryIdu3aITs7G4cOHUK9evX0Y8Ny6tGjBzZs2IDRo0fj5ZdfxvXr1/HJJ5/Ay8tLP5wAAD788EPcuHEDHTp0QNWqVfHgwQN8+eWXUCqVaNOmDQBpeu7AwEAEBwfDzc0N165dw8KFC+Hr64tatWoV+trmZeDAgfj555/RrVs3jB07Fi+++CKUSiVu3LiB3bt3o1evXujTpw/q1auH1157DQsXLoRSqUTHjh1x5swZzJ8/P1fXSp2DBw+iTZs2RlsTy6xSnHCCKijdrC15PWJiYsS+fftE+/bthZ2dnbCxsRHNmzcX//vf/wzymTRpkggODhaVK1cWarVaVK9eXYwbN04kJSUJIYS4ffu2GDZsmKhbt66ws7MT9vb2omHDhuKLL74QGo2mNE6dqMLp3bu3UKlU+c5YNXDgQKFQKERCQoK4fv26GD58uPD09BRKpVJ4e3uL/v37i9u3b+vT379/X4wdO1b4+PgIpVIp3N3dRffu3cWFCxf0aeLj48XLL78snJ2dhaOjo3jttdfE0aNHjc7KZWdnZ7Rc586dE506dRIODg6icuXK4pVXXhFxcXECgPjoo49ypX3llVeEi4uLUKlUwsfHRwwbNkw8fvw4V75t27YVzs7OIj09vZBXkahk8PNo+uexVatWolu3brm2P3r0SHz44YeiVq1aQqVSCRcXF9G+fXtx4MABfRpjs+TNmTNH+Pn5CbVaLerVqye+++47/cx1On/88Yfo2rWrqFKlilCpVMLd3V1069ZN7Nu3T5/m888/F6GhocLV1VV/jm+++aaIjY3VpynOLHlCCJGVlSXmz58vGjVqJKytrYW9vb2oW7euGDlypLh8+bI+XUZGhnjvvfeEu7u7sLa2Fs2bNxfR0dFGz//KlStGZ98r62RCCFEKcRoREVGFk5iYCF9fX/znP//BvHnzSrs4RBVaYT6P69evx4ABA3Dt2jWDMTpUNNOmTcOqVatw9erVPGfRK4sYMBEREZnZjRs38O+//+Kzzz7Drl27cOnSJX75IiolpnwehRAIDQ1FUFAQFi1a9JxLWr48ePAA1atXx9dff51rGvKyjpM+EBERmdn333+Ptm3b4uzZs/j5558ZLBGVIlM+jzKZDN999x28vb25lmMxxcTEYPLkyRg8eHBpF8VkbGEiIiIiIiLKQ5FamJYsWQJ/f39YW1sjKCgI+/btyzd9VFQUgoKCYG1tjerVq+da/+bs2bPo168f/Pz8IJPJsHDhwhI5LhGVD3v37kXPnj3h7e0NmUyG33//3eB1IQSmT58Ob29v2NjY6H85fFZGRgb+85//wNXVFXZ2dnjppZcKtVYHEZUPrEeIqKhMDpjWrVuH8PBwfPDBBzh+/DhatWqFrl27Ii4uzmj6mJgYdOvWDa1atcLx48cxZcoUvPvuu1i/fr0+TXp6OqpXr445c+bkueK5qcclovLj4cOHaNSoUZ79x+fNm4cFCxZg0aJFOHLkCDw9PdGpUyekpqbq04SHh2Pjxo1Yu3Yt9u/fj7S0NPTo0QNarfZ5nQYRlSLWI0RUZKZOq/fiiy+KUaNGGWyrW7eumDRpktH0EyZMEHXr1jXYNnLkSNG8eXOj6X19fcUXX3xR7OMSUfkEQGzcuFH/PDs7W3h6eoo5c+botz1+/Fg4OjqKZcuWCSGEePDggVAqlWLt2rX6NDdv3hRWVlbir7/+em5lJ6KygfUIEZnCpPn8MjMzcezYsVyLfoaFheHAgQNG94mOjkZYWJjBts6dO2P58uXIysqCUqk0y3EBqek8IyND/zw7Oxv37t2Di4uLZS2WRVQOCSGQmpoKb29vWFkVff6ZmJgYJCQkGNQzupXRDxw4gJEjR+LYsWPIysoySOPt7Y3AwEAcOHAAnTt3Npo36xCisquk6hCA9QhRRVXYesSkgCkpKQlarRYeHh4G2z08PJCQkGB0n4SEBKPpNRoNkpKS4OXlZZbjAsDs2bPx8ccfF5g/EZWe69evo2rVqkXeX1cHGKsfrl27pk+jUqlQuXLlXGlYhxBZtuLWIQDrEaKKrqB6pEgrRuX8RUQIke+vJMbSG9te0sedPHkyIiIi9M+Tk5Ph4+OD69evo1KlSiYdm4hKVkpKCqpVqwYHB4cSyc/U+qEwaZ5XHZKlzcbR2Pu4cT8dznYquDmo4WavhrVSjqt30nA5MRUXE1IRcycdAKBSWsFaaQWVlRVO3niAhJQMg/zcHdSo6+WAOh4O2HH+NmKS0uFqr8L3Q4NR090B9x5mYvTP/+DMzWRYK63wclA1qBRWkMsAuUwGpcIKNio5bJRy2KrkUMmtABOq67M3U/D9/hhYyYBlQ4IQWsPV4PU7KY/x69Eb2HYuAf/eeZhrf3cHNao42eBhpgYxd9ORpTGcyreyrRJ1vSqhprs9HK2VsLeWw06lgJ1agWf/Ox+kZ2HF3zGIu/cIAODnYgsXOzWOxd3Xp1ErrZCRZdpUwQ7Wcrg5WMPNXg1XexU02QKXE9Nw7W46tNmGE8+6O6hRzdkW7g5qONupUNlWBSc7JZJSMnApMRWXE9Nw4/4jPDtfrUwG2KnkcHNQw93BGu4Oalir5Dh5/QEu3U7LVZ7Ktko083eGp5MNktMz8eBRFpLTs3AvPRNJqRlIy3g6vkZhJUNtDwc0qFoJ9b0c4WBTsgtH3kvPxLLdV3EnLRMA0LOhF2p52GP1wTgkpkrvU6VchqqVbeDrYgsfZztUc7aBtUIOhVwGhZUVFFYyONurEOTrnO+xSroOASy7HiEi0xW2HjGppnR1dYVcLs/1S0piYmKuX2V0PD09jaZXKBRwcXEx23EBqTldrVbn2l6pUiVWUkRlRHG7pOgmiklISDBosX62fvD09ERmZibu379v8OtwYmIiQkND88zbnHVIeqYGURfvYNvZBOy6kIiUx5oi5iSHnb0DWtd2RacAT7Sp7QY3h6dl/r+0DAxZfhjn41Pw5i9nMbdfQ8z56wL+TcqCc2VHrBj2Apr4VM4nf9P1FQKp2Ur8duwGJm6+gk1jPODnagchBDaduIWPNp9F8qMsAIC1rT1a13ZFtwZeaFjVCVUr28BaKdfnpc0WuHE/HVcS0yAEEOBdCV6O1oV+37zeph7WHI7DlzsuIy4tE3FpGVDa2CEswAOvNfdFaA0XpGZocOPeI1y/n46E5Md4mKnBo0wt0jO1eJylhbuDNfxcbeHvagc/VztUsjbelTxDo8WVxDQkpmSgSmUb+DjbGpxLXtIzNUh7rIFaKZcCYblVnueXlJaB6Kt3cezafXg6WqNlTVcEeFWClVXe1+NRphaJqY+RlqFBDTf7QpWpOAaE1sHn2y5i1cFr+PNiMnAxGYAcnq6VMbylPwY388nzGhZFSXRrs9R6hIhKRkH1iEkBk0qlQlBQECIjI9GnTx/99sjISPTq1cvoPiEhIfjf//5nsG379u0IDg4u1Piloh6XiCoGf39/eHp6IjIyEk2aNAEgjXuMiorC3LlzAQBBQUFQKpWIjIxE//79AQDx8fE4c+YM5s2b99zLnPwoCy8t2o9rd9P121ztVQis4oj7DzORmJqBO6kZ0GQLeDtao65XJdTzckBtDwco5VZ4nKXFoywtHmdlw8/FFi1quub5JdjVXo01I5ph6A+HcfJGMt7+6RgAwNvRGqvefBE13Uvu13kdmUyGT/sE4sqdNByPe4ARq47iu9eDMXvreWw7exsAEFilEoa38EfHAI98vzzLrWTwdbGDr4tdkcqilFvh9RA/9GlSBeuOXEemNht9m1SFp6O1Pk0layUCvJUI8C7el1e1Qo763o6o723afrYqBWxVhbsdu9qr0bORN3o2KvxBbFTyIl+/oqhkrcTHvQLRp2lVTN98Fo+ztBjewh+9mnhDrTBvsFZUlliPENHzY3JbfEREBIYMGYLg4GCEhITg22+/RVxcHEaNGgVAanq+efMmVq1aBQAYNWoUFi1ahIiICIwYMQLR0dFYvnw51qxZo88zMzMT586d0/998+ZNnDhxAvb29qhZs2ahjktE5VdaWhquXLmifx4TE4MTJ07A2dkZPj4+CA8Px6xZs1CrVi3UqlULs2bNgq2trX41cUdHR7z55pt477334OLiAmdnZ4wfPx4NGjRAx44dn/v5rPg7BtfupsPFToU+Taqgc6AnmvpUhvyZVoLsbIEMTTZsVMX/gulkq8Lqt5rhzR+P4nDsPdRyt8eqN1+El6NNsfPOi1ohxzevBaHnov24nJiGdp/vgRBSd6x329fCqLY1oJQXb6C+KRyslXirVfXndjwCGldzwu9jWpR2MfTKWz1CRM9RUabWW7x4sfD19RUqlUo0bdpUREVF6V8bOnSoaNOmjUH6PXv2iCZNmgiVSiX8/PzE0qVLDV6PiYkRAHI9cuaT33ELIzk5WQAQycnJJu1HRCXPlM/j7t27jdYRQ4cOFUJIUwJ/9NFHwtPTU6jVatG6dWtx+vRpgzwePXok3nnnHeHs7CxsbGxEjx49RFxcnNnKnGcejzJFg4/+Er4T/xCbT9wscj5F8ShTIyLPJoiUR5nP7Zj/XLsnak3ZInwn/iG6LNwrzt5k/Uslw9TPY3mqR4ioZBT28ygTQhiOUC3HUlJS4OjoiOTkZPYbpkLRarXIysoq7WJYJKVSCbk879YRS/w8lkSZv955GZ9HXkINNztsH9fGoFWpvDoaew9XEtPQt2lVqBTPr1WJyjdLrEMAyy03UXlU2M9jyU6PQ1ROCCGQkJCABw8elHZRLJqTkxM8PT251sgTqY+z8P3+GADAux1qVYhgCQCC/ZwR7Jf/jGdERERlFQMmIiN0wZK7uztsbW35hd9EQgikp6cjMTERAAq13lpFsCr6GpIfZaG6qx16NDRxZgAiIiIqFQyYiHLQarX6YKmwU99TbjY20oQCiYmJcHd3z7d7XkXwMEOD7/f9CwB4p33NCtO6REREZOkYMBHloBuzZGtrW8olsXy6a5iVlVXhA6ZV0ddwPz0Lfi62eMmEKaGJiIhKgt+kP0u7CM9N7JzuJZofR98S5YHd8IqP11DyMEOD7/StS7WgeI7TaRMREVHx8K5NRGRm0Vfv4t7DTFRxskHvxmxdIiIisiQMmIjIKD8/PyxcuLC0i1EuPMzUAAB8XWzZukRERGRhOIaJqBxp27YtGjduXCKBzpEjR2BnZ1f8QhGytNJyd0oGS0RERBaHARNRBSKEgFarhUJR8Effzc3tOZSoYtBoswEASjnHdBEREVka/txJVE4MGzYMUVFR+PLLLyGTySCTyfDjjz9CJpNh27ZtCA4Ohlqtxr59+3D16lX06tULHh4esLe3xwsvvIAdO3YY5JezS55MJsP333+PPn36wNbWFrVq1cLmzZuf81lapix9wMQql4iIyNLw7k1UCEIIpGdqnvtDCFHoMn755ZcICQnBiBEjEB8fj/j4eFSrVg0AMGHCBMyePRvnz59Hw4YNkZaWhm7dumHHjh04fvw4OnfujJ49eyIuLi7fY3z88cfo378/Tp06hW7duuHVV1/FvXv3inVtKwJdlzyOXyIiIrI87JJHVAiPsrQI+HDbcz/uuRmdYasq3MfU0dERKpUKtra28PT0BABcuHABADBjxgx06tRJn9bFxQWNGjXSP//000+xceNGbN68Ge+8806exxg2bBgGDRoEAJg1axa+/vprHD58GF26dDH53CoSTfaTFiYuVktERGRx+HMnUQUQHBxs8Pzhw4eYMGECAgIC4OTkBHt7e1y4cKHAFqaGDRvq/7azs4ODgwMSExPNUubyhJM+EBERWS62MBEVgo1SjnMzOpfKcUtCztnu3n//fWzbtg3z589HzZo1YWNjg5dffhmZmZn55qNUKg2ey2QyZD9pPaG86cYwKTjpAxERkcVhwERUCDKZrNBd40qTSqWCVqstMN2+ffswbNgw9OnTBwCQlpaG2NhYM5eu4uKkD0RERJaLd2+icsTPzw+HDh1CbGwskpKS8mz9qVmzJjZs2IATJ07g5MmTGDx4MFuKzEij75LHFiYiIiJLw4CJqBwZP3485HI5AgIC4ObmlueYpC+++AKVK1dGaGgoevbsic6dO6Np06bPubQVRyZbmMgUQgAZqaVdCiIieqLs9zEiokKrXbs2oqOjDbYNGzYsVzo/Pz/s2rXLYNuYMWMMnufsomdsivMHDx4UqZwVjYbTipcfD+8CMhlg62ye/B89ANa9Blz7G2gyBGg3BXDwNM+xiIioUBgwERGZGacVLyfuXgW+aQNkpgFVgoDanYFaYYBXIymIKqysR4BcBVjlmNQlJR5Y3Q9IPCs9/2clcPo3IOQdoMW7gNqh5M7FXB7dl1rIrB1znx8RkYViwEREZGaZmidjmBRmbmF6cF36Mu9ez7zHeZYQQNptwNYVkJfjW4oQwNaJQOaTrnI3j0qP3TMBzwbA0P8BNpULzufOReD7ToDSBnjxLSDoDcDOFUi6AqzuAzyIA+w9gE4zgCPLgRuHgb3zgKPLAe8mQCVvoFIV6V+vRoBHA8DKyPvq4V0AQsrbmGvRwJ5ZQJVgoPn/Afbu+Z/7/VjgxlHgQaxUPl051JWAm8eA2H1AzD7gzvknO8mkoMmmMuDXAuj5tfFyEhFZgHJ8dyMiKht0LUwKc7YwXdoG/DoU0GYAr20AarQz37GEAG7+A5zfBJzbJH2ZdqkF9FoM+DQzzzFvHQcSzgCVvJ4GDOpKprXsPCsjDdgxHbgfA/T7vuBg5+IW4EokYKUEXt8E3L0MXI4Eru4CEk4DB74GOnyYfx5CAH9NAjKSpceuT4G984H6fYHL24D0u4BzdWDIRqCyH9BwAHD+f8DOj4G7V4ArO3Lnae0E+LUE/FsDMivgxhHpce9fADLgxRFA+6lS8KIrQ/QiIPIjQGiBmL3AwSVS978W7wKO1YAH16RrffusdN1vHAHSk0y8wAJ4/EB63I8BqjUHmg4xMQ8iorKBARMRkZnpphVXmauF6cQvwKZ3pC/AALD+LWDUPimoKGlXdgD/Gwck55hQ5O5l4IfOQLNRQIdpgMrO+P7GCCG1rDhWM94Kcfcq8EMXQPPYcLtcJQUJOlZKoFZHqdXGv3XewdStE8B/hwP3rkrP/1kFtBibd/myHkmBDgCE/kdqMfFrAQQNA87/Aax7FTi4DGj2f4C9W975XN4uBVhWSiDsU+DkGiD+BHDyF+l1r0bAq+uf5iGTAQEvAXW6SmOaHlwHUm4BKTeloObGUSkgufCH9MhFAIe/Bc5tBrrOAWq0B34f/TRt3R5AarzUQnTkO+DoD9L/W0ZK7qyslFL5XGsBD5OeluPxA8CtLuDXCvBvBfi2BKwrSV3zHt0HTv0K7JsvBX0BLz0N3IiILAgDJiIiM8vSTfpgji5Jf38JRD5p2Wg4AEg8J7V4/PYGMOwPQK7Mf39T3DgKrH0N0DwClHbSGJ6AXkC1F4FdM4ETq4FDS4FLW4HeSwHf0PzzS78HnFoHHPsRuHMBaPAK0Pc7w0BHCOCPcClYcvKRWpVSbkpfxrU5F1p+DJzdKD2cawBBQ6XAqVIVqcugTAYcXCpdr+wsQGEt5Xt8NRD6bt4B1v4vpICuUhWg9XjD1+p2B7ybArf+kdJ1mWU8D20WsG2K9Hfz/wOajwKajQSuHwIOfwdYKYBun0nBRk5yJVC9rfE8b50AYvcC1w5I26q+AFQNlsZY3ToB/BkhtTb9NgxQOUhdCq2UQJfZwAtvSfvE7AX2LwD+3SMFS3IV4FZH6u7n2UDK07MBoLQ2UgaN8a6Y9u7So81E4PxmIOkSEDUP6DzT+PXRSU0AdnwM1OwANHg5/7RERM8JAyYiIjN7unBtCXfJi/xQCpgAaWKATp9IY0y+aQNcPyj9qh/2af55ZGsByAoeX3L3KvBLfylYqtkR6P8ToLJ9+nrvxUBgH2DzWKmL3up+wP8dAJz9c+d1/xqwexZw7nfDVqPTvwFejYHQd55uO/Gz9IVeYS11hXOuLm3PTAce3ZMCKp20RCloO/Wb1HoU+UwXOSul1O3uYaL0vE53KWhY3Ez6Mn/jKFDthdxlvfcvsH+h9HfnmblbzmQyqcvb6r7Ake+BkDGAY5Xc+Rz+TupWZ+cGtH7/6b4+zaVHUciVUpmrvQC0ei/36zXaAf8XLQVy+xdIwZKjD9D/Rymg0qneRnokXZaCUNfahQ+0Cxq3plBJ13l1P+DQMqDp61IwlpMmQwpm934mjcOLiQLqvSTtX4H5TfqztIvw3MTO6V7aRSDKE0dgEhGZ2dOFa0uwyo39+2mw1OkT6cu8lZUUUPRaLG0/8LXUZSwvSZeBz2oCn7gAc/2Br4OA7zsCm9+VAghdMJJ2R/rCm35X6pb1ykrDYEmnZkdgzEHAJxTISgf+965hQAMAj1OAn/oAp9ZKwZJHA6D759IkB4AU5MTse3LcRGDbB9Lf7aY8DZYA6fiOVQGnak8fVYOAHl8A710Aen4F+LYA7D0ByKQWpYeJgFwNdJsPDPwZqOwL1O8t5Xf8J+PX6K8p0rgw/zZAQG/jaWq0l85ZmyF94c/p4V0gao70d/tpxluRzEVpDbSbLAVOXT8DRkYZBkvPcq0FeNQv2VZJQHpf1O4KZGukro3PvieEkMbfLWkO7PjoyQyEwVJAXsGDJSIqO9jCRERkZroWJkVJtjD9s1L6t8lr0mD9ZwW8BDQfAxxcLI1Z8aifu6VHCGDrBKmVBpD+1f1944iUv0egNE7n5Bpp4L6TDzD4N0Btn3e51A5Sa9OSUKll6J+VUh66Y25+R2r9qVQV6L8KqNJUamkRQppk4NQ64L9vAG9HAZHTpDEyng2l8ykstb3UHS9oqPRcmyXN5JdySzqHZ9c1avKadH5nNgBd5hgGghf+lLoX6rrL5dVlT9fK9GM3KfBqMdbweu+ZBTxOloLDJq8V/jxKkmtN6VFaOs8Eru6UxnBd3CK1JJ7+FTi57unMevYeQMePpa6lnFGPiMoQBkxERGb2tEteCX0JfHRfmp0OAIKGG0/T6eMnM6YdBjaOAob9adh96uJW6curXAUM/wtQ2kpjitKTpNfObgRunwG2PBmzY+Mszb7n4FFw+ZyrSxM/bJsCbJsK1OwkdVM79I1Ubisl8MqPUouQjkwG9FgI3D4H3D4NrOgqTWwgkwMvfV28KcvlSqk1yrFq7td8W0gz0t2PlcbaNBoobU+/B/wxTvo75B3j3cie5ddCamm6uguImiu1+t08Ko1ROvqDlKbL7Iq7NpFLDam74v4vgPUjpBZIPGlpkqulMV2t37eMtaaIqMLhTzhERGamydZ1ySuhFqZTvz3pzhYotdAYI1dK02WrHKTxTH9/8fS1rMfAtsnS3yHvSF203OtJX/oDegF9lgER54EucwG3etLYn0FrpS5bhdVslDRZQGaqFHhcPwJsnyq9FvaJ8fFCKltgwCppJrUH156UbzTg3bjwxzWVTAY0ftLqc3z10+1bJ0qtUq61gbaTC5dX+yfnd3INML8msGagFCCIbKk7n3+rEi26xWk1HnDwArIeAhBSsNrzK2D8JalLJoMlIiqjGDARlSNt27ZFeHh4ieU3bNgw9O7du8Tyq6gyNSXYwiTE0+54TV/Pfx2iyr5A9/nS33vmSNNHA9I6PPdjpS+vxiYLAABbZ+lX/zEHgQkxpq+vZCWXxlLJVdIaQz/1kcYRBfSSgqm8OFcH+n4vTRfuXB1oO8W04xZF40EAZNLiq/dipHFfp3+VytB7mfHZ4YypEmQ4zsmtrtQF76Wvpdn/Kjq1vbTGVLf5wNhTwBtbpG6TNk6lXTIionyxSx4RkZnpWphKZFrxW/9IXeXkaqBh/4LTNxwgDao/u0HqCjX4V2Df59JrnWbkPx5Jp6iLw7rVAdpMkBZozUyVpvp+aVHB+dUOA945KrVsGZtcoqQ5VpVmlLu6Swomz22WtrcYa9htsDD6LJNa7VxrMRAwxr2e9CAisiBsYSIqJ4YNG4aoqCh8+eWXkMlkkMlkiI2Nxblz59CtWzfY29vDw8MDQ4YMQVJSkn6///73v2jQoAFsbGzg4uKCjh074uHDh5g+fTpWrlyJTZs26fPbs2dP6Z2gBXu6cG0JdMn7Z5X0b0AvKaAoiEwG9FggrSF07yrwXXtp/Ei1ZtK6R+bWIhyo+iKgdgT6ryz8DHEuNaRWrudFNxnDke+l2fTc6ha+K96zlDZSd0MGS0RE5QZbmIgKQ4gng5SfM6VtoX/d//LLL3Hp0iUEBgZixgxpimatVos2bdpgxIgRWLBgAR49eoSJEyeif//+2LVrF+Lj4zFo0CDMmzcPffr0QWpqKvbt2wchBMaPH4/z588jJSUFK1asAAA4Oz/HL7DliKakFq7NSANO/1f6WzcDXGHYVJYWkl31EpCRDEAGdJ1X9JYjU8iVUtcrbdbzaS0qqjrdAWsnaVY+mRzovQRQqEu7VEREVAYwYCIqjKx0YJb38z/ulFu5F8rMg6OjI1QqFWxtbeHpKU2b/OGHH6Jp06aYNWuWPt0PP/yAatWq4dKlS0hLS4NGo0Hfvn3h6+sLAGjQoIE+rY2NDTIyMvT5UdGU2LTiZzdK69Q4V5cGzJuiehsg9F3gwFdA8BvmnUghJ7my5Nf2KWlKa2lM2IGvpHFdea1VREREFQ4DJqJy7NixY9i9ezfs7XOPU7l69SrCwsLQoUMHNGjQAJ07d0ZYWBhefvllVK5ciK5eVGj6LnnFnfShsJM95KXTDKB+H2ldI8qtw4dAg5d5fYiIyAADJqLCUNpKrT2lcdxiyM7ORs+ePTF37txcr3l5eUEulyMyMhIHDhzA9u3b8fXXX+ODDz7AoUOH4O/vbyRHKgp9l7z8AqakK0DqLcC/tfHXb5+T1lWyUgCNBhetIDJZ3tOQk9QK5tWotEtBRERlDAMmosKQyQrdNa40qVQqaLVa/fOmTZti/fr18PPzg0Jh/OMuk8nQokULtGjRAh9++CF8fX2xceNGRERE5MqPiiZTv3CtkVYhIaSFTf+aBGgzgT7fAo0GGKbJzga2TpD+rtO1cIvHEhERUYngLHlE5Yifnx8OHTqE2NhYJCUlYcyYMbh37x4GDRqEw4cP499//8X27dsxfPhwaLVaHDp0CLNmzcLRo0cRFxeHDRs24M6dO6hXr54+v1OnTuHixYtISkpCVlZWKZ+hZXq6cG2OKjcjDdgwAvgzQgqWAGDLeOD+NcN0R5dLawQpbaVudURERPTcMGAiKkfGjx8PuVyOgIAAuLm5ITMzE3///Te0Wi06d+6MwMBAjB07Fo6OjrCyskKlSpWwd+9edOvWDbVr18bUqVPx+eefo2vXrgCAESNGoE6dOggODoabmxv+/vvvUj5Dy5OdLaA1FjDduShN8X36N2lWtk4zpOm3M1KAjaOA7Ccte/digMgPpb87TpcmfCAiIqLnhl3yiMqR2rVrIzo6Otf2DRs2GE1fr149/PXXX3nm5+bmhu3bt5dY+SqirOxs/d8KuQx4dB/YtwA49A2gzQDsPYFXVgC+oUC9l4BlLYG4A8DfC4EW44BN70izNPq2BF4YUXonQkREVEExYCIiMiPdhA8qZMHmyFLg78+ltX4AoEYHoM8ywN5deu7sL62PtGk0sHsW8OA6cG0/oLQDei0CiruOExEREZmMARMRkRllabPhhFRsUH0E5c4EaaNbPakLXq1OuacHbzwYuPQXcH4zcExaMBidPpaCKSIiInruGDAREZlRllagh/wgqlslQNi5QdZxOtBoEGAlN76DTAb0/BK4fhhISwD8WgHBbz7XMhMREdFTDJiIiMwoS5uNhrJ/AQCyoDeAJq8VvJOtMzB4LXBsJdBmIrviERERlSIGTEREZqTRCjSwkgImeDcp/I7eTUxLT0RERGbBgIkoD9nPzG5GRcNrCGQ9fohaspvSE+/GpVoWIqLyyG/Sn6VdhOcmdk730i5ChcSAiSgHlUoFKysr3Lp1C25ublCpVJDlHJhP+RJCIDMzE3fu3IGVlRVUKlVpF6nUyO+cgUKWjSQ4wdXBq7SLQ0RERCZiwESUg5WVFfz9/REfH49bt26VdnEsmq2tLXx8fGBVgcfgqG6fBABckNVESwbeREREFocBE5ERKpUKPj4+0Gg00Gq1pV0ciySXy6FQKCp865z6zikAwCV5DbQs5bIQERGR6RgwEeVBJpNBqVRCqVSWdlHIgtkknQYAXFHUKuWSEBERUVFU3H4yRETmlvkQNslXAAAxSgZMRERElqhIAdOSJUvg7+8Pa2trBAUFYd++ffmmj4qKQlBQEKytrVG9enUsW7YsV5r169cjICAAarUaAQEB2Lhxo8HrGo0GU6dOhb+/P2xsbFC9enXMmDGDs3ARkV5qairCw8Ph6+sLGxsbhIaG4siRI/rXhw0bBplMZvBo3ry5+QqUcBoykY0EURkpShfzHYeISkSZq0OIqEwwOWBat24dwsPD8cEHH+D48eNo1aoVunbtiri4OKPpY2Ji0K1bN7Rq1QrHjx/HlClT8O6772L9+vX6NNHR0RgwYACGDBmCkydPYsiQIejfvz8OHTqkTzN37lwsW7YMixYtwvnz5zFv3jx89tln+Prrr4tw2kRUHr311luIjIzETz/9hNOnTyMsLAwdO3bEzZs39Wm6dOmC+Ph4/WPLli3mK9Ct4wCA09nVoZSzQZ+orCtzdQgRlQkm38EXLFiAN998E2+99Rbq1auHhQsXolq1ali6dKnR9MuWLYOPjw8WLlyIevXq4a233sLw4cMxf/58fZqFCxeiU6dOmDx5MurWrYvJkyejQ4cOWLhwoT5NdHQ0evXqhe7du8PPzw8vv/wywsLCcPToUdPPmojKnUePHmH9+vWYN28eWrdujZo1a2L69Onw9/c3qJ/UajU8PT31D2dnZ/MV6knAdCrbH0p5xZ78gqisK5N1CBGVCSYFTJmZmTh27BjCwsIMtoeFheHAgQNG94mOjs6VvnPnzjh69CiysrLyTfNsni1btsTOnTtx6dIlAMDJkyexf/9+dOvWzZRTIKJySjejobW1tcF2Gxsb7N+/X/98z549cHd3R+3atTFixAgkJiaar1C3TgAATgt/KCrw1OpElqBM1iFEVCaYNEteUlIStFotPDw8DLZ7eHggISHB6D4JCQlG02s0GiQlJcHLyyvPNM/mOXHiRCQnJ6Nu3bqQy+XQarWYOXMmBg0alGd5MzIykJGRoX+ekpJS6HMlIsvi4OCAkJAQfPLJJ6hXrx48PDywZs0aHDp0CLVqSRMudO3aFa+88gp8fX0RExODadOmoX379jh27BjUanWuPItVh2SkAknSDzxnsqsjQMGAiagsM0cdAvC7CFF5UKQ7eM51VYQQ+a61Yix9zu0F5blu3TqsXr0av/zyC/755x+sXLkS8+fPx8qVK/M87uzZs+Ho6Kh/VKtWreCTIyKL9dNPP0EIgSpVqkCtVuOrr77C4MGDIZfLAQADBgxA9+7dERgYiJ49e2Lr1q24dOkS/vzzT6P5FasOiT8FQOChtSeS4AilFbvkEZV1JV2HAPwuQlQemBQwubq6Qi6X52pNSkxMzNVCpOPp6Wk0vUKhgIuLS75pns3z/fffx6RJkzBw4EA0aNAAQ4YMwbhx4zB79uw8yzt58mQkJyfrH9evXzfldInIwtSoUQNRUVFIS0vD9evXcfjwYWRlZcHf399oei8vL/j6+uLy5ctGXy9WHRJ/AgBw17E+AHDSByILUNJ1CMDvIkTlgUl3cJVKhaCgIERGRhpsj4yMRGhoqNF9QkJCcqXfvn07goOD9QuC5pXm2TzT09NhlWMMgFwuz3dacbVajUqVKhk8iKj8s7Ozg5eXF+7fv49t27ahV69eRtPdvXsX169fh5eXl9HXi1WHPJnw4Y59XQCAgpM+EFmMkqpDAH4XISoPTBrDBAAREREYMmQIgoODERISgm+//RZxcXEYNWoUAOmXlJs3b2LVqlUAgFGjRmHRokWIiIjAiBEjEB0djeXLl2PNmjX6PMeOHYvWrVtj7ty56NWrFzZt2oQdO3YYDLLs2bMnZs6cCR8fH9SvXx/Hjx/HggULMHz48OJeAyIqJ7Zt2wYhBOrUqYMrV67g/fffR506dfDGG28gLS0N06dPR79+/eDl5YXY2FhMmTIFrq6u6NOnT8kX5knAdNu+HgBAxRYmojKvTNUhRFRmmBwwDRgwAHfv3sWMGTMQHx+PwMBAbNmyBb6+vgCA+Ph4gzWZ/P39sWXLFowbNw6LFy+Gt7c3vvrqK/Tr10+fJjQ0FGvXrsXUqVMxbdo01KhRA+vWrUOzZs30ab7++mtMmzYNo0ePRmJiIry9vTFy5Eh8+OGHxTl/IipHkpOTMXnyZNy4cQPOzs7o168fZs6cCaVSCY1Gg9OnT2PVqlV48OABvLy80K5dO6xbtw4ODg4lW5DHKcDdKwCAeLu6ABLZwkRkAcpMHUJEZYpM6GZgqABSUlLg6OiI5ORkNokTlTJL/DwWuswx+4CVPQBHH3zZYAO+2HEJg5v5YFafBs+vsETlnCXWIYBp5fablPdkEuVN7JzuRd6X16lweJ1yK+znkX1EiIhK2pPuePBujCytNM6SXfKIiIgsE+/gREQlLeG09K93E2Q9mZhGwWnFiYiILJLJY5iIiKgAvZcCLcYCts7IinoAAFBy4VoiIiKLxICJiKikyRWAZyAAQJN9DwC4cC0REZGF4k+eRERmpBvDxIVriYiILBPv4EREZpSllSYiVTBgIiIiski8gxMRmZFG38LELnlERESWiAETEZEZ6VqY2CWPiIjIMvEOTkRkRroxTAq2MBEREVkkBkxERGbESR+IiIgsG+/gRERmpMnWdcljCxMREZElYsBERGRGmRq2MBEREVky3sGJiMxI18KksGJ1S0REZIl4ByciMiNOK05ERGTZGDAREZlRJqcVJyIismi8gxMRmZGG04oTERFZNAZMRERmpJtWXMUWJiIiIovEOzgRkRllPemSp2DAREREZJF4ByciMiNNNid9ICIismQMmIiIzCiLkz4QERFZNN7BiYjMSDeGSWHFFiYiIiJLxICJiMiMsvTrMLG6JSIiskS8gxMRmZGGXfKIiIgsGu/gRERmIoSAJlsXMLFLHhERkSViwEREZCa6CR8ATitORERkqXgHJyIyE92U4gAXriUiIrJUvIMTEZlJlubZFiZ2ySMiIrJEDJiIiMwk65kWJk4rTkREZJkYMBERmcnTKcVlkMkYMBEREVkiBkxERGaim1JcYcWqloiIyFLxLk5EZCaZz7QwERERkWViwEREZCZctJaIiMjy8S5ORGQmT8cwsaolIiKyVLyLExGZiS5g4pTiRERElosBExGRmWiy2SWPiIjI0vEuTkRkJlkaTvpARERk6RgwERGZSVY2pxUnIiKydLyLExGZib6FScGqloiIyFLxLk5EZCaa7CcBkxW75BEREVkqBkxERGaS9WQdJs6SR0REZLkYMBERmQnXYSIiIrJ8vIsTEZmJRstpxYmIiCwd7+JERGaSqeW04kRERJaOARMRkZlongRMCrYwERERWSzexYmIzEQ36YOKARMREZHF4l2ciMhMsp5MK67gtOJEREQWiwETEZGZaPTTirOqJSIislS8ixMRmYluWnEVJ30gIiKyWAyYiIjMJIstTERERBaPd3EiIjPhwrVERESWj3dxIiIz0XAdJiIiIotXpIBpyZIl8Pf3h7W1NYKCgrBv375800dFRSEoKAjW1taoXr06li1blivN+vXrERAQALVajYCAAGzcuDFXmps3b+K1116Di4sLbG1t0bhxYxw7dqwop0BE5VBqairCw8Ph6+sLGxsbhIaG4siRI/rXhRCYPn06vL29YWNjg7Zt2+Ls2bNmK0/mky55bGEisgxlrQ4horLB5Lv4unXrEB4ejg8++ADHjx9Hq1at0LVrV8TFxRlNHxMTg27duqFVq1Y4fvw4pkyZgnfffRfr16/Xp4mOjsaAAQMwZMgQnDx5EkOGDEH//v1x6NAhfZr79++jRYsWUCqV2Lp1K86dO4fPP/8cTk5Opp81EZVLb731FiIjI/HTTz/h9OnTCAsLQ8eOHXHz5k0AwLx587BgwQIsWrQIR44cgaenJzp16oTU1FSzlOfpwrVsYSKyBGWtDiGiskEmhBCm7NCsWTM0bdoUS5cu1W+rV68eevfujdmzZ+dKP3HiRGzevBnnz5/Xbxs1ahROnjyJ6OhoAMCAAQOQkpKCrVu36tN06dIFlStXxpo1awAAkyZNwt9//11ga1Z+UlJS4OjoiOTkZFSqVKnI+RBR8ZX05/HRo0dwcHDApk2b0L17d/32xo0bo0ePHvjkk0/g7e2N8PBwTJw4EQCQkZEBDw8PzJ07FyNHjizxMo9bdwIbj9/EB93qYUTr6kU/OSLKxRLrEFPL7Tfpz6KfkIWJndO94ER54HUqHF6n3Ar7eTSphSkzMxPHjh1DWFiYwfawsDAcOHDA6D7R0dG50nfu3BlHjx5FVlZWvmmezXPz5s0IDg7GK6+8And3dzRp0gTfffddvuXNyMhASkqKwYOIyieNRgOtVgtra2uD7TY2Nti/fz9iYmKQkJBgUNeo1Wq0adMmz/qruHVIJscwEVkMc9QhAL+LEJUHJgVMSUlJ0Gq18PDwMNju4eGBhIQEo/skJCQYTa/RaJCUlJRvmmfz/Pfff7F06VLUqlUL27Ztw6hRo/Duu+9i1apVeZZ39uzZcHR01D+qVatmyukSkQVxcHBASEgIPvnkE9y6dQtarRarV6/GoUOHEB8fr69PTKm/iluHPO2SxzFMRGWdOeoQgN9FiMqDIt3FZTLDX0uFELm2FZQ+5/aC8szOzkbTpk0xa9YsNGnSBCNHjsSIESMMugbmNHnyZCQnJ+sf169fL/jkiMhi/fTTTxBCoEqVKlCr1fjqq68wePBgyOVyfRpT6q/i1iG6dZhUDJiILEJJ1yEAv4sQlQcm3cVdXV0hl8tz/ZKSmJiY6xcXHU9PT6PpFQoFXFxc8k3zbJ5eXl4ICAgwSFOvXr08J5sApKbySpUqGTyIqPyqUaMGoqKikJaWhuvXr+Pw4cPIysqCv78/PD09AcCk+qu4dUgWJ30gsiglXYcA/C5CVB6YFDCpVCoEBQUhMjLSYHtkZCRCQ0ON7hMSEpIr/fbt2xEcHAylUplvmmfzbNGiBS5evGiQ5tKlS/D19TXlFIioArCzs4OXlxfu37+Pbdu2oVevXvovPM/WNZmZmYiKisqz/iouLlxLZJnKSh1CRGWDwtQdIiIiMGTIEAQHByMkJATffvst4uLiMGrUKABS0/PNmzf1Y4tGjRqFRYsWISIiAiNGjEB0dDSWL1+un/0OAMaOHYvWrVtj7ty56NWrFzZt2oQdO3Zg//79+jTjxo1DaGgoZs2ahf79++Pw4cP49ttv8e233xb3GhBRObFt2zYIIVCnTh1cuXIF77//PurUqYM33ngDMpkM4eHhmDVrFmrVqoVatWph1qxZsLW1xeDBg81SHo1+HSa2MBFZgrJWhxBR2WBywDRgwADcvXsXM2bMQHx8PAIDA7FlyxZ9S098fLxBNzl/f39s2bIF48aNw+LFi+Ht7Y2vvvoK/fr106cJDQ3F2rVrMXXqVEybNg01atTAunXr0KxZM32aF154ARs3bsTkyZMxY8YM+Pv7Y+HChXj11VeLc/5EVI4kJydj8uTJuHHjBpydndGvXz/MnDlT35o9YcIEPHr0CKNHj8b9+/fRrFkzbN++HQ4ODmYpT1a2FDAprNjCRGQJylodQkRlg8nrMFkyrsNEVHZY4ufR1DJ3+3IfzsWnYOXwF9GmtttzKCFRxWGJdQjAdZjywvWFCofXqXBKdR0mIiIqPE32kzFMVuySR0REZKkYMBERmYluWnGlglUtERGRpeJdnIjITPTTirOFiYiIyGIxYCIiMhNOK05ERGT5eBcnIjKTp9OKs6olIiKyVLyLExGZib5LHtdhIiIislgMmIiIzEQ36YOKLUxEREQWi3dxIiIz0U0rzhYmIiIiy8WAiYjIDIQQT6cVZwsTERGRxeJdnIjIDDTZQv+30opVLRERkaXiXZyIyAx0Ez4AgFLBLnlERESWigETEZEZ6LrjAYCCLUxEREQWi3dxIiIz0DzbwsRJH4iIiCwWAyYiIjPQtTAprGSQyRgwERERWSoGTEREZsBFa4mIiMoHBkxERGagC5g4pTgREZFl452ciMgMdNOKM2AiIiKybLyTExGZQaZG18LELnlERESWjAETEZEZ6FqYOKU4ERGRZeOdnIjIDDRatjARERGVBwyYiIjMIJOTPhAREZULvJMTEZmBRrcOEwMmIiIii8Y7ORGRGeimFVexSx4REZFFY8BERGQGWWxhIiIiKhd4JyciMoMsTvpARERULjBgIiIyA002J30gIiIqD3gnJyIyA32XPCu2MBEREVkyBkxERGaQxWnFiYiIygXeyYmIzEA3rTgDJiIiIsvGOzkRkRlw0gciIqLygQETEZEZcFpxIiKi8oF3ciIiM9BwDBMREVG5wDs5EZEZsEseERFR+cCAiYjIDLKyddOKs5olIiKyZLyTExGZQZbmSQuTgi1MRERElowBExGRGWietDAp2cJERERk0XgnJyIyg0xO+kBERFQu8E5ORGQGulnyFJz0gYiIyKIxYCIiMgPNk3WYVGxhIiIismi8kxMRmUEmW5iIiIjKBQZMRERmoGthUrCFiYiIyKLxTk5EZAa6hWtVbGEiIiKyaAyYiIjMgAvXEhERlQ+8kxMRmcHThWtZzRIREVky3smJiMxAk/0kYLJilzwiIiJLxoCJiMgMsp5M+sCFa4mIiCwb7+RERGaQxWnFiYiIygUGTEREZqBhCxMREVG5wDs5EZEZ6FqYGDARERFZNt7JiYjMICubXfKIiIjKAwZMRERmkKWRuuSp2MJERERk0Yp0J1+yZAn8/f1hbW2NoKAg7Nu3L9/0UVFRCAoKgrW1NapXr45ly5blSrN+/XoEBARArVYjICAAGzduzDO/2bNnQyaTITw8vCjFJ6JySKPRYOrUqfD394eNjQ2qV6+OGTNmIPtJSw8ADBs2DDKZzODRvHlz85SHLUxEFqWs1SFEVHYoTN1h3bp1CA8Px5IlS9CiRQt888036Nq1K86dOwcfH59c6WNiYtCtWzeMGDECq1evxt9//43Ro0fDzc0N/fr1AwBER0djwIAB+OSTT9CnTx9s3LgR/fv3x/79+9GsWTOD/I4cOYJvv/0WDRs2LOIpE1F5NHfuXCxbtgwrV65E/fr1cfToUbzxxhtwdHTE2LFj9em6dOmCFStW6J+rVCqzlIfTihNZlrJWhxBR2WFywLRgwQK8+eabeOuttwAACxcuxLZt27B06VLMnj07V/ply5bBx8cHCxcuBADUq1cPR48exfz58/UB08KFC9GpUydMnjwZADB58mRERUVh4cKFWLNmjT6vtLQ0vPrqq/juu+/w6aefmnyyRFR+RUdHo1evXujevTsAwM/PD2vWrMHRo0cN0qnVanh6epq9PPpJH6wYMBFZgrJWhxBR2WHSnTwzMxPHjh1DWFiYwfawsDAcOHDA6D7R0dG50nfu3BlHjx5FVlZWvmly5jlmzBh0794dHTt2LFR5MzIykJKSYvAgovKpZcuW2LlzJy5dugQAOHnyJPbv349u3boZpNuzZw/c3d1Ru3ZtjBgxAomJiXnmWZw6RDetOLvkEVkGc9QhAL+LEJUHJrUwJSUlQavVwsPDw2C7h4cHEhISjO6TkJBgNL1Go0FSUhK8vLzyTPNsnmvXrsU///yDI0eOFLq8s2fPxscff1zo9ERkuSZOnIjk5GTUrVsXcrkcWq0WM2fOxKBBg/RpunbtildeeQW+vr6IiYnBtGnT0L59exw7dgxqtTpXnkWtQ4QQyOS04kQWxRx1CMDvIkTlgcld8gBAJjP8xVQIkWtbQelzbs8vz+vXr2Ps2LHYvn07rK2tC13OyZMnIyIiQv88JSUF1apVK/T+RGQ51q1bh9WrV+OXX35B/fr1ceLECYSHh8Pb2xtDhw4FAAwYMECfPjAwEMHBwfD19cWff/6Jvn375sqzqHWINlvo/1ayhYnIIpijDgH4XYSoPDApYHJ1dYVcLs/VmpSYmJirhUjH09PTaHqFQgEXF5d80+jyPHbsGBITExEUFKR/XavVYu/evVi0aBEyMjIgl8tzHVutVuf5iw8RlS/vv/8+Jk2ahIEDBwIAGjRogGvXrmH27Nn6Lzs5eXl5wdfXF5cvXzb6elHrEN2EDwBbmIgshTnqEIDfRYjKA5Pu5CqVCkFBQYiMjDTYHhkZidDQUKP7hISE5Eq/fft2BAcHQ6lU5ptGl2eHDh1w+vRpnDhxQv8IDg7Gq6++ihMnThgNloioYklPT4dVjgkW5HK5wZTAOd29exfXr1+Hl5dXiZYl65ljcgwTkWUoS3UIEZUtJnfJi4iIwJAhQxAcHIyQkBB8++23iIuLw6hRowBITc83b97EqlWrAACjRo3CokWLEBERgREjRiA6OhrLly83mP1u7NixaN26NebOnYtevXph06ZN2LFjB/bv3w8AcHBwQGBgoEE57Ozs4OLikms7EVVMPXv2xMyZM+Hj44P69evj+PHjWLBgAYYPHw5AmmVz+vTp6NevH7y8vBAbG4spU6bA1dUVffr0KdGyaJ5tYeIseUQWoSzVIURUtpgcMA0YMAB3797FjBkzEB8fj8DAQGzZsgW+vr4AgPj4eMTFxenT+/v7Y8uWLRg3bhwWL14Mb29vfPXVV/opxQEgNDQUa9euxdSpUzFt2jTUqFED69aty7UGExFRXr7++mtMmzYNo0ePRmJiIry9vTFy5Eh8+OGHAKRfik+fPo1Vq1bhwYMH8PLyQrt27bBu3To4ODiUaFl0U4rLrWSwsmILE5ElKEt1CBGVLTKhm4GhAkhJSYGjoyOSk5NRqVKl0i4OUYVmiZ/Hwpb5xv10tJy7G2qFFS5+2vU5lpCo4rDEOgQwrdx+k/58TqUqfbFzuhd5X16nwuF1yq2wn0f2FSEiKmG6SR9UnPCBiIjI4vFuTkRUwjRPuuRxwgciIiLLx4CJiKiEcdFaIiKi8oN3cyKiEqabJY8BExERkeXj3ZyIqIRpsnUtTOySR0REZOkYMBERlbBMjdTCpGALExERkcXj3ZyIqITpWpgUXIOJiIjI4jFgIiIqYbqFa1UKVrFERESWjndzIqISpluHiS1MRERElo8BExFRCcvitOJERETlBu/mREQljNOKExERlR+8mxMRlbCnLUzskkdERGTpGDAREZUw/RgmtjARERFZPN7NiYhKGBeuJSIiKj8YMBERlbBMDSd9ICIiKi94NyciKmGabN204qxiiYiILB3v5kREJSxLo1u4ll3yiIiILB0DJiKiEpbFFiYiIqJyg3dzIqISpuHCtUREROUG7+ZERCWM6zARERGVHwyYiIhKmBCATAYoGDARERFZPEVpF4CIqLyZ2iMAH3SvByFKuyRERERUXAyYiIjMQCaTQcYGJiIiIovHLnlERERERER5YMBERERERESUBwZMREREREREeWDARERERERElAcGTERERERERHlgwERERERERJQHBkxERERERER5YMBERERERESUBwZMREREREREeWDARERERERElAcGTDnce5iJiF9P4J1f/intohARERERUSljwJSDEAIb/rmJP07FQ5stSrs4RERERERUihgw5WBvrdD/nfZYU4olISIiIiKi0saAKQe1Qg6VQrosqRlZpVwaIiIiIiIqTQyYjHBQS61MaRlsYSIiIiIiqsgYMBnh8KRbXiq75BERERERVWgMmIzQjWPiGCYiIiIiooqNAZMRDmolACDlMccwERERERFVZAyYjNC3MHEMExERERFRhcaAyQiOYSIiIiIiIoABk1H6WfIYMBERERERVWgMmIxglzwiIiIiIgIYMBnlYM1JH4iIiIiIiAGTUfbskkdERERERGDAZBQnfSAiIiIiIoABk1EOHMNERERERERgwGSUbgxTKscwERERERFVaEUKmJYsWQJ/f39YW1sjKCgI+/btyzd9VFQUgoKCYG1tjerVq2PZsmW50qxfvx4BAQFQq9UICAjAxo0bDV6fPXs2XnjhBTg4OMDd3R29e/fGxYsXi1L8AunHMLGFichiaDQaTJ06Ff7+/rCxsUH16tUxY8YMZGdn69MIITB9+nR4e3vDxsYGbdu2xdmzZ0ux1ERUVrAOIaK8mBwwrVu3DuHh4fjggw9w/PhxtGrVCl27dkVcXJzR9DExMejWrRtatWqF48ePY8qUKXj33Xexfv16fZro6GgMGDAAQ4YMwcmTJzFkyBD0798fhw4d0qeJiorCmDFjcPDgQURGRkKj0SAsLAwPHz4swmnnT9clL4VjmIgsxty5c7Fs2TIsWrQI58+fx7x58/DZZ5/h66+/1qeZN28eFixYgEWLFuHIkSPw9PREp06dkJqaWoolJ6KygHUIEeVFJoQQpuzQrFkzNG3aFEuXLtVvq1evHnr37o3Zs2fnSj9x4kRs3rwZ58+f128bNWoUTp48iejoaADAgAEDkJKSgq1bt+rTdOnSBZUrV8aaNWuMluPOnTtwd3dHVFQUWrduXaiyp6SkwNHREcnJyahUqVKe6ZLTs9BoxnYAwMVPu0CtkBcqfyIqvMJ+HgurR48e8PDwwPLly/Xb+vXrB1tbW/z0008QQsDb2xvh4eGYOHEiACAjIwMeHh6YO3cuRo4c+dzLTERFZ4l1iKnl9pv0Z9FPyMLEzule5H15nQqH1ym3wn4eTWphyszMxLFjxxAWFmawPSwsDAcOHDC6T3R0dK70nTt3xtGjR5GVlZVvmrzyBIDk5GQAgLOzsymnUCh26qcB0sMMbYnnT0Qlr2XLlti5cycuXboEADh58iT279+Pbt26AZBauxMSEgzqGrVajTZt2uRb1xBRxcA6hIjyojAlcVJSErRaLTw8PAy2e3h4ICEhweg+CQkJRtNrNBokJSXBy8srzzR55SmEQEREBFq2bInAwMA8y5uRkYGMjAz985SUlHzPT0cht4KtSo70TC1SH2fB2U5VqP2IqPRMnDgRycnJqFu3LuRyObRaLWbOnIlBgwYBgL4+MVbXXLt2zWieRa1DiMjymKMOAViPEJUHRZr0QSaTGTwXQuTaVlD6nNtNyfOdd97BqVOn8uyupzN79mw4OjrqH9WqVcs3/bN0Ez9wLSYiy7Bu3TqsXr0av/zyC/755x+sXLkS8+fPx8qVKw3SmVLXFKcOISLLYo46BGA9QlQemBQwubq6Qi6X52r5SUxMzPWLi46np6fR9AqFAi4uLvmmMZbnf/7zH2zevBm7d+9G1apV8y3v5MmTkZycrH9cv369wHPU4eK1RJbl/fffx6RJkzBw4EA0aNAAQ4YMwbhx4/RjKz09PQHApPqrOHUIEVkWc9QhAOsRovLApIBJpVIhKCgIkZGRBtsjIyMRGhpqdJ+QkJBc6bdv347g4GAolcp80zybpxAC77zzDjZs2IBdu3bB39+/wPKq1WpUqlTJ4FFY9k/WYuLU4kSWIT09HVZWhlWaXC7XTwns7+8PT09Pg7omMzMTUVFRedZfxalDiMiymKMOAViPEJUHJo1hAoCIiAgMGTIEwcHBCAkJwbfffou4uDiMGjUKgPRLys2bN7Fq1SoA0ox4ixYtQkREBEaMGIHo6GgsX77coDvd2LFj0bp1a8ydOxe9evXCpk2bsGPHDuzfv1+fZsyYMfjll1+wadMmODg46H/hcXR0hI2NTbEugjGV9C1MXLyWyBL07NkTM2fOhI+PD+rXr4/jx49jwYIFGD58OACpG014eDhmzZqFWrVqoVatWpg1axZsbW0xePDgUi49EZU21iFElBeTA6YBAwbg7t27mDFjBuLj4xEYGIgtW7bA19cXABAfH2+wJpO/vz+2bNmCcePGYfHixfD29sZXX32Ffv366dOEhoZi7dq1mDp1KqZNm4YaNWpg3bp1aNasmT6Nbhrztm3bGpRnxYoVGDZsmKmnUSAuXktkWb7++mtMmzYNo0ePRmJiIry9vTFy5Eh8+OGH+jQTJkzAo0ePMHr0aNy/fx/NmjXD9u3b4eDgUIolJ6KygHUIEeXF5HWYLJkpax9M+O9J/Hr0Bt7vXAdj2tV8TiUkqjgscU0jSywzUXllqZ9HrsNkHNcXKhxep8Ip1XWYKhJ7tTSGiZM+EBERERFVXAyY8mBvreuSxzFMREREREQVFQOmPFTitOJERERERBUeA6Y86Cd9YMBERERERFRhMWDKg4M1xzAREREREVV0DJjyoBvDlMppxYmIiIiIKiwGTHlw4KQPREREREQVHgOmPDg8GcNk/yge+PkV4MceQObDUi4VERERERE9TwyY8mBvrUAXq8NYm/0+cHk7ELsPOLe5tItFRERERETPEQMmYzLT4bp7IpapFsJR9hBC/WTl31NrS7dcRERERET0XDFgyinpMvBdeyhPrES2kGGJ5iXcG/yX9Nq/UUDyzdz7ZD4ELkcC1w4AiReAtDuAVgNkZ0v/ajIBbQUYC6XNAvZ9DiScLu2SEBERERGVCEVpF6DMUdoCaQmAvQdGpo1ApCYAnW194eITAsRFA6d/A1qGG+7z+2jg3O8FZCwD2k6SHuXViZ+BnTOA0+uB0QdKuzRERERERMXGFqacHKsAg9YCo/7GWXVTAE8Wr200UHr95FpAiKfprx+RgiWZFeBcA7B2yiNjAUQvBjLTC1eOR/eNt2aVtKzHwJWdwF+TgUUvAN+0Bh4nFy2vy5HSv4lnpZY2IiIiIiILxxYmY3yaA3iyeG3yY2nx2oDewJYJwJ3zQMIpwKuRFDjtmC7t02gw0Hux9LdW8zTokMmkxzetgQdxwIU/gIb98z++VgN83xG4fw0Y8BNQp2vJnl/yDeDSNmkyi5i9QFaOIO6fVUDof0zLU5sldVnUObsBcJ9S/LIWRJMJHPgSqNkR8G5i/uMRERERUYXCgCkf9s+uxWTjKgUu534HTq6TAqYrO4Br+wG5Gmg3+emOcgVg52KYWaPBQNQcqdtaQQHTxT+Bu1ekv399HRi0RgoITJGdDVzdCdyPBTLTpHFWj5OlcVa3zximdfCS8ldYA0e+Aw5/CzQfDVjJC3+864eBzNSnz89sANpOloJFczr2I7DrU+Cfn4B3j5tWZiIiIiKiAjBgyodu8drUxxppQ6OBUsB0+jeg4/SnrUvN3gYcq+afWeNBUsD0bxTw4DrgVC3vtIe+lf61dQXSk4C1rwKv/gb4ty5cwbOzgf+9Cxz/yfjrMiug6otA7TCgVmfAo74U2GSmA2f+K7WEXdwK1OtRuOMBUvAIALW7Ald3AXcvS4GZZ4PC51EUJ9dI/z64JrWa1e1m3uNZAm2WFBhf2iZdF2snwMYJsHWW3lOVfYHK/tJ7tqAAU5MJWCkAK/beJSIiooqJAVM+7NU5AqaaHQFbF+BhIrBpjBQQqB2BlhEFZ1bZD/BrJa3ndHIN0GaC8XQJp6VWK5kcGLET2DoJuLQV+GUA8NoGwDck/+M8GyzJrIA63QB1JUBtD6jsAPeAJ+fhnHtflS0QNAzY/wVwaFnRAqb6faQv4Rf+AM5uNG/AdOcScOufp88PLatYAdOtE8C9q9I4tKx0IOuRdD2u7AQyUgre30oJuNYCei0GqjTN/XrieeC7DoC1o/RjQePBUnpACsriT0kToaTG59632UjAyadYp0dERERUFjBgyoeDvkvek4BJrgQCXwYOfwOc/lXa1jLcePBhTONXpYDpxM9A6/eNd1c79I30b0AvKcjqvxJYM0jqXvfzK8DA1UD1tsbzz84G/hj7NFjq8y3Q8JXCnq7khbeAv7+SyplwBvAMLHif1NvSuC4AqNH+acB0ZgPQfppp3fKSb0pf1Gu0L7hVQ7culldj6fgxUdK+7vUKfzxLdD8W2D4VOP+/vNPYugK1O0vjujJSpElE0u8Dabel/e/HAtlZQOI5IGoeMNjIGmOHvgGyHkqP/QukR5VgKbC+cTT32LdnBfRmwERERETlAgOmfDhYKwEAqY+fWUOp0QApYAKksT/NRhU+w4CXgC3vS19Wrx0A/FoYvp5+T+ruB0i/0AOAQg0M/Bn4pb80QcPqfkCPL4CmrxvuqwuW/llV9GAJkLpp1espdT08/A3w0tcF73N1l/SvV2PA3g2o3QVQ2AD3Y4D4E4WbjEEIqezbpkhjrhoNlo4tz+Mtmp0NnHoStLYYK7Vmnd8sfcnvubDg41mizIdS69/fXwHaDKkVslozqeVQaS1Nie9YTbr+VZrm390uWwvcPAYs7wRc3gak3AIqeT9zrHTgzHrp77aTgVvHpVkQbx59msbaCfAJAVxrAsgRFDt4lNRZExEREZUqBkz50HXJ07cwAYB3U8CtnjRbXpuJ0q/thaWyA+r3llqATvycO2D6ZyWgeSxNKFGt2dPtShvg1f9K3QBP/wZs/g9w9yrQ4SMpuDjxsxQo3I95Eix9U7RgSaf5/0kB06lfgQ7Tc09gkdOVJ9OJ6yamUNtLrRvnfpdamQoKmFJvS+d0edvTbSd/kc6t33JAocq9z7W/geTrUnfDOl0Bew8pYDq5FujwYeFb/cqqmH3Af9+QuttZWUnjiDQZ0jUBpPFsXeYCHgFFy99KDlR7EfAJBeIOAMd/Btq8//T1c5uklqnKfkDrCVIZUm9L11hmBfiGAq51OLaJiIiIyj0GTPnQdclLefxMwCSTAQNWSy0ngf1Mz7TJa1LAdPZ3oOs8KbgApKnED38v/d1sVO5ubAo10Pc7aa2nqDnA3wuB2P3AnYtPZ6dTOwI9FgANXja9XM+q1kwK2uJPSkFcq3zGaGVrn7YwPTuTX2BfKWA6+zvQaYZ0Psk3gL2fAff+fTKuykEKIs9sAB7dA+QqqQtfZV9g/VvSl/O1g4D+P+UOTE8+6UJWv7cUUPqGAh4NgNunpevbYmzRz18IICMVsK5U9DyKIyMV+P3/gId3cr/m5AN0ngXU7VEyMxAGDZUCpn9WAa3eexoA6SYMafza020OHsCLI4p/TCIiIiILwoApH/oWpmcDJkDqguRas2iZVmsmBT33rkq/4jd5Vdp+8U8g5YY0qUT9vsb3lcmk6cud/YFN7zztHuVaW+rC13Dg0wCsOGQyoNn/Ab+PAo58L63JJFcaT3vruDQ+Ru0IVH3h6fZaYYDKHkiOk8YWxf4NHPhKakEzxqMB0Pfbpy0mKntpdsArO6RuiIPWSDO9AVJ3sXObpL8bDXpa5uajpFa4w98Bzcfk3Z3PmKxHUqvOpa3S7HIpt4CeX0oBhTmcWCONg+s67+lECjo7P5Faz5x8gFfXS+eWrQVENuBS03iLW1EF9AK2TpD+n/7dJQW9d69KLXgyK2miByIiIqIKjAFTPnRjmAy65BWXTCZ9Cd31iTSbXdRcadxJcpz0etAb0niU/DQaKE0LfWqt1NJQvV3Jd40K7AtETgNSbgIb3gZ6LzVeLt3seNXbGAYoShupq9zp34Cf+khf9gHAtwXQZIg0YUBGqvRw8ASaDjUMBGp2AIZslMZuxR0AvmsntTR5BgIXt0itak4+QLXmz5T5ZSDyQynYuLhFGjNWEG2W9H9x+LvckxhseR+oGixNu/6sOxeBLeOliQ1eeLPgY+T0MEnaPzMNWNkTeGML4Fxdei3ukLQOFiAFbG61Tc/fFEobKdA+/A1wbKUUMB1fLb1WowPgWMW8xyciIiIq4zgAIR9P12HKKiCliZoMkcbcZGukdXKu7ZfWPrJSAMHDC5eHTzNp8oeaHcwzjkShBrrNl6aePrsBWPWS9EU/J13AVKtT7td0LWUi+8mMfz8Bw/6U1qR64U1phsEO06RuXsZaTXxDgGF/AI4+Uje+7ztKLTO67ngNBxqeu9JamhYdAKIXSV3r8pN8A1jRDfj7SylYqlQFCH4TGPyb1EKmzQD++6bUoqXzIA5Y1VuagGPLeCnAMUaIvI+/7/OnY5FS44GVL0n5ajKksVwQ0oyKNdrnX/6SomtFu7gFSIkHTvwiPW865Pkcn4iIiKgMYwtTPvTTiufsklfsjD2AceeAtATpS3vyDalVxLNh2fpFv35vafKEda8B1w9JAcurvz3tQpZ+T5ppDZBaI3Kq3QVoPxVQOQDBb0hBmKm8GgEjo4ANI6Tg7PdnZiVsNDB3+hfeAqIXS+U99as0q6Exl7YDG99+2p2w1yJpdkDduCDvJsDSUGlyj+0fSMFpWqIULKXekoLbbI1UnlH7pbFYOim3gDUDpUBxyO+AnevT1x7ESd0cAWlyjr2fAXevSC1NNdoDSRcBO3cg7FPTr1VRedSXulPeOCJd57QEqWto7a7PrwxEREREZRRbmPKRa+HakiRXSFN4+zSXJmloOU5qLSpr/FsDb+4AnHylWfi+bQssegH4qimwtIUUFLgHGA/0rKyk9aaajypasKRj6yy1+rSdDP301VVfAFxq5E5byfvposDbJktB3bOEAPbMBX55RQqWvBpLAVnAS4aTKNi7AX2fTB9/9Aepm9rqvtLYM0cfKUiqVEVq+Yr86Ol+qbel4Cf+pLQI8a+vA5rMp6/vmQtoM6VFjBsOAF7f/OTaxkrHAYBunz3/Wf6aPmllit0n/dtwYMmOlSIiIiKyUAyY8mGva2HK1CA7u4DuXeWZW23grZ1SkJKZBiRdkgKH1FvS6/X7mL8MVlZA20nS9Or+raXZ9PIS8h9p6vf0u9KYpmftmw/smSX9/cII4M3t0iQaxtRo/3S2vU1jpADIzg14/XdpcVzdGlVHvgOu7gbS7khdF+9eASpVlVrWrv0N/DVRSnfnojRdOiBNCS+TSYHm0P9J6QFpTFpAL5MvT7EF9pXKq8PueEREREQA2CUvX5WeTPogBPAwU6OfBKJCsncD3vhL6oKnzZS6pFnJpcVS3Yu4FlBR1OooPfKjUEmL1/7QWZoeu9Egac2rg8uAXU+6uoV9Ks3+V5B2U6XZ8279I02F/tqGpy1bNTtIY56OLpcCKmsn4M4FwMEbGPY/4M4lqWve0R+kbm//7pFa5Or2AKo9M6NgZV8pcLu4RWp1Konpwk2lspPW7jr6A1AlWAoIiYiIiIgBU37UCisorGTQZAukZVTwgAmQuhH6NCs4XVng01yaAOLYj8Af4UDz0U9betpMKlywBEjB14DV0iQSDfsDXg0NXw/7RFqH6n6MNKOgvYfUYuRcXXp0/AjYMR3YMgEQWgAyaVxXTo5VSn+NozaTpO6DL75VuuUgIiIiKkPYJS8fMpnMfBM/kPl1nC51oUu6JAVNgLQ+U9tJpuXjWAXoMluaCCInlR3QZ5k0m6CdmxQsPbtGV4twoMErT4IlSK1dZbX1xsED6L3Y+HkSERERVVAMmAqgG8eUwoDJ8thUBrrMefq86etA55kl3+XNpznw7j/Au8cBtzqGr8lk0lgnnxDAxllaeJiIiIiILAa75BXAQa0E8KhkF6+l5yewnzSVt9ACLSPMNz7IySfv15Q20vpTIhuQV/BunUREREQWhgFTAezNtXgtPR8yGdAqorRLIU2QAXlpl4KIiIiITMQueQWoxDFMREREREQVFgOmAph18VoiIiIiIirTGDAVQN8lj2OYiIiIiIgqHAZMBdCtvcQxTEREREREFQ8DpgLouuRxDBMRERERUcXDgKkA+kkf2CWPiIiIiKjCYcBUgKfTijNgIiIiIiKqaBgwFUBauJaTPhARERERVUQMmArAhWuJiIiIiCouBkwFcODCtUREREREFRYDpgLou+QxYCIiIiIiqnAYMBVA1yXvUZYWGm12KZeGiIiIiIieJwZMBdCtwwQADzO0pVgSIiIiIiJ63hgwFUClsIJaIV2mf5PSSrk0RERERET0PDFgKoS2ddwAABPXn8KjTLYyERERERFVFAyYCmFmnwZwc1Dj0u00fPLnudIuDhERERERPScMmArB1V6NL/o3hkwG/HIoDltPx5d2kYiIiIiI6DlgwFRILWu5YlSbGgCACetP4fq99FIukfldv5eOTSdushsiEREREVVYRQqYlixZAn9/f1hbWyMoKAj79u3LN31UVBSCgoJgbW2N6tWrY9myZbnSrF+/HgEBAVCr1QgICMDGjRuLfdySFtGpNpr4OCH1sQb/WXMcp28kIztbPJdj33uYiX/i7kOI53O86Kt30e2rfRi79gRazduFb6Ku4mEG16KissvPzw8ymSzXY8yYMQCAYcOG5XqtefPmpVxqIiorWIcQUV4UBScxtG7dOoSHh2PJkiVo0aIFvvnmG3Tt2hXnzp2Dj49PrvQxMTHo1q0bRowYgdWrV+Pvv//G6NGj4ebmhn79+gEAoqOjMWDAAHzyySfo06cPNm7ciP79+2P//v1o1qxZkY5rDkq5Fb4a2ATdvtyHE9cfoOei/XBzUKNtbTcE+1XG/fQs3Lz/CDcfPEJSWgZ8nG1R39sR9b0roa6XA7KzgaS0DNx9mIl7DzPgWckGTXycYK2U53lMjTYbPx28hgXbLyE1Q4MX/CpjavcANKrmZLbz3HzyFsb/ehKZ2myoFFZISsvE7K0XsCzqKoa38EeXQE/UdLeHTCYzWxl0HmdpEXcvHX4udlAp2CBqLo+ztPj16HX8eSoe9bwqYdCLPqjj6VDaxTLJkSNHoNU+bQ09c+YMOnXqhFdeeUW/rUuXLlixYoX+uUqleq5lJKKyi3UIEeVFJkxssmjWrBmaNm2KpUuX6rfVq1cPvXv3xuzZs3OlnzhxIjZv3ozz58/rt40aNQonT55EdHQ0AGDAgAFISUnB1q1b9Wm6dOmCypUrY82aNUU6rjEpKSlwdHREcnIyKlWqZMppGzgedx9L91zF/itJSC9mdzWVwgpNqjmheXUXNKrmiGqVbVGlsg1sVQocib2Hab+fwYWE1Fz79WlSBRO61IGXo02xjv8sIQS+3xeDmVuk/6uugZ747JVG+OtMAhbvvoKYpIf6tC52Krzo74wX/Z1RtbItnO1UcLFTwclWidTHGiSmZuBO6mPcSc2AjUoBH2dbVHO2gYeDNays8g+0tNkC0VfvYtOJm/jrbAJSH2tgrbRCsK8zQmq4IMi3Mh5naZGQ/BjxyY+RmPpYupZyK6iVcqjkVrC3VsDRRgknGyUcbZSoZKOEvVoBe2sF7NUKZGmzce1uOq7dTUfs3Yd4kJ4JJ1sVKtuq4GwnPdwc1HB3UMPuyVpc2dkCt1MfIzYpHTfup8NKJoODtQIO1son/ypgp5byVyuskPwoC+dupeDsrRSci09BeqYGgd6OaFTNCY2qOsHRVqnPNzVDg9THWXiQnoXkR9K/aRlZcK9kjRqu9qhS2QbyAq5bUegCpSW7ryIh5bHBa0G+lTHoRR8083eGi70KtiqTf1/JV0l9HvMSHh6OP/74A5cvX4ZMJsOwYcPw4MED/P7770XO09xlJqLCs8Q6BDCt3H6T/izWsSxJ7JzuRd6X16lweJ1yK+zn0aRvQJmZmTh27BgmTZpksD0sLAwHDhwwuk90dDTCwsIMtnXu3BnLly9HVlYWlEoloqOjMW7cuFxpFi5cWOTjAkBGRgYyMjL0z5OTkwFIF6c4ajjJMb93bWRoauD4tQfYe/kOLt1OhYudCt5ONvByskFlWxVi76bhQnwqLiSk4trddMitZKhsq4SLvRpONkr8eycNd9IyEX0hDdEXbhgcw9lWiXvpWQAARxsFxnasjZY1XbFo1xVsPnkL6w9exoZDl6FSWEEuA6ysZFDIZNK6UUo51AorqORyfXCi+6qtaxR6+vzpl/AMjRbn46Xg7NVmPpjQpSayM9IRVqsSOtRogr/OxGPj8Zs4fv0B7txLx5/3HuDPY/+adO2UcitUtlVCrbTSl1Ehl+HZUODG/Ue4+zDTYJ/0jGzsPZuGvWfjTDpeSbBTy+Foo8SdtExkabILtY/CSgaNke6aW/95+reLnQqPNdpCLYislFuhmrONPmiRQfq/NBZC5Wz5yy/MunE/HXfSpGvtUUmNgS9Ww9mbKdh98Q6OXErHkUs39WltVFZwtlPBTqWATCaDwkoGK5kMcisZFg9uqg8AC0v3OTRHN9PMzEysXr0aERERBtdjz549cHd3h5OTE9q0aYOZM2fC3d09z3zMVYcQUfFZQh0CFK8eyc4o/+OldYpTr/I6FQ6vU97pCqxHhAlu3rwpAIi///7bYPvMmTNF7dq1je5Tq1YtMXPmTINtf//9twAgbt26JYQQQqlUip9//tkgzc8//yxUKlWRjyuEEB999JEAwAcffJThx/Xr1wtXAZlg3bp1Qi6Xi5s3b+q3rV27Vvzxxx/i9OnTYvPmzaJRo0aifv364vHjx6xD+ODDgh9luQ5hPcIHH5bxKKgeKVIfm5y/YAsh8h3PYix9zu2FydPU406ePBkRERH659nZ2bh37x5cXFzy3S8lJQXVqlXD9evXS6yZv6TztIQyWkqellBGc+RZ2mUUQiA1NRXe3t4lcuxnLV++HF27djXIe8CAAfq/AwMDERwcDF9fX/z555/o27ev0XzKUh1irnyZZ9nP01z5WnqellCHAEWvR0qLud7D5Q2vU+GU9etU2HrEpIDJ1dUVcrkcCQkJBtsTExPh4eFhdB9PT0+j6RUKBVxcXPJNo8uzKMcFALVaDbVabbDNyckp7xPMoVKlSiX+n1vSeVpCGS0lT0sooznyLM0yOjo6luhxAeDatWvYsWMHNmzYkG86Ly8v+Pr64vLly3mmKYt1iLnyZZ5lP09z5WvJeZb1OgQofj1SWsz1Hi5veJ0Kpyxfp8LUIyZNO6ZSqRAUFITIyEiD7ZGRkQgNDTW6T0hISK7027dvR3BwMJRKZb5pdHkW5bhEVDGtWLEC7u7u6N49/wGfd+/exfXr1+Hl5fWcSkZEloB1CBHlZPI8zREREfj+++/xww8/4Pz58xg3bhzi4uIwatQoAFLT8+uvv65PP2rUKFy7dg0RERE4f/48fvjhByxfvhzjx4/Xpxk7diy2b9+OuXPn4sKFC5g7dy527NiB8PDwQh+XiCg7OxsrVqzA0KFDoVA8bUBPS0vD+PHjER0djdjYWOzZswc9e/aEq6sr+vTpU4olJqKyhHUIERlVlMGQixcvFr6+vkKlUommTZuKqKgo/WtDhw4Vbdq0MUi/Z88e0aRJE6FSqYSfn59YunRprjx/++03UadOHaFUKkXdunXF+vXrTTpuSXr8+LH46KOPChzIWZp5WkIZLSVPSyijOfK0hDKaatu2bQKAuHjxosH29PR0ERYWJtzc3IRSqRQ+Pj5i6NChIi4uzizlMNd1sJT/M+bJ//uynmdeykodUppKux63FLxOhVNerpPJ6zARERERERFVFCZ3ySMiIiIiIqooGDARERERERHlgQETERERERFRHhgwEREREVGx+Pn5YeHChaVdDIvStm1bgxmhywqZTIbff/9d//zChQto3rw5rK2t0bhx4zy3lWcMmHJYsmQJ/P39YW1tjaCgIOzbt6/IeU2fPh0ymczg4enpaVIee/fuRc+ePeHt7Z3rDQxIKxRPnz4d3t7esLGxQdu2bXH27Nli5Tls2LBc5W7evHme+c2ePRsvvPACHBwc4O7ujt69e+PixYvFKmdh8jSlnEuXLkXDhg31C6eFhIRg69atRS5fYfI09TrmdR1kMplBhVqUsuaXn6nlLOh9XZzylRcVoR4pTL7lsS7RscQ6paTrk/zyZb1SenJex5yPYcOGFbh/zs9yeWPs/SmTydClS5fSLppZPXveSqUSHh4e6NSpE3744QdkZ2fr08XHx6Nr16765x999BHs7Oxw8eJF7Ny5M89tpcncATsDpmesW7cO4eHh+OCDD3D8+HG0atUKXbt2RVxcXJHzrF+/PuLj4/WP06dPm7T/w4cP0ahRIyxatMjo6/PmzcOCBQuwaNEiHDlyBJ6enujUqRNSU1OLnCcAdOnSxaDcW7ZsyTNtVFQUxowZg4MHDyIyMhIajQZhYWF4+PBhkctZmDxNKWfVqlUxZ84cHD16FEePHkX79u3Rq1cv/Q23KNexoDxNvY45HTlyBN9++y0aNmxosL0oZc0vv6KUM7/3dVHLV15UlHqkMPkC5a8u0bG0OqWk65OC8i1KWVmvlIxnr+HChQtRqVIlg21ffvllaRexTMj5/oyPj8eaNWtKu1hmpzvv2NhYbN26Fe3atcPYsWPRo0cPaDQaAICnpyfUarV+n6tXr6Jly5bw9fWFi4tLnttMlZmZWfwTel5KZzbzsunFF18Uo0aNMthWt25dMWnSpCLl99FHH4lGjRqVQMkkAMTGjRv1z7Ozs4Wnp6eYM2eOftvjx4+Fo6OjWLZsWZHyFEJaS6tXr15FLmdiYqIAoF8nqyTKmTPPkihn5cqVxffff18i5cuZZ3HLl5qaKmrVqiUiIyNFmzZtxNixY4UQRb+WeeVXlHLm974uyWtpqSpiPWIsXyEqTl2iU1brlJKuTwrKtyhlZb1iHitWrBCOjo4G25YsWSKqV68ulEqlqF27tli1apX+NV9fXwFA//D19RVCCHHlyhXx0ksvCXd3d2FnZyeCg4NFZGSkQb6+vr7iiy++MPMZlYyC3p+XLl0SrVq1Emq1WtSrV09s377doI7bvXu3ACDu37+v3+f48eMCgIiJiRFCCJGUlCQGDhwoqlSpImxsbERgYKD45ZdfDI6T83Njbnmd986dOwUA8d133wkhDOvzZ98PAMRHH31kdJsQQty4cUP0799fODk5CWdnZ/HSSy/pr8ezx581a5bw8vLSv78Ku99nn30mPD09hbOzsxg9erTIzMwUQkjXMWeZShpbmJ7IzMzEsWPHEBYWZrA9LCwMBw4cKHK+ly9fhre3N/z9/TFw4ED8+++/xS2qXkxMDBISEgzKrFar0aZNm2KVGQD27NkDd3d31K5dGyNGjEBiYmKh901OTgYAODs7l1g5c+ZZnHJqtVqsXbsWDx8+REhISImUL2eexSkfAIwZMwbdu3dHx44dDbYXtax55VfUcub1vjbne9ISsB7JrTzXJTplvU4p6fqkoHyLWlbWK+a3ceNGjB07Fu+99x7OnDmDkSNH4o033sDu3bsBSC2GALBixQrEx8frn6elpaFbt27YsWMHjh8/js6dO6Nnz57Fajkvq7Kzs9G3b1/I5XIcPHgQy5Ytw8SJE03O5/HjxwgKCsIff/yBM2fO4O2338aQIUNw6NAhM5S6eNq3b49GjRphw4YNuV6Lj49H/fr18d577yE+Ph7jx483ui09PR3t2rWDvb099u7di/3798Pe3h5dunQxaEnauXMnzp8/j8jISPzxxx+F3m/37t24evUqdu/ejZUrV+LHH3/Ejz/+CADYsGEDqlatihkzZuhbC0uaosRztFBJSUnQarXw8PAw2O7h4YGEhIQi5dmsWTOsWrUKtWvXxu3bt/Hpp58iNDQUZ8+eLXLz5bN05TJW5mvXrhU5365du+KVV16Br68vYmJiMG3aNLRv3x7Hjh0zaKI1RgiBiIgItGzZEoGBgSVSTmN5FqWcp0+fRkhICB4/fgx7e3ts3LgRAQEB+htuUcqXV55FKZ/O2rVr8c8//+hvVM8qyrXML7+ilDO/97W53pOWgvWIofJal+hYQp1S0vVJYfItSllZrzwf8+fPx7BhwzB69GgAQEREBA4ePIj58+ejXbt2cHNzAwA4OTkZjCFr1KgRGjVqpH/+6aefYuPGjdi8eTPeeeed53sSJeSPP/6Avb29wbaJEyeiWbNmOH/+PGJjY1G1alUAwKxZswzG9BRGlSpVMH78eP3z//znP/jrr7/w22+/oVmzZsU/gRJWt25dnDp1Ktd2T09PKBQK2Nvb698T9vb2ubb98MMPsLKywvfffw+ZTAZACrydnJywZ88e/Q8ednZ2+P7776FSqUzar3Llyli0aBHkcjnq1q2L7t27Y+fOnRgxYgScnZ0hl8vh4OBg8hjfwmLAlIPuP0tHCJFrW2E9++Fq0KABQkJCUKNGDaxcuRIRERHFKuezSrLMADBgwAD934GBgQgODoavry/+/PNP9O3bN99933nnHZw6dQr79+8vsXLmlaep5axTpw5OnDiBBw8eYP369Rg6dCiioqKKVb688gwICCjSdbx+/TrGjh2L7du3w9raOs/jFrashcnP1HLm977WDeou6fekpWE9IimvdYlOWa9TSro+MSVf1itl0/nz5/H2228bbGvRokWB45oePnyIjz/+GH/88Qdu3boFjUaDR48eWXQLU7t27bB06VKDbc7Ozvjpp5/g4+OjD5YAGLTyFpZWq8WcOXOwbt063Lx5ExkZGcjIyICdnV2xy24Oxf08HTt2DFeuXIGDg4PB9sePH+Pq1av65w0aNNAHS6bsV79+fcjlcv1zLy8vk8fzFgcDpidcXV0hl8tz/QqcmJiY61etorKzs0ODBg1w+fLlEslPF0UnJCTAy8tLv70kywxIb0pfX98Cy/2f//wHmzdvxt69ew0qmuKUM688i1JOlUqFmjVrAgCCg4Nx5MgRfPnll/qm9qKUL688v/nmG5PLB0gVR2JiIoKCgvTbtFot9u7di0WLFuln9ypsWQvKLyMjw6ACKmw5n/Xs+7p3794mla+8YT2Sv/JSl+iU9TqlpOuTwubLeqVsK0rg+f7772Pbtm2YP38+atasCRsbG7z88suWNWg/Bzs7O/1n7VnSsB1DOa+PlZVVrrRZWVkGaT7//HN88cUXWLhwIRo0aAA7OzuEh4eX2Wt2/vx5+Pv7F3n/7OxsBAUF4eeff871mq7lEkCugLGw+ymVSoPXZDKZwcx+5sYxTE+oVCoEBQUhMjLSYHtkZCRCQ0NL5BgZGRk4f/68QYVfHP7+/vD09DQoc2ZmJqKiokqszABw9+5dXL9+Pc9yCyHwzjvvYMOGDdi1a1euD1xRyllQnkUpp7FjZGRklOh11OVZ1PJ16NABp0+fxokTJ/SP4OBgvPrqqzhx4gSqV69uUlkLyi/nl5rClvNZz76vn9d7sqxiPZK/8lqXPHusslSnlHR9Uth8Wa+UXfXq1cvVwnrgwAHUq1dP/1ypVEKr1Rqk2bdvH4YNG4Y+ffqgQYMG8PT0RGxs7PMo8nMXEBCAuLg43Lp1S78tOjraII3ui/yzY2VOnDhhkGbfvn3o1asXXnvtNTRq1AjVq1cvsR+6StquXbtw+vRp9OvXr8h5NG3aFJcvX4a7uztq1qxp8HB0dCzx/XJSqVS53rclqsSnkbBga9euFUqlUixfvlycO3dOhIeHCzs7OxEbG1uk/N577z2xZ88e8e+//4qDBw+KHj16CAcHB5PyS01NFcePH9fPvrJgwQJx/Phxce3aNSGEEHPmzBGOjo5iw4YN4vTp02LQoEHCy8tLpKSkFCnP1NRU8d5774kDBw6ImJgYsXv3bhESEiKqVKmSZ57/93//JxwdHcWePXtEfHy8/pGenq5PY2o5C8rT1HJOnjxZ7N27V8TExIhTp06JKVOmCCsrK7F9+/YiX8f88izKdcxLzll0ilLWvPIrSjkLel8Xt3yWrqLUIwXlW17rEh1LrVNKuj4xli/rlbIj5yx5GzduFEqlUixdulRcunRJfP7550Iul4vdu3fr09SqVUv83//9n4iPjxf37t0TQgjRu3dv0bhxY3H8+HFx4sQJ0bNnT+Hg4GDwXrK0WfK6dOliUCfEx8eLO3fuCK1WKwICAkSHDh3EiRMnxN69e0VQUJDBzHGZmZmiWrVq4pVXXhEXL14Uf/zxh6hTp47BLHnh4eGiWrVq4u+//xbnzp0Tb731lqhUqZLBLHWlMUue7rxv3Lghjh07JmbOnCns7e1Fjx49hEajEULknvW0UaNG+pnw8tr28OFDUatWLdG2bVuxd+9e8e+//4o9e/aId999V1y/fl1//Jyz9BV1v7Fjx4o2bdron3fq1Em89NJL4saNG+LOnTvFuk7GMGDKYfHixcLX11eoVCrRtGlTg6lnTTVgwADh5eUllEql8Pb2Fn379hVnz541KQ/d1JU5H0OHDhVCSNOtfvTRR8LT01Oo1WrRunVrcfr06SLnmZ6eLsLCwoSbm5tQKpXCx8dHDB06VMTFxeWZn7G8AIgVK1bo05hazoLyNLWcw4cP1/+/urm5iQ4dOui/2BT1OuaXZ1GuY15yVqhFKWte+RWlnAW9r4tbvvKgItQjBeVbXusSHUutU0q6PjGWL+uVssPUacWFEGLz5s2iZs2aQqFQ6Kd9jomJEe3atRM2NjaiWrVqYtGiRbneS5YWMBmrF+rUqSOEEOLixYuiZcuWQqVSidq1a4u//vorVxCxf/9+0aBBA2FtbS1atWolfvvtN4OA6e7du6JXr17C3t5euLu7i6lTp4rXX3+91AMm3bkqFArh5uYmOnbsKH744Qeh1Wr16YoSMAkhRHx8vHj99deFq6urUKvVonr16mLEiBEiOTlZf3xj05oXZb+cAVN0dLRo2LChUKvVZplWXCaEkc6aREREREQEQBozs3HjRv2YOqpYOIaJiIiIiIgoDwyYiIiIiIiI8sBpxYmIiIiI8sERLBUbW5iIiIiIiIjywICJiIiIiIgoDwyYiIiIiIiI8sCAiYiIiIiIKA8MmIiIiIiIiPLAgImIiIiIiCgPDJiIiIiIiIjywICJiIiIiIgoDwyYiIiIiIiI8vD/H40XNYVRo3wAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw losses and accuracies\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Loss')\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(test_losses, label='test')\n",
    "plt.xticks(range(0, 51, 5))\n",
    "plt.ylim(0, 0.01)\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(train_acc, label='train')\n",
    "plt.plot(test_acc, label='test')\n",
    "plt.xticks(range(0, 51, 5))\n",
    "plt.ylim(75, 100)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Accuracy(classified)')\n",
    "plt.bar(['Total', 'Equal', 'Different'], [test_acc[-1], acc_equal, acc_different])\n",
    "plt.ylim(75, 100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果分析\n",
    "\n",
    "可以看到，ResNet18 的性能非常好，训练和测试 loss 一直保持在一个很小的水平；准确度也逐渐上升到97%附近。另外，相等数据的准确度不如不等数据。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
